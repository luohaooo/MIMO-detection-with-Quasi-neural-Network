{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "from scipy.linalg import orth\n",
    "from sphere_decoding.new_sphereDecodingUseC import sphere_decoding_BER\n",
    "import matplotlib.pyplot as plt\n",
    "# from timeit import default_timer as time\n",
    "\n",
    "# 交叉熵正常训练\n",
    "\n",
    "\n",
    "Nt = 2\n",
    "Nr = 4\n",
    "\n",
    "iter_num = 30\n",
    "channel_list = np.load(\"channel_list_4_2.npy\")\n",
    "H_list = channel_list[0:iter_num]\n",
    "cov_list = np.load(\"covmatrix_list_4.npy\")\n",
    "\n",
    "SNR_list = np.array([0,4,8,12,16])\n",
    "\n",
    "\n",
    "# Adam\n",
    "# beta1 = 0.8 \n",
    "# beta2 = 0.999\n",
    "# episilon = 1e-8\n",
    "\n",
    "max_iter = 100\n",
    "\n",
    "pilot_length = 128\n",
    "\n",
    "beta1 = 0\n",
    "\n",
    "# SD_mean_performance = np.zeros(len(SNR_list))\n",
    "# SD_mean_performance_estimated = np.zeros(len(SNR_list))\n",
    "MAP_mean_performance = np.zeros(len(SNR_list))\n",
    "MaxLog_mean_performance = np.zeros(len(SNR_list))\n",
    "QNN_mean_performance_128 = np.zeros(len(SNR_list))\n",
    "\n",
    "save_loss = np.empty((len(SNR_list), iter_num))\n",
    "save_BER = np.empty((len(SNR_list), iter_num))\n",
    "save_channel = np.empty((len(SNR_list), iter_num, Nr, Nt), dtype=np.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate signals for simulation\n",
    "def generate_random_bit_sequence(length):\n",
    "    return ''.join(random.choice('01') for _ in range(length))\n",
    "\n",
    "def qam16_modulation(binary_input):\n",
    "    mapping = {\n",
    "        '0000': (1+1j),\n",
    "        '0001': (1+3j),\n",
    "        '0010': (3+1j),\n",
    "        '0011': (3+3j),\n",
    "        '0100': (1-1j),\n",
    "        '0101': (1-3j),\n",
    "        '0110': (3-1j),\n",
    "        '0111': (3-3j),\n",
    "        '1000': (-1+1j),\n",
    "        '1001': (-1+3j),\n",
    "        '1010': (-3+1j),\n",
    "        '1011': (-3+3j),\n",
    "        '1100': (-1-1j),\n",
    "        '1101': (-1-3j),\n",
    "        '1110': (-3-1j),\n",
    "        '1111': (-3-3j)\n",
    "    }\n",
    "    return mapping.get(binary_input, \"Invalid binary input\")/np.sqrt(10)\n",
    "\n",
    "def generate_x_sequence(length, Nt):\n",
    "    total_bits_sequence = generate_random_bit_sequence(length*Nt*4)\n",
    "    bits_sequence = [total_bits_sequence[i:i+4] for i in range(0, len(total_bits_sequence), 4)]\n",
    "    x_sequence = np.empty((Nt, length), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        x_sequence[:,ii] = [qam16_modulation(bits_sequence[ii*Nt+jj]) for jj in range(Nt)]\n",
    "    return bits_sequence, x_sequence\n",
    "\n",
    "def generate_channel(SNR):\n",
    "    return np.sqrt(SNR)*H_list\n",
    "\n",
    "def generate_covmatrix(dimension):\n",
    "    U = orth(np.random.randn(dimension,dimension))\n",
    "    x = np.random.rand(dimension)\n",
    "    x = (x/np.sum(x))*dimension\n",
    "    V = np.diag(x)\n",
    "    whitening_matrix = np.dot(U, np.sqrt(V))\n",
    "    cov_matrix = np.dot(whitening_matrix, whitening_matrix.conj().T)\n",
    "    return cov_matrix\n",
    "\n",
    "def generate_noise(cov_matrix,Nr):\n",
    "    real_part = np.random.multivariate_normal(np.zeros(Nr), cov_matrix/2)\n",
    "    imag_part = np.random.multivariate_normal(np.zeros(Nr), cov_matrix/2)\n",
    "    return (real_part+1j*imag_part).reshape(Nr,1)\n",
    "\n",
    "def generate_data(Nr,Nt,length,H_channel,cov_matrix):\n",
    "    bits_sequence, x_sequence = generate_x_sequence(length, Nt)\n",
    "    n_sequence = np.empty((length,Nr,1), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        n_sequence[ii] = generate_noise(cov_matrix,Nr)\n",
    "    y_sequence = np.empty((Nr, length), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        s = np.dot(H_channel, x_sequence[:,ii].reshape(Nt,1))\n",
    "        y_sequence[:, ii] = (s + n_sequence[ii]).reshape(Nr)\n",
    "    return bits_sequence, x_sequence, y_sequence\n",
    "\n",
    "def whiten_matrix(cov_matrix, H):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    diagmatrix = np.sqrt(np.diag(eigenvalues))\n",
    "    whitening_matrix = np.linalg.inv(np.dot(eigenvectors, diagmatrix))\n",
    "    return np.dot(whitening_matrix, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training H_hat\n",
    "\n",
    "def bits2signals(bits):\n",
    "    # bits: input binary string with length of (4*Nt) \n",
    "    return np.array([qam16_modulation(bits[i:i+4]) for i in range(0, len(bits), 4)]).reshape(Nt,1)\n",
    "\n",
    "def calculate_layer1_training(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "    output = np.empty(dimension_layer1)\n",
    "    # calculate gradient components in layer1\n",
    "    gradients = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    gradient_component = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        # s_conjugate_transpose = s.conj().T\n",
    "        y = y.reshape(Nr, 1)\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        error_norm[index] = np.square(np.linalg.norm(error))\n",
    "        gradient_component[index] = np.dot(error, s.conj().T)\n",
    "\n",
    "    min_error_norm = np.min(error_norm)\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        value =  np.exp(-error_norm[index]+min_error_norm)\n",
    "        output[index] = value\n",
    "        gradients[index] = -value*(-gradient_component[index])\n",
    "    # print(output)\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "def layer2_matrix(n):\n",
    "    if n == 1:\n",
    "        return np.array([0,1])\n",
    "    else:\n",
    "        last_ = layer2_matrix(n-1)\n",
    "        half_cols_num = 2**(n-1)\n",
    "        first_row = np.concatenate((np.zeros(half_cols_num), np.ones(half_cols_num)))\n",
    "        remain_rows = np.hstack((last_, last_))\n",
    "        # print(remain_rows)\n",
    "        return np.vstack((first_row, remain_rows))\n",
    "\n",
    "\n",
    "def calculate_layer2_training(layer1_output, true_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = sum_prob_1/total_prob\n",
    "    # calculate gradient components in layer2\n",
    "    gradients = np.zeros(2**(4*Nt))\n",
    "    # print(output)\n",
    "    epsilon = 1e-10  # 为了防止log(0)的情况，添加一个小的常数\n",
    "    output = np.clip(output, epsilon, 1. - epsilon)\n",
    "    for ii in range(len(gradients)):\n",
    "        # gradient1 = true_output/output\n",
    "        # gradient2 = (np.ones(len(true_output))-true_output)/(np.ones(len(output))-output)\n",
    "        for jj in range(4*Nt):\n",
    "            gradient1 = true_output[jj]/output[jj]\n",
    "            gradient2 = (1-true_output[jj])/(1-output[jj])\n",
    "            gradient3 = A[jj][ii]/total_prob\n",
    "            gradient4 = sum_prob_1[jj]/np.square(total_prob)\n",
    "            # gradients for cross entropy\n",
    "            gradients[ii] += (-1/(4*Nt))*(gradient1-gradient2)*(gradient3-gradient4)\n",
    "            # gradients for MSE\n",
    "            # gradients[ii] += (1/(4*Nt))*2*(output[jj]-true_output[jj])*(gradient3-gradient4)\n",
    "\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "def calculate_square_error(layer2_output, true_sequence):\n",
    "    return np.linalg.norm(layer2_output-true_sequence)**2\n",
    "\n",
    "def calculate_cross_entropy(layer2_output, true_sequence):\n",
    "    epsilon = 1e-10  # 为了防止log(0)的情况，添加一个小的常数\n",
    "    layer2_output = np.clip(layer2_output, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -np.mean(true_sequence * np.log(layer2_output) + (1 - true_sequence) * np.log(1 - layer2_output))\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def calculate_cost_function(H_hat):\n",
    "    total_loss = 0\n",
    "    total_gradients = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    training_length = len(y_sequence[0])\n",
    "    for ii in range(training_length):\n",
    "        # print(ii)\n",
    "        true_sequence = ''.join(bits_sequence[ii*Nt+jj] for jj in range(Nt))\n",
    "        true_sequence = np.array([eval(ii) for ii in true_sequence])\n",
    "        layer1_output, layer1_gradients = calculate_layer1_training(H_hat, y_sequence[:, ii])\n",
    "        layer2_output, layer2_gradients = calculate_layer2_training(layer1_output, true_sequence)\n",
    "        total_loss += calculate_cross_entropy(layer2_output,true_sequence)\n",
    "        # SGD\n",
    "        if np.random.rand() < 0.9:\n",
    "            for jj in range(2**(4*Nt)):\n",
    "                total_gradients += (layer2_gradients[jj]*layer1_gradients[jj])\n",
    "    mean_loss = total_loss/training_length\n",
    "    return mean_loss, total_gradients\n",
    "\n",
    "\n",
    "def training(max_iter):\n",
    "    H_hat = np.sqrt(1/2)*(np.random.randn(Nr,Nt)+1j*np.random.randn(Nr,Nt))\n",
    "    # H_hat = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    # H_hat = np.copy(H_estimated)\n",
    "    momentum = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    last_loss = -100\n",
    "    mean_loss = -200\n",
    "    m = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    v = np.zeros((Nr,Nt))\n",
    "    for iter_num in range(max_iter):\n",
    "        # solve the gradient\n",
    "        mean_loss, total_gradients = calculate_cost_function(H_hat)\n",
    "        print(\"loss: \"+str(mean_loss))\n",
    "        if np.abs(last_loss-mean_loss) < 1e-4  and mean_loss < 1 and iter_num > 29:\n",
    "            return H_hat, mean_loss\n",
    "        if np.abs(last_loss-mean_loss) < 1e-4  and mean_loss > 1:\n",
    "            return training(max_iter)\n",
    "        else:\n",
    "            last_loss = mean_loss\n",
    "        # update H_hat\n",
    "        momentum = (1-beta1)*total_gradients + beta1*momentum\n",
    "        H_hat -= alpha * momentum\n",
    "\n",
    "        # Adaptive momentum to update H_hat\n",
    "        # m = beta1*m + (1-beta1)*total_gradients # update biased first moment estimate\n",
    "        # gradients_square = np.abs(total_gradients)**2 # elementwise square of gradients matrix\n",
    "        # v = beta2*v + (1-beta2)*gradients_square # update biased second raw moment estimate\n",
    "        # m_hat = m/(1-beta1**(iter_num+1)) # compute bias-corrected first moment estimate\n",
    "        # v_hat = v/(1-beta2**(iter_num+1)) # compute bias-corrected second raw moment estimate\n",
    "        # print(\"v:\"+str(np.sqrt(v_hat)))\n",
    "        # H_hat -= alpha * m_hat / (np.sqrt(v_hat)+episilon) # update H_hat\n",
    "        # print(H_hat)\n",
    "    return training(max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing QNN for detection\n",
    "def calculate_layer1_testing(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    output = np.zeros(dimension_layer1)\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        y = y.reshape(Nr,1)\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        error_norm[index] = np.square(np.linalg.norm(error))\n",
    "\n",
    "    min_error_norm = np.min(error_norm)\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        value =  np.exp(-error_norm[index]+min_error_norm)\n",
    "        output[index] = value\n",
    "    return output\n",
    "\n",
    "\n",
    "def calculate_layer2_testing(layer1_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = np.array([sum_prob_1[ii]/total_prob for ii in range(4*Nt)])\n",
    "    return output\n",
    "\n",
    "def detection(y, H_trained):\n",
    "    layer1_output = calculate_layer1_testing(H_trained, y)\n",
    "    layer2_output = calculate_layer2_testing(layer1_output)\n",
    "    detect_result = ''\n",
    "    for ii in range(len(layer2_output)):\n",
    "        if(layer2_output[ii]>0.5):\n",
    "            detect_result += '1'\n",
    "        else:\n",
    "            detect_result += '0'\n",
    "    return(detect_result)\n",
    "\n",
    "def count_differences(str1, str2):\n",
    "    return sum(a != b for a, b in zip(str1, str2))\n",
    "\n",
    "def calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing):\n",
    "    error = 0\n",
    "    for ii in range(len(y_sequence_testing[0])):\n",
    "        detect_result = detection(y_sequence_testing[:,ii], H_trained)\n",
    "        true_sequence = ''.join(bits_sequence_testing[ii*Nt+jj] for jj in range(Nt))\n",
    "        error += count_differences(detect_result, true_sequence)\n",
    "    BER = error/(len(y_sequence_testing[0])*len(detect_result))\n",
    "    return BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing QNN for detection\n",
    "def calculate_layer1_testing(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    output = np.zeros(dimension_layer1)\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        y = y.reshape(Nr,1)\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        error_norm[index] = np.square(np.linalg.norm(error))\n",
    "\n",
    "    min_error_norm = np.min(error_norm)\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        value =  np.exp(-error_norm[index]+min_error_norm)\n",
    "        output[index] = value\n",
    "    return output\n",
    "\n",
    "\n",
    "def calculate_layer2_testing(layer1_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = np.array([sum_prob_1[ii]/total_prob for ii in range(4*Nt)])\n",
    "    return output\n",
    "\n",
    "def detection_QNN(y, H_trained):\n",
    "    layer1_output = calculate_layer1_testing(H_trained, y)\n",
    "    layer2_output = calculate_layer2_testing(layer1_output)\n",
    "    QNN_detect_result = ''\n",
    "    for ii in range(len(layer2_output)):\n",
    "        if(layer2_output[ii]>0.5):\n",
    "            QNN_detect_result += '1'\n",
    "        else:\n",
    "            QNN_detect_result += '0'\n",
    "    return QNN_detect_result\n",
    "\n",
    "\n",
    "def detection_MAP_MaxLog(H_estimated, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "\n",
    "    min_error_norm_1 = np.ones(4*Nt)*10000\n",
    "    min_error_norm_0 = np.ones(4*Nt)*10000\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        y = y.reshape(Nr,1)\n",
    "        error = y - np.dot(H_estimated, s)\n",
    "        error_norm_value = np.square(np.linalg.norm(error))\n",
    "        error_norm[index] = error_norm_value\n",
    "        for ii in range(4*Nt):\n",
    "            bit = bits[ii]\n",
    "            if bit == '1':\n",
    "                if error_norm_value<min_error_norm_1[ii]:\n",
    "                    min_error_norm_1[ii] = error_norm_value\n",
    "            if bit == '0':\n",
    "                if error_norm_value<min_error_norm_0[ii]:\n",
    "                    min_error_norm_0[ii] = error_norm_value\n",
    "    MaxLog_detect_result = ''\n",
    "    for ii in range(4*Nt):\n",
    "        if min_error_norm_0[ii] - min_error_norm_1[ii] > 0:\n",
    "            MaxLog_detect_result += '1'\n",
    "        else:\n",
    "            MaxLog_detect_result += '0'\n",
    "            \n",
    "    MAP_detect_result = str(bin(np.argmin(error_norm))[2:].zfill(4*Nt))\n",
    "    \n",
    "    return MaxLog_detect_result, MAP_detect_result\n",
    "\n",
    "def count_differences(str1, str2):\n",
    "    return sum(a != b for a, b in zip(str1, str2))\n",
    "\n",
    "def calculate_BER(H_trained, H_estimated, bits_sequence_testing, y_sequence_testing):\n",
    "    error_QNN = 0\n",
    "    error_MAP = 0\n",
    "    error_MaxLog = 0\n",
    "    for ii in range(len(y_sequence_testing[0])):\n",
    "        detect_result_QNN = detection_QNN(y_sequence_testing[:,ii], H_trained)\n",
    "        MaxLog_detect_result, MAP_detect_result = detection_MAP_MaxLog(H_estimated, y_sequence_testing[:,ii])\n",
    "        true_sequence = ''.join(bits_sequence_testing[ii*Nt+jj] for jj in range(Nt))\n",
    "        error_QNN += count_differences(detect_result_QNN, true_sequence)\n",
    "        error_MAP += count_differences(MAP_detect_result, true_sequence)\n",
    "        error_MaxLog += count_differences(MaxLog_detect_result, true_sequence)\n",
    "    BER_QNN = error_QNN/(len(y_sequence_testing[0])*len(detect_result_QNN))\n",
    "    BER_MAP = error_MAP/(len(y_sequence_testing[0])*len(MAP_detect_result))\n",
    "    BER_MaxLog = error_MaxLog/(len(y_sequence_testing[0])*len(MaxLog_detect_result))\n",
    "    \n",
    "    return BER_QNN, BER_MAP, BER_MaxLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0.05\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 0\n",
      "loss: 1.1407221330731547\n",
      "loss: 0.7228807082781127\n",
      "loss: 0.7062301292797408\n",
      "loss: 0.5203398918145202\n",
      "loss: 0.3104170798332249\n",
      "loss: 0.28106490912168464\n",
      "loss: 0.27365962745311967\n",
      "loss: 0.27095734607730354\n",
      "loss: 0.26993550523223764\n",
      "loss: 0.26876886642529235\n",
      "loss: 0.26817971933477786\n",
      "loss: 0.2683716711037683\n",
      "loss: 0.2675767685491376\n",
      "loss: 0.26752830031332053\n",
      "loss: 0.2672507220657791\n",
      "loss: 0.2670241165164854\n",
      "loss: 0.26692801938548755\n",
      "loss: 0.26693858702236983\n",
      "loss: 0.2667714976389812\n",
      "loss: 0.2668164538397805\n",
      "loss: 0.26683229105809747\n",
      "loss: 0.26682271643191224\n",
      "loss: 0.2668475505071555\n",
      "loss: 0.26679030716637564\n",
      "loss: 0.2667337116949038\n",
      "loss: 0.26697341836813565\n",
      "loss: 0.26686336323184434\n",
      "loss: 0.2667056554774826\n",
      "loss: 0.26702101071905154\n",
      "loss: 0.266795041948417\n",
      "loss: 0.26683983078319923\n",
      "MAP: 0.1500244140625\n",
      "MaxLog: 0.1500244140625\n",
      "QNN: 0.122802734375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 1\n",
      "loss: 1.298539867782291\n",
      "loss: 0.7984047857914283\n",
      "loss: 0.49379471432547495\n",
      "loss: 0.3811770312368548\n",
      "loss: 0.32668013338295215\n",
      "loss: 0.29650034654982765\n",
      "loss: 0.2841736960574488\n",
      "loss: 0.2776822376613005\n",
      "loss: 0.27398994644610875\n",
      "loss: 0.27160400693133757\n",
      "loss: 0.2698429010190876\n",
      "loss: 0.2687529167889902\n",
      "loss: 0.26796862220172724\n",
      "loss: 0.26726436596394304\n",
      "loss: 0.2668399540188187\n",
      "loss: 0.2666573534141503\n",
      "loss: 0.26623076511314797\n",
      "loss: 0.2660555367450818\n",
      "loss: 0.2659719523473735\n",
      "loss: 0.2657999345743679\n",
      "loss: 0.2657049361978385\n",
      "loss: 0.2659174719403878\n",
      "loss: 0.2657019883843746\n",
      "loss: 0.26562504430911543\n",
      "loss: 0.26548293454764477\n",
      "loss: 0.2654672548623808\n",
      "loss: 0.2657839087000007\n",
      "loss: 0.26542057730587704\n",
      "loss: 0.26540338378998773\n",
      "loss: 0.2652687871665505\n",
      "loss: 0.2652911643178522\n",
      "MAP: 0.1234130859375\n",
      "MaxLog: 0.1234130859375\n",
      "QNN: 0.1019287109375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 2\n",
      "loss: 1.2605566247363051\n",
      "loss: 0.6596386396470433\n",
      "loss: 0.5661275940427783\n",
      "loss: 0.5315114184611094\n",
      "loss: 0.5051227157265773\n",
      "loss: 0.44344836960311873\n",
      "loss: 0.3998245470201004\n",
      "loss: 0.3764022076554208\n",
      "loss: 0.36121832396058046\n",
      "loss: 0.35313926647185273\n",
      "loss: 0.3480820103387651\n",
      "loss: 0.344276064070733\n",
      "loss: 0.34210463828807985\n",
      "loss: 0.3406144085689068\n",
      "loss: 0.3391423545582684\n",
      "loss: 0.3384881602037106\n",
      "loss: 0.33802091023957476\n",
      "loss: 0.33729750296486477\n",
      "loss: 0.3373386420450975\n",
      "loss: 0.33718694402312543\n",
      "loss: 0.33684776868058225\n",
      "loss: 0.33703216934025343\n",
      "loss: 0.33682627648291\n",
      "loss: 0.33679022904374106\n",
      "loss: 0.336824963981612\n",
      "loss: 0.3368558353131328\n",
      "loss: 0.3368728113010045\n",
      "loss: 0.33689267186041855\n",
      "loss: 0.33666211233907734\n",
      "loss: 0.3368466624550294\n",
      "loss: 0.3369741083885227\n",
      "loss: 0.3366897721752274\n",
      "loss: 0.3367623904072936\n",
      "MAP: 0.1832275390625\n",
      "MaxLog: 0.1832275390625\n",
      "QNN: 0.1510009765625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 3\n",
      "loss: 0.9259165404330868\n",
      "loss: 0.6310344252082886\n",
      "loss: 0.5302479512663633\n",
      "loss: 0.4827260653997849\n",
      "loss: 0.44346073244179257\n",
      "loss: 0.409056390092384\n",
      "loss: 0.38109268599723467\n",
      "loss: 0.3590504402119607\n",
      "loss: 0.3420268595201039\n",
      "loss: 0.3319990689958666\n",
      "loss: 0.3267188439243625\n",
      "loss: 0.3191657223158741\n",
      "loss: 0.31625707080515336\n",
      "loss: 0.3144722719171968\n",
      "loss: 0.3135179949276892\n",
      "loss: 0.3128668259646622\n",
      "loss: 0.31235212428703013\n",
      "loss: 0.311751270179158\n",
      "loss: 0.31153375095728153\n",
      "loss: 0.3114973354170933\n",
      "loss: 0.3113330678372684\n",
      "loss: 0.31148854963926603\n",
      "loss: 0.31109879171805194\n",
      "loss: 0.31098051496479884\n",
      "loss: 0.3109571170167947\n",
      "loss: 0.31100037180674506\n",
      "loss: 0.31101584933916293\n",
      "loss: 0.31098918815512905\n",
      "loss: 0.31095257721728814\n",
      "loss: 0.3112335221172611\n",
      "loss: 0.3109558696598665\n",
      "loss: 0.3108535818504167\n",
      "loss: 0.31086922946821716\n",
      "MAP: 0.159912109375\n",
      "MaxLog: 0.159912109375\n",
      "QNN: 0.1431884765625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 4\n",
      "loss: 2.0058549064831275\n",
      "loss: 0.9286819343147665\n",
      "loss: 0.6239316955151069\n",
      "loss: 0.54629366999426\n",
      "loss: 0.5276380546917238\n",
      "loss: 0.3812654574024333\n",
      "loss: 0.2814244427415501\n",
      "loss: 0.26160256104382473\n",
      "loss: 0.2532939871742296\n",
      "loss: 0.24789830315921446\n",
      "loss: 0.244723195160603\n",
      "loss: 0.24276715372299046\n",
      "loss: 0.24143034404439245\n",
      "loss: 0.24067991014465248\n",
      "loss: 0.24020574280728887\n",
      "loss: 0.23973169554430782\n",
      "loss: 0.23937541831039846\n",
      "loss: 0.23922728167233728\n",
      "loss: 0.239071905240566\n",
      "loss: 0.2389709116103146\n",
      "loss: 0.23888745951713045\n",
      "loss: 0.23878065885492505\n",
      "loss: 0.23877224314250978\n",
      "loss: 0.23871149314244677\n",
      "loss: 0.2387660688720471\n",
      "loss: 0.23893422077990661\n",
      "loss: 0.23865486521010515\n",
      "loss: 0.23864138350816397\n",
      "loss: 0.2388315877229847\n",
      "loss: 0.23873955522018883\n",
      "loss: 0.23857762541390937\n",
      "loss: 0.2386415586874527\n",
      "MAP: 0.1322021484375\n",
      "MaxLog: 0.1322021484375\n",
      "QNN: 0.095703125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 5\n",
      "loss: 1.74408293909605\n",
      "loss: 0.9699040840314804\n",
      "loss: 0.6802398797480949\n",
      "loss: 0.7140172998113269\n",
      "loss: 0.49564521802974093\n",
      "loss: 0.3434864339490793\n",
      "loss: 0.32081710194504925\n",
      "loss: 0.3120869159024305\n",
      "loss: 0.3082314811324901\n",
      "loss: 0.305894776992034\n",
      "loss: 0.30453885898013405\n",
      "loss: 0.3030319372925245\n",
      "loss: 0.3016693358415505\n",
      "loss: 0.3010824996698626\n",
      "loss: 0.3001352258351546\n",
      "loss: 0.2998473732668939\n",
      "loss: 0.2992660439916239\n",
      "loss: 0.2983625740223351\n",
      "loss: 0.2979020958229693\n",
      "loss: 0.2977547376330763\n",
      "loss: 0.2972227576905636\n",
      "loss: 0.2970517222127703\n",
      "loss: 0.29714292781656154\n",
      "loss: 0.29738918513545787\n",
      "loss: 0.2976553868797869\n",
      "loss: 0.2966715927373788\n",
      "loss: 0.29661826093978344\n",
      "loss: 0.2963789952649152\n",
      "loss: 0.2960992645136112\n",
      "loss: 0.29610557687970307\n",
      "loss: 0.2963703627279556\n",
      "loss: 0.2960185576397631\n",
      "loss: 0.29604979147017285\n",
      "MAP: 0.1651611328125\n",
      "MaxLog: 0.1651611328125\n",
      "QNN: 0.1240234375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 6\n",
      "loss: 0.8949420414782141\n",
      "loss: 0.6100292008882371\n",
      "loss: 0.42124170288558127\n",
      "loss: 0.3792889811727297\n",
      "loss: 0.36080021568730664\n",
      "loss: 0.34914348501027487\n",
      "loss: 0.34255772169556387\n",
      "loss: 0.33683277098101244\n",
      "loss: 0.33418627241059456\n",
      "loss: 0.3317833106004217\n",
      "loss: 0.32967269126485726\n",
      "loss: 0.32830750951412535\n",
      "loss: 0.32741676936949266\n",
      "loss: 0.32623126682637404\n",
      "loss: 0.32569653494203693\n",
      "loss: 0.3247861533463368\n",
      "loss: 0.3244863498766366\n",
      "loss: 0.32421551659931624\n",
      "loss: 0.3237295013179375\n",
      "loss: 0.3233606195953333\n",
      "loss: 0.323022734766798\n",
      "loss: 0.3227198681882595\n",
      "loss: 0.32248446686439536\n",
      "loss: 0.3222389934738008\n",
      "loss: 0.32199092033606963\n",
      "loss: 0.3217557482530817\n",
      "loss: 0.3216442723634482\n",
      "loss: 0.3213612738956428\n",
      "loss: 0.32106542379811\n",
      "loss: 0.32121984686467564\n",
      "loss: 0.3208847781458827\n",
      "loss: 0.32071870183639833\n",
      "loss: 0.32047934173340265\n",
      "loss: 0.3202997504004788\n",
      "loss: 0.3202748728412811\n",
      "MAP: 0.17236328125\n",
      "MaxLog: 0.17236328125\n",
      "QNN: 0.1566162109375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 7\n",
      "loss: 0.8899439181898773\n",
      "loss: 0.6282345292084939\n",
      "loss: 0.44964410079708317\n",
      "loss: 0.4061984237776364\n",
      "loss: 0.39022079146742567\n",
      "loss: 0.3834495050452678\n",
      "loss: 0.3770854054055182\n",
      "loss: 0.37370899580530015\n",
      "loss: 0.37180842936932124\n",
      "loss: 0.3681425282496064\n",
      "loss: 0.3665210499258259\n",
      "loss: 0.36439675092784996\n",
      "loss: 0.3633977722987638\n",
      "loss: 0.36188278814499386\n",
      "loss: 0.36045633901695007\n",
      "loss: 0.36034536120581884\n",
      "loss: 0.35910234808802033\n",
      "loss: 0.358984879689073\n",
      "loss: 0.35775405262708415\n",
      "loss: 0.3572108213675389\n",
      "loss: 0.35691883564986066\n",
      "loss: 0.3566559430593299\n",
      "loss: 0.35665376626384826\n",
      "loss: 0.3563054953769091\n",
      "loss: 0.35589788422431484\n",
      "loss: 0.35573054895844475\n",
      "loss: 0.35594697212586335\n",
      "loss: 0.35550086780037904\n",
      "loss: 0.3555154717232109\n",
      "loss: 0.3562507544454654\n",
      "loss: 0.35541944132555203\n",
      "loss: 0.355586647911957\n",
      "loss: 0.3554905993678432\n",
      "MAP: 0.2103271484375\n",
      "MaxLog: 0.2103271484375\n",
      "QNN: 0.169677734375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 8\n",
      "loss: 0.918043146507667\n",
      "loss: 0.5951295883714969\n",
      "loss: 0.5267958793455825\n",
      "loss: 0.3741435365540345\n",
      "loss: 0.3400531794081924\n",
      "loss: 0.3323499570508705\n",
      "loss: 0.32775602245674135\n",
      "loss: 0.3256584470391229\n",
      "loss: 0.32474173100534404\n",
      "loss: 0.3235773264900358\n",
      "loss: 0.32310115867445677\n",
      "loss: 0.32300091208778137\n",
      "loss: 0.322707880924954\n",
      "loss: 0.3225374185730228\n",
      "loss: 0.32224413543775166\n",
      "loss: 0.3223006232540083\n",
      "loss: 0.32259768707241626\n",
      "loss: 0.32275163840031423\n",
      "loss: 0.32306278474682065\n",
      "loss: 0.32276379756076595\n",
      "loss: 0.32240857915947224\n",
      "loss: 0.3223711721785735\n",
      "loss: 0.32266390465450595\n",
      "loss: 0.3221723418945147\n",
      "loss: 0.32219445152627574\n",
      "loss: 0.32238181551026956\n",
      "loss: 0.3221295582509944\n",
      "loss: 0.32241706075981363\n",
      "loss: 0.3223917726056435\n",
      "loss: 0.3227704416319586\n",
      "loss: 0.3223089929561729\n",
      "loss: 0.3225960300578904\n",
      "loss: 0.3222021980836747\n",
      "loss: 0.32206680731097204\n",
      "loss: 0.32214867528783464\n",
      "MAP: 0.169189453125\n",
      "MaxLog: 0.169189453125\n",
      "QNN: 0.1455078125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 9\n",
      "loss: 0.9331253948442495\n",
      "loss: 0.576503151419441\n",
      "loss: 0.47351188782261117\n",
      "loss: 0.4237331722654643\n",
      "loss: 0.3973068491663147\n",
      "loss: 0.38210009392537586\n",
      "loss: 0.37119203958790786\n",
      "loss: 0.3636797466817985\n",
      "loss: 0.35782777124320625\n",
      "loss: 0.35365534002575116\n",
      "loss: 0.3508099447539494\n",
      "loss: 0.34844532893176366\n",
      "loss: 0.34673904065689776\n",
      "loss: 0.34520551877348277\n",
      "loss: 0.34389863449931496\n",
      "loss: 0.343094625855975\n",
      "loss: 0.34253078553829963\n",
      "loss: 0.3417860437365046\n",
      "loss: 0.3414607191875215\n",
      "loss: 0.34099701771882174\n",
      "loss: 0.3406670407303236\n",
      "loss: 0.3405501530772467\n",
      "loss: 0.3403505065896323\n",
      "loss: 0.34024539390452074\n",
      "loss: 0.3401076627646096\n",
      "loss: 0.34004500303326385\n",
      "loss: 0.340217057329214\n",
      "loss: 0.34016852019335836\n",
      "loss: 0.34066698487037855\n",
      "loss: 0.33992838715589574\n",
      "loss: 0.3396893051104089\n",
      "loss: 0.33974024662079244\n",
      "MAP: 0.18115234375\n",
      "MaxLog: 0.18115234375\n",
      "QNN: 0.1593017578125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 10\n",
      "loss: 1.1659738732037346\n",
      "loss: 1.0096896691630537\n",
      "loss: 1.2727057953322156\n",
      "loss: 0.7931228954148007\n",
      "loss: 0.7190594568340439\n",
      "loss: 0.7409644563927155\n",
      "loss: 0.54027731462342\n",
      "loss: 0.5074832546536664\n",
      "loss: 0.491132651505844\n",
      "loss: 0.4813795913040295\n",
      "loss: 0.47135874214004847\n",
      "loss: 0.4628212229578391\n",
      "loss: 0.45574814430266586\n",
      "loss: 0.44911461311897133\n",
      "loss: 0.44324114429580086\n",
      "loss: 0.43712884578564226\n",
      "loss: 0.4323985739402006\n",
      "loss: 0.4279447463069844\n",
      "loss: 0.42395866857099695\n",
      "loss: 0.42049385323991706\n",
      "loss: 0.41770093223887217\n",
      "loss: 0.41527354673223016\n",
      "loss: 0.4126276169562567\n",
      "loss: 0.410678794129956\n",
      "loss: 0.4089299098100861\n",
      "loss: 0.4079252005551414\n",
      "loss: 0.40714419858883066\n"
     ]
    }
   ],
   "source": [
    "for ii in range(len(SNR_list)):\n",
    "    SNR_dB = SNR_list[ii]\n",
    "    SNR = 10**(SNR_dB / 10)\n",
    "    \n",
    "    # SD_performance = np.zeros(iter_num)\n",
    "    # SD_performance_estimated = np.zeros(iter_num)\n",
    "    MAP_performance = np.zeros(iter_num)\n",
    "    MaxLog_performance = np.zeros(iter_num)\n",
    "    QNN_performance_128 = np.zeros(iter_num)\n",
    "\n",
    "    alpha = 0.05\n",
    "    print(\"step: \"+ str(alpha))\n",
    "\n",
    "    for jj in range(iter_num):\n",
    "        print(\"----------------------------current SNR_dB: \" +str(SNR_dB))\n",
    "        print(\"----------------------------current iter num: \" +str(jj))\n",
    "\n",
    "        H = H_list[jj] * np.sqrt(SNR)\n",
    "        cov = cov_list[0]\n",
    "        # cov = np.eye(Nr)\n",
    "\n",
    "        bits_sequence_testing, x_sequence_testing, y_sequence_testing = generate_data(Nr,Nt,1024,H,cov)\n",
    "        bits_sequence, x_sequence, y_sequence = generate_data(Nr,Nt,pilot_length,H,cov)\n",
    "        H_estimated = np.dot(y_sequence, np.linalg.pinv(x_sequence))\n",
    "        # print(\"估计信道\")\n",
    "        # print(H_estimated)\n",
    "\n",
    "        # SD_performance[jj] = sphere_decoding_BER(H, y_sequence_testing, bits_sequence_testing, 1)\n",
    "        # print(\"SD (perfect CSI): \"+str(SD_performance[jj]))\n",
    "\n",
    "\n",
    "        # SD_performance_estimated[jj] = sphere_decoding_BER(H_estimated, y_sequence_testing, bits_sequence_testing, 10000)\n",
    "        # print(\"SD (estimated CSI): \"+str(SD_performance_estimated[jj]))\n",
    "\n",
    "        # H_w = whiten_matrix(cov, H)\n",
    "        # print(\"白化信道\")\n",
    "        # print(H_w)\n",
    "\n",
    "        H_trained, loss = training(max_iter)\n",
    "        BER_QNN, BER_MAP, BER_MaxLog = calculate_BER(H_trained, H_estimated, bits_sequence_testing, y_sequence_testing)\n",
    "\n",
    "        # print(\"真实信道\")\n",
    "        # print(H)\n",
    "        # print(\"QNN信道\")\n",
    "        # print(H_trained)\n",
    "        # print(\"白化信道\")\n",
    "        # print(H_w)\n",
    "        \n",
    "\n",
    "        # save_BER[ii][jj] = BER\n",
    "        MAP_performance[jj] = BER_MAP\n",
    "        print(\"MAP: \"+str(BER_MAP))\n",
    "\n",
    "        MaxLog_performance[jj] = BER_MaxLog\n",
    "        print(\"MaxLog: \"+str(BER_MaxLog))\n",
    "\n",
    "        QNN_performance_128[jj] = BER_QNN\n",
    "        print(\"QNN: \"+str(BER_QNN))\n",
    "\n",
    "    # SD_mean_performance[ii] = np.mean(SD_performance)\n",
    "    # SD_mean_performance_estimated[ii] = np.mean(SD_performance_estimated)\n",
    "    MAP_mean_performance[ii] = np.mean(MAP_performance)\n",
    "    MaxLog_mean_performance[ii] = np.mean(MaxLog_performance)\n",
    "    QNN_mean_performance_128[ii] = np.mean(QNN_performance_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "lns1 = ax1.plot(SNR_list, SD_mean_performance_estimated, '-ro', linewidth=2.0, label=\"Max Log (estimated CSI)\")\n",
    "lns2 = ax1.plot(SNR_list, QNN_mean_performance_128, '-bo', linewidth=2.0, label=\"QNN Decoding (128 pilot)\")\n",
    "\n",
    "\n",
    "\n",
    "lns = lns1+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, loc=\"lower left\")\n",
    "\n",
    "# ax1.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs='auto'))\n",
    "# ax1.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "# ax1.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
    "\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax1.set_xticks(SNR_list)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_adjustable(\"datalim\")\n",
    "ax1.set_xlim(-0.5,16.5)\n",
    "ax1.set_ylim(1e-4, 0.8)\n",
    "ax1.set_ylabel(\"BER\")\n",
    "ax1.set_xlabel(\"SNR(dB)\")\n",
    "plt.title(r\"covariance matrix $\\neq$ I\")\n",
    "\n",
    "# plt.savefig('BER.png',dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
