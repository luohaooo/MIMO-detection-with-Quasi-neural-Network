{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "from scipy.linalg import orth\n",
    "from sphere_decoding.new_sphereDecodingUseC import sphere_decoding_BER\n",
    "import matplotlib.pyplot as plt\n",
    "# from timeit import default_timer as time\n",
    "\n",
    "# 交叉熵正常训练\n",
    "\n",
    "\n",
    "Nt = 2\n",
    "Nr = 4\n",
    "\n",
    "iter_num = 30\n",
    "channel_list = np.load(\"channel_list_4_2.npy\")\n",
    "H_list = channel_list[0:iter_num]\n",
    "cov_list = np.load(\"covmatrix_list_4.npy\")\n",
    "\n",
    "SNR_list = np.array([0,4,8,12,16])\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# Adam\n",
    "# beta1 = 0.8 \n",
    "# beta2 = 0.999\n",
    "# episilon = 1e-8\n",
    "\n",
    "max_iter = 100\n",
    "\n",
    "pilot_length = 128\n",
    "\n",
    "beta1 = 0\n",
    "\n",
    "SD_mean_performance = np.zeros(len(SNR_list))\n",
    "SD_mean_performance_estimated = np.zeros(len(SNR_list))\n",
    "QNN_mean_performance_128 = np.zeros(len(SNR_list))\n",
    "\n",
    "save_loss = np.empty((len(SNR_list), iter_num))\n",
    "save_BER = np.empty((len(SNR_list), iter_num))\n",
    "save_channel = np.empty((len(SNR_list), iter_num, Nr, Nt), dtype=np.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate signals for simulation\n",
    "def generate_random_bit_sequence(length):\n",
    "    return ''.join(random.choice('01') for _ in range(length))\n",
    "\n",
    "def qam16_modulation(binary_input):\n",
    "    mapping = {\n",
    "        '0000': (1+1j),\n",
    "        '0001': (1+3j),\n",
    "        '0010': (3+1j),\n",
    "        '0011': (3+3j),\n",
    "        '0100': (1-1j),\n",
    "        '0101': (1-3j),\n",
    "        '0110': (3-1j),\n",
    "        '0111': (3-3j),\n",
    "        '1000': (-1+1j),\n",
    "        '1001': (-1+3j),\n",
    "        '1010': (-3+1j),\n",
    "        '1011': (-3+3j),\n",
    "        '1100': (-1-1j),\n",
    "        '1101': (-1-3j),\n",
    "        '1110': (-3-1j),\n",
    "        '1111': (-3-3j)\n",
    "    }\n",
    "    return mapping.get(binary_input, \"Invalid binary input\")/np.sqrt(10)\n",
    "\n",
    "def generate_x_sequence(length, Nt):\n",
    "    total_bits_sequence = generate_random_bit_sequence(length*Nt*4)\n",
    "    bits_sequence = [total_bits_sequence[i:i+4] for i in range(0, len(total_bits_sequence), 4)]\n",
    "    x_sequence = np.empty((Nt, length), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        x_sequence[:,ii] = [qam16_modulation(bits_sequence[ii*Nt+jj]) for jj in range(Nt)]\n",
    "    return bits_sequence, x_sequence\n",
    "\n",
    "def generate_channel(SNR):\n",
    "    return np.sqrt(SNR)*H_list\n",
    "\n",
    "def generate_covmatrix(dimension):\n",
    "    U = orth(np.random.randn(dimension,dimension))\n",
    "    x = np.random.rand(dimension)\n",
    "    x = (x/np.sum(x))*dimension\n",
    "    V = np.diag(x)\n",
    "    whitening_matrix = np.dot(U, np.sqrt(V))\n",
    "    cov_matrix = np.dot(whitening_matrix, whitening_matrix.conj().T)\n",
    "    return cov_matrix\n",
    "\n",
    "def generate_noise(cov_matrix,Nr):\n",
    "    real_part = np.random.multivariate_normal(np.zeros(Nr), cov_matrix/2)\n",
    "    imag_part = np.random.multivariate_normal(np.zeros(Nr), cov_matrix/2)\n",
    "    return (real_part+1j*imag_part).reshape(Nr,1)\n",
    "\n",
    "def generate_data(Nr,Nt,length,H_channel,cov_matrix):\n",
    "    bits_sequence, x_sequence = generate_x_sequence(length, Nt)\n",
    "    n_sequence = np.empty((length,Nr,1), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        n_sequence[ii] = generate_noise(cov_matrix,Nr)\n",
    "    y_sequence = np.empty((Nr, length), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        s = np.dot(H_channel, x_sequence[:,ii].reshape(Nt,1))\n",
    "        y_sequence[:, ii] = (s + n_sequence[ii]).reshape(Nr)\n",
    "    return bits_sequence, x_sequence, y_sequence\n",
    "\n",
    "def whiten_matrix(cov_matrix, H):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    diagmatrix = np.sqrt(np.diag(eigenvalues))\n",
    "    whitening_matrix = np.linalg.inv(np.dot(eigenvectors, diagmatrix))\n",
    "    return np.dot(whitening_matrix, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training H_hat\n",
    "\n",
    "def bits2signals(bits):\n",
    "    # bits: input binary string with length of (4*Nt) \n",
    "    return np.array([qam16_modulation(bits[i:i+4]) for i in range(0, len(bits), 4)]).reshape(Nt,1)\n",
    "\n",
    "def calculate_layer1_training(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "    output = np.empty(dimension_layer1)\n",
    "    # calculate gradient components in layer1\n",
    "    gradients = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    gradient_component = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        # s_conjugate_transpose = s.conj().T\n",
    "        y = y.reshape(Nr, 1)\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        error_norm[index] = np.square(np.linalg.norm(error))\n",
    "        gradient_component[index] = np.dot(error, s.conj().T)\n",
    "\n",
    "    min_error_norm = np.min(error_norm)\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        value =  np.exp(-error_norm[index]+min_error_norm)\n",
    "        output[index] = value\n",
    "        gradients[index] = -value*(-gradient_component[index])\n",
    "    # print(output)\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "def layer2_matrix(n):\n",
    "    if n == 1:\n",
    "        return np.array([0,1])\n",
    "    else:\n",
    "        last_ = layer2_matrix(n-1)\n",
    "        half_cols_num = 2**(n-1)\n",
    "        first_row = np.concatenate((np.zeros(half_cols_num), np.ones(half_cols_num)))\n",
    "        remain_rows = np.hstack((last_, last_))\n",
    "        # print(remain_rows)\n",
    "        return np.vstack((first_row, remain_rows))\n",
    "\n",
    "\n",
    "def calculate_layer2_training(layer1_output, true_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = sum_prob_1/total_prob\n",
    "    # calculate gradient components in layer2\n",
    "    gradients = np.zeros(2**(4*Nt))\n",
    "    # print(output)\n",
    "    epsilon = 1e-10  # 为了防止log(0)的情况，添加一个小的常数\n",
    "    output = np.clip(output, epsilon, 1. - epsilon)\n",
    "    for ii in range(len(gradients)):\n",
    "        # gradient1 = true_output/output\n",
    "        # gradient2 = (np.ones(len(true_output))-true_output)/(np.ones(len(output))-output)\n",
    "        for jj in range(4*Nt):\n",
    "            gradient1 = true_output[jj]/output[jj]\n",
    "            gradient2 = (1-true_output[jj])/(1-output[jj])\n",
    "            gradient3 = A[jj][ii]/total_prob\n",
    "            gradient4 = sum_prob_1[jj]/np.square(total_prob)\n",
    "            # gradients for cross entropy\n",
    "            gradients[ii] += (-1/(4*Nt))*(gradient1-gradient2)*(gradient3-gradient4)\n",
    "            # gradients for MSE\n",
    "            # gradients[ii] += (1/(4*Nt))*2*(output[jj]-true_output[jj])*(gradient3-gradient4)\n",
    "\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "def calculate_square_error(layer2_output, true_sequence):\n",
    "    return np.linalg.norm(layer2_output-true_sequence)**2\n",
    "\n",
    "def calculate_cross_entropy(layer2_output, true_sequence):\n",
    "    epsilon = 1e-10  # 为了防止log(0)的情况，添加一个小的常数\n",
    "    layer2_output = np.clip(layer2_output, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -np.mean(true_sequence * np.log(layer2_output) + (1 - true_sequence) * np.log(1 - layer2_output))\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def calculate_cost_function(H_hat):\n",
    "    total_loss = 0\n",
    "    total_gradients = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    training_length = len(y_sequence[0])\n",
    "    for ii in range(training_length):\n",
    "        # print(ii)\n",
    "        true_sequence = ''.join(bits_sequence[ii*Nt+jj] for jj in range(Nt))\n",
    "        true_sequence = np.array([eval(ii) for ii in true_sequence])\n",
    "        layer1_output, layer1_gradients = calculate_layer1_training(H_hat, y_sequence[:, ii])\n",
    "        layer2_output, layer2_gradients = calculate_layer2_training(layer1_output, true_sequence)\n",
    "        total_loss += calculate_cross_entropy(layer2_output,true_sequence)\n",
    "        # SGD\n",
    "        if np.random.rand() < 0.9:\n",
    "            for jj in range(2**(4*Nt)):\n",
    "                total_gradients += (layer2_gradients[jj]*layer1_gradients[jj])\n",
    "    mean_loss = total_loss/training_length\n",
    "    return mean_loss, total_gradients\n",
    "\n",
    "\n",
    "def training(max_iter):\n",
    "    H_hat = np.sqrt(1/2)*(np.random.randn(Nr,Nt)+1j*np.random.randn(Nr,Nt))\n",
    "    # H_hat = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    # H_hat = np.copy(H_estimated)\n",
    "    momentum = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    last_loss = -100\n",
    "    mean_loss = -200\n",
    "    m = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    v = np.zeros((Nr,Nt))\n",
    "    for iter_num in range(max_iter):\n",
    "        # solve the gradient\n",
    "        mean_loss, total_gradients = calculate_cost_function(H_hat)\n",
    "        print(\"loss: \"+str(mean_loss))\n",
    "        if np.abs(last_loss-mean_loss) < 1e-4:\n",
    "            return H_hat, mean_loss\n",
    "        else:\n",
    "            last_loss = mean_loss\n",
    "\n",
    "        # update H_hat\n",
    "        momentum = (1-beta1)*total_gradients + beta1*momentum\n",
    "        H_hat -= alpha * momentum\n",
    "\n",
    "        # Adaptive momentum to update H_hat\n",
    "        # m = beta1*m + (1-beta1)*total_gradients # update biased first moment estimate\n",
    "        # gradients_square = np.abs(total_gradients)**2 # elementwise square of gradients matrix\n",
    "        # v = beta2*v + (1-beta2)*gradients_square # update biased second raw moment estimate\n",
    "        # m_hat = m/(1-beta1**(iter_num+1)) # compute bias-corrected first moment estimate\n",
    "        # v_hat = v/(1-beta2**(iter_num+1)) # compute bias-corrected second raw moment estimate\n",
    "        # print(\"v:\"+str(np.sqrt(v_hat)))\n",
    "        # H_hat -= alpha * m_hat / (np.sqrt(v_hat)+episilon) # update H_hat\n",
    "        # print(H_hat)\n",
    "    return H_hat, mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing QNN for detection\n",
    "def calculate_layer1_testing(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    output = np.zeros(dimension_layer1)\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        y = y.reshape(Nr,1)\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        error_norm[index] = np.square(np.linalg.norm(error))\n",
    "\n",
    "    min_error_norm = np.min(error_norm)\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        value =  np.exp(-error_norm[index]+min_error_norm)\n",
    "        output[index] = value\n",
    "    return output\n",
    "\n",
    "\n",
    "def calculate_layer2_testing(layer1_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = np.array([sum_prob_1[ii]/total_prob for ii in range(4*Nt)])\n",
    "    return output\n",
    "\n",
    "def detection(y, H_trained):\n",
    "    layer1_output = calculate_layer1_testing(H_trained, y)\n",
    "    layer2_output = calculate_layer2_testing(layer1_output)\n",
    "    detect_result = ''\n",
    "    for ii in range(len(layer2_output)):\n",
    "        if(layer2_output[ii]>0.5):\n",
    "            detect_result += '1'\n",
    "        else:\n",
    "            detect_result += '0'\n",
    "    return(detect_result)\n",
    "\n",
    "def count_differences(str1, str2):\n",
    "    return sum(a != b for a, b in zip(str1, str2))\n",
    "\n",
    "def calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing):\n",
    "    error = 0\n",
    "    for ii in range(len(y_sequence_testing[0])):\n",
    "        detect_result = detection(y_sequence_testing[:,ii], H_trained)\n",
    "        true_sequence = ''.join(bits_sequence_testing[ii*Nt+jj] for jj in range(Nt))\n",
    "        error += count_differences(detect_result, true_sequence)\n",
    "    BER = error/(len(y_sequence_testing[0])*len(detect_result))\n",
    "    return BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 0\n",
      "SD (estimated CSI): 0.1846923828125\n",
      "loss: 2.100889863611202\n",
      "loss: 0.9503643386496824\n",
      "loss: 1.016722793730889\n",
      "loss: 0.481412932256079\n",
      "loss: 0.3341971174717855\n",
      "loss: 0.3140032960035448\n",
      "loss: 0.30353676224327664\n",
      "loss: 0.2961837833225298\n",
      "loss: 0.2906025631884666\n",
      "loss: 0.28661651219321443\n",
      "loss: 0.2838448467828515\n",
      "loss: 0.28107542074245423\n",
      "loss: 0.2792787385282996\n",
      "loss: 0.27733561717266614\n",
      "loss: 0.27602814765707573\n",
      "loss: 0.2747692326871205\n",
      "loss: 0.2734137344681405\n",
      "loss: 0.2722415625300117\n",
      "loss: 0.2712203402954631\n",
      "loss: 0.2706669846288199\n",
      "loss: 0.2700854757185876\n",
      "loss: 0.269411737286479\n",
      "loss: 0.26874618616997353\n",
      "loss: 0.2682829691792162\n",
      "loss: 0.2678319010713694\n",
      "loss: 0.26758062682517164\n",
      "loss: 0.26699744153808214\n",
      "loss: 0.2666379606619592\n",
      "loss: 0.26655677080759355\n",
      "QNN: 0.1268310546875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 1\n",
      "SD (estimated CSI): 0.29736328125\n",
      "loss: 1.3403417405505025\n",
      "loss: 1.5353082480613056\n",
      "loss: 1.0609558867989106\n",
      "loss: 0.8334825129298754\n",
      "loss: 1.2748028024956664\n",
      "loss: 0.8106119468721463\n",
      "loss: 0.6356290009717341\n",
      "loss: 0.5537558774413043\n",
      "loss: 0.5013782052211179\n",
      "loss: 0.38817473085109117\n",
      "loss: 0.3049111142952685\n",
      "loss: 0.2739790163501338\n",
      "loss: 0.26709805889884686\n",
      "loss: 0.2631461013650325\n",
      "loss: 0.2608337830026989\n",
      "loss: 0.259183451377846\n",
      "loss: 0.25802607482603884\n",
      "loss: 0.25761259909970696\n",
      "loss: 0.256879197682499\n",
      "loss: 0.25636488580701294\n",
      "loss: 0.25605543874140296\n",
      "loss: 0.2556950539714298\n",
      "loss: 0.2554014595313687\n",
      "loss: 0.25516205641302586\n",
      "loss: 0.25498400585945746\n",
      "loss: 0.2549415534572646\n",
      "QNN: 0.1123046875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 2\n",
      "SD (estimated CSI): 0.2445068359375\n",
      "loss: 1.068563030871374\n",
      "loss: 0.6983847600428978\n",
      "loss: 0.5831457596927699\n",
      "loss: 0.5317361649982627\n",
      "loss: 0.5076803397734245\n",
      "loss: 0.5015293608812934\n",
      "loss: 0.45604611788665983\n",
      "loss: 0.4125430275072457\n",
      "loss: 0.3874342622612658\n",
      "loss: 0.37368050252788076\n",
      "loss: 0.3651957467507872\n",
      "loss: 0.35972001395832626\n",
      "loss: 0.35623874085043916\n",
      "loss: 0.3533325877937406\n",
      "loss: 0.3509781575278308\n",
      "loss: 0.3497432809068579\n",
      "loss: 0.34825463651481425\n",
      "loss: 0.3471291021142772\n",
      "loss: 0.34624619439987453\n",
      "loss: 0.34565771912504767\n",
      "loss: 0.3457705497775597\n",
      "loss: 0.344935253203351\n",
      "loss: 0.3447312898100117\n",
      "loss: 0.3447502156026609\n",
      "QNN: 0.1558837890625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 3\n",
      "SD (estimated CSI): 0.3040771484375\n",
      "loss: 1.2748325264869198\n",
      "loss: 0.824994476028588\n",
      "loss: 1.0057322606370587\n",
      "loss: 0.7806842768789802\n",
      "loss: 0.42866685329185117\n",
      "loss: 0.3681720219938542\n",
      "loss: 0.35325914152405224\n",
      "loss: 0.3411221632914409\n",
      "loss: 0.33172170466722745\n",
      "loss: 0.3250574758441855\n",
      "loss: 0.3184941854463475\n",
      "loss: 0.31313311135159616\n",
      "loss: 0.3085669341677779\n",
      "loss: 0.30562987584586876\n",
      "loss: 0.30319565976197793\n",
      "loss: 0.30138348609212867\n",
      "loss: 0.3000629995331702\n",
      "loss: 0.2992109095542789\n",
      "loss: 0.2978661099905101\n",
      "loss: 0.29723950623098355\n",
      "loss: 0.2966609158263624\n",
      "loss: 0.2965145785175796\n",
      "loss: 0.29625442280216574\n",
      "loss: 0.2960844176624083\n",
      "loss: 0.2960091003173384\n",
      "QNN: 0.1337890625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 4\n",
      "SD (estimated CSI): 0.3597412109375\n",
      "loss: 0.9063106457868548\n",
      "loss: 0.7236913390915716\n",
      "loss: 0.6759439186553773\n",
      "loss: 0.3921031932476942\n",
      "loss: 0.3361031360044899\n",
      "loss: 0.30990548975447585\n",
      "loss: 0.2949109503142731\n",
      "loss: 0.2844620988429862\n",
      "loss: 0.2768533962377626\n",
      "loss: 0.2708256301780783\n",
      "loss: 0.26645712252093917\n",
      "loss: 0.2628047303632312\n",
      "loss: 0.25972144663816554\n",
      "loss: 0.2566447883802128\n",
      "loss: 0.2543614728328269\n",
      "loss: 0.25203819235602953\n",
      "loss: 0.24997880741434178\n",
      "loss: 0.2483914093716332\n",
      "loss: 0.24711409245775418\n"
     ]
    }
   ],
   "source": [
    "for ii in range(len(SNR_list)):\n",
    "    SNR_dB = SNR_list[ii]\n",
    "    SNR = 10**(SNR_dB / 10)\n",
    "    \n",
    "    SD_performance = np.zeros(iter_num)\n",
    "    SD_performance_estimated = np.zeros(iter_num)\n",
    "    QNN_performance_128 = np.zeros(iter_num)\n",
    "\n",
    "    for jj in range(iter_num):\n",
    "        print(\"----------------------------current SNR_dB: \" +str(SNR_dB))\n",
    "        print(\"----------------------------current iter num: \" +str(jj))\n",
    "\n",
    "        H = H_list[jj] * np.sqrt(SNR)\n",
    "        cov = cov_list[0]\n",
    "        # cov = np.eye(Nr)\n",
    "\n",
    "        bits_sequence_testing, x_sequence_testing, y_sequence_testing = generate_data(Nr,Nt,1024,H,cov)\n",
    "        bits_sequence, x_sequence, y_sequence = generate_data(Nr,Nt,pilot_length,H,cov)\n",
    "        H_estimated = np.dot(y_sequence, np.linalg.pinv(x_sequence))\n",
    "        # print(\"估计信道\")\n",
    "        # print(H_estimated)\n",
    "\n",
    "        # SD_performance[jj] = sphere_decoding_BER(H, y_sequence_testing, bits_sequence_testing, 1)\n",
    "        # print(\"SD (perfect CSI): \"+str(SD_performance[jj]))\n",
    "\n",
    "\n",
    "        SD_performance_estimated[jj] = sphere_decoding_BER(H_estimated, y_sequence_testing, bits_sequence_testing, 100000)\n",
    "        print(\"SD (estimated CSI): \"+str(SD_performance_estimated[jj]))\n",
    "\n",
    "        H_w = whiten_matrix(cov, H)\n",
    "        # print(\"白化信道\")\n",
    "        # print(H_w)\n",
    "\n",
    "        H_trained, loss = training(max_iter)\n",
    "        BER = calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing)\n",
    "\n",
    "        # print(\"真实信道\")\n",
    "        # print(H)\n",
    "        # print(\"QNN信道\")\n",
    "        # print(H_trained)\n",
    "        # print(\"白化信道\")\n",
    "        # print(H_w)\n",
    "        \n",
    "\n",
    "        # save_BER[ii][jj] = BER\n",
    "\n",
    "        QNN_performance_128[jj] = BER\n",
    "        print(\"QNN: \"+str(BER))\n",
    "\n",
    "    # SD_mean_performance[ii] = np.mean(SD_performance)\n",
    "    SD_mean_performance_estimated[ii] = np.mean(SD_performance_estimated)\n",
    "    QNN_mean_performance_128[ii] = np.mean(QNN_performance_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33003495, -0.12032008,  0.40484119, -0.15513787],\n",
       "       [-0.12032008,  1.27876119, -0.41453419, -0.06953362],\n",
       "       [ 0.40484119, -0.41453419,  0.8246921 , -0.13861221],\n",
       "       [-0.15513787, -0.06953362, -0.13861221,  1.56651177]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
