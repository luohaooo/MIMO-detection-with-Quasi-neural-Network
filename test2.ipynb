{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "optimization by gradient descent (GD) and adaptive momentum (Adam)\n",
    "'''\n",
    "\n",
    "import numpy as np \n",
    "import random\n",
    "from scipy.optimize import minimize\n",
    "from sphere_decoding.sphereDecodingUseC import sphere_decoding_BER\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as time\n",
    "\n",
    "\n",
    "\n",
    "# generate signals for simulation\n",
    "def generate_random_bit_sequence(length):\n",
    "    return ''.join(random.choice('01') for _ in range(length))\n",
    "\n",
    "def qam16_modulation(binary_input):\n",
    "    mapping = {\n",
    "        '0000': (1+1j),\n",
    "        '0001': (1+3j),\n",
    "        '0010': (3+1j),\n",
    "        '0011': (3+3j),\n",
    "        '0100': (1-1j),\n",
    "        '0101': (1-3j),\n",
    "        '0110': (3-1j),\n",
    "        '0111': (3-3j),\n",
    "        '1000': (-1+1j),\n",
    "        '1001': (-1+3j),\n",
    "        '1010': (-3+1j),\n",
    "        '1011': (-3+3j),\n",
    "        '1100': (-1-1j),\n",
    "        '1101': (-1-3j),\n",
    "        '1110': (-3-1j),\n",
    "        '1111': (-3-3j)\n",
    "    }\n",
    "    return mapping.get(binary_input, \"Invalid binary input\")/np.sqrt(10)\n",
    "\n",
    "def generate_x_sequence(length, Nt):\n",
    "    total_bits_sequence = generate_random_bit_sequence(length*Nt*4)\n",
    "    bits_sequence = [total_bits_sequence[i:i+4] for i in range(0, len(total_bits_sequence), 4)]\n",
    "    x_sequence = [np.array([qam16_modulation(bits_sequence[i+j]) for j in range(Nt)]) for i in range(0, len(bits_sequence), Nt)]\n",
    "    return bits_sequence, x_sequence\n",
    "\n",
    "def generate_noise(SNR, Nr):\n",
    "    \"\"\"\n",
    "    生成具有指定信噪比和维度的复数高斯噪声向量。\n",
    "\n",
    "    :param SNR: 信噪比\n",
    "    :param Nr: 噪声向量的维度\n",
    "    :return: 调整后的噪声向量\n",
    "    \"\"\"\n",
    "    # 生成一个随机实数方阵 A\n",
    "    A = np.random.randn(Nr, Nr)\n",
    "\n",
    "    # 构造半正定矩阵 B\n",
    "    B = A @ A.T\n",
    "\n",
    "    # 计算 B 的迹并归一化\n",
    "    trace_B = np.trace(B)\n",
    "    cov_matrix = B / trace_B\n",
    "\n",
    "    # 生成标准复高斯噪声\n",
    "    noise = (np.random.normal(scale=np.sqrt(0.5), size=(Nr, 1)) +\n",
    "             1j * np.random.normal(scale=np.sqrt(0.5), size=(Nr, 1)))\n",
    "\n",
    "    # 计算协方差矩阵的平方根（Cholesky分解）\n",
    "    cov_matrix_sqrt = np.linalg.cholesky(cov_matrix)\n",
    "\n",
    "    # 应用协方差矩阵\n",
    "    adjusted_noise = cov_matrix_sqrt @ noise\n",
    "\n",
    "    # 计算调整后的噪声功率\n",
    "    noise_power_adjusted = np.mean(np.abs(adjusted_noise)**2)\n",
    "\n",
    "    # 计算需要的噪声调整因子以保持所需的SNR\n",
    "    adjust_factor = np.sqrt((1 / SNR) / noise_power_adjusted)\n",
    "\n",
    "    # 应用调整因子\n",
    "    adjusted_noise *= adjust_factor\n",
    "\n",
    "    return adjusted_noise\n",
    "\n",
    "def generate_data(Nr,Nt,SNR_dB,length,H_channel):\n",
    "    bits_sequence, x_sequence = generate_x_sequence(length, Nt)\n",
    "    SNR= 10**(SNR_dB/10)\n",
    "    n_sequence = [generate_noise(SNR, Nr) for i in range(length)]\n",
    "    y_sequence = [np.dot(H_channel, x_sequence[i].reshape(Nt,1)) + n_sequence[i] for i in range(length)]\n",
    "    return bits_sequence, x_sequence, y_sequence\n",
    "\n",
    "\n",
    "\n",
    "# training H_hat\n",
    "\n",
    "\n",
    "\n",
    "def bits2signals(bits):\n",
    "    # bits: input binary string with length of (4*Nt) \n",
    "    return np.array([qam16_modulation(bits[i:i+4]) for i in range(0, len(bits), 4)]).reshape(Nt,1)\n",
    "\n",
    "def calculate_layer1_training(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    output = np.empty(dimension_layer1)\n",
    "    # calculate gradient components in layer1\n",
    "    gradients = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        # s_conjugate_transpose = s.conj().T\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        value =  np.exp(-np.square(np.linalg.norm(error)))\n",
    "        output[index] = value\n",
    "        gradient_component = np.dot(error, s.conj().T)\n",
    "        gradients[index] = -value*(-gradient_component)\n",
    "    return output, gradients\n",
    "\n",
    "def layer2_matrix(n):\n",
    "    if n == 1:\n",
    "        return np.array([0,1])\n",
    "    else:\n",
    "        last_ = layer2_matrix(n-1)\n",
    "        half_cols_num = 2**(n-1)\n",
    "        first_row = np.concatenate((np.zeros(half_cols_num), np.ones(half_cols_num)))\n",
    "        remain_rows = np.hstack((last_, last_))\n",
    "        # print(remain_rows)\n",
    "        return np.vstack((first_row, remain_rows))\n",
    "\n",
    "\n",
    "def calculate_layer2_training(layer1_output, true_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = np.array([sum_prob_1[ii]/total_prob for ii in range(4*Nt)])\n",
    "    # calculate gradient components in layer2\n",
    "    gradients = np.zeros(2**(4*Nt))\n",
    "    for ii in range(len(gradients)):\n",
    "        for jj in range(4*Nt):\n",
    "            gradients[ii] += 2*(true_output[jj]-output[jj])*(-(A[jj][ii]/total_prob)+(sum_prob_1[jj]/np.square(total_prob)))\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "def calculate_square_error(layer2_output, true_sequence):\n",
    "    return np.linalg.norm(layer2_output-true_sequence)**2\n",
    "\n",
    "\n",
    "\n",
    "def calculate_cost_function(H_hat):\n",
    "    total_loss = 0\n",
    "    total_gradients = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    training_length = len(y_sequence)\n",
    "    for ii in range(training_length):\n",
    "        # print(ii)\n",
    "        true_sequence = ''.join(bits_sequence[ii*Nt+jj] for jj in range(Nt))\n",
    "        true_sequence = np.array([eval(ii) for ii in true_sequence])\n",
    "        layer1_output, layer1_gradients = calculate_layer1_training(H_hat, y_sequence[ii])\n",
    "        layer2_output, layer2_gradients = calculate_layer2_training(layer1_output, true_sequence)\n",
    "        total_loss += calculate_square_error(layer2_output,true_sequence)\n",
    "        # SGD\n",
    "        if np.random.rand() < 0.6:\n",
    "            for jj in range(2**(4*Nt)):\n",
    "                total_gradients += (layer2_gradients[jj]*layer1_gradients[jj])\n",
    "    mean_loss = total_loss/training_length\n",
    "    return mean_loss, total_gradients\n",
    "\n",
    "\n",
    "def training(max_iter):\n",
    "    H_hat = np.sqrt(1/2)*(np.random.randn(Nr,Nt)+1j*np.random.randn(Nr,Nt))\n",
    "    # H_hat = H\n",
    "    momentum = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    last_loss = -100\n",
    "    for iter_num in range(max_iter):\n",
    "        # solve the gradient\n",
    "        mean_loss, total_gradients = calculate_cost_function(H_hat)\n",
    "        if iter_num % 10 == 9:\n",
    "            print(\"loss: \"+str(mean_loss))\n",
    "            if np.abs(last_loss-mean_loss) < 0.01:\n",
    "                return H_hat\n",
    "            else:\n",
    "                last_loss = mean_loss\n",
    "        # update H_hat\n",
    "        momentum = (1-beta1)*total_gradients + beta1*momentum\n",
    "        # print(alpha * momentum)\n",
    "        # print(\"momentum norm: \"+str(np.log10(np.sum(np.square(np.abs(momentum))))))\n",
    "        H_hat -= alpha * momentum\n",
    "        # print(H_hat)\n",
    "\n",
    "    return H_hat\n",
    "\n",
    "\n",
    "\n",
    "# testing QNN for detection\n",
    "def calculate_layer1_testing(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    output = np.zeros(dimension_layer1)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        s_conjugate_transpose = s.conj().T\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        value =  np.exp(-np.square(np.linalg.norm(error)))\n",
    "        output[index] = value\n",
    "    return output\n",
    "\n",
    "def calculate_layer2_testing(layer1_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = np.array([sum_prob_1[ii]/total_prob for ii in range(4*Nt)])\n",
    "    return output\n",
    "\n",
    "def detection(y, H_trained):\n",
    "    layer1_output = calculate_layer1_testing(H_trained, y)\n",
    "    layer2_output = calculate_layer2_testing(layer1_output)\n",
    "    detect_result = ''\n",
    "    for ii in range(len(layer2_output)):\n",
    "        if(layer2_output[ii]>0.5):\n",
    "            detect_result += '1'\n",
    "        else:\n",
    "            detect_result += '0'\n",
    "    return(detect_result)\n",
    "\n",
    "def count_differences(str1, str2):\n",
    "    return sum(a != b for a, b in zip(str1, str2))\n",
    "\n",
    "def calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing):\n",
    "    error = 0\n",
    "    for ii in range(len(y_sequence_testing)):\n",
    "        detect_result = detection(y_sequence_testing[ii], H_trained)\n",
    "        true_sequence = ''.join(bits_sequence_testing[ii*Nt+jj] for jj in range(Nt))\n",
    "        error += count_differences(detect_result, true_sequence)\n",
    "    BER = error/(len(y_sequence_testing)*len(detect_result))\n",
    "    return BER\n",
    "\n",
    "\n",
    "# generate training and tesing data\n",
    "Nt = 2\n",
    "Nr = 4\n",
    "# generate channel\n",
    "\n",
    "iter_num = 30\n",
    "SNR_list = np.array([0, 5, 10, 15, 20, 25])\n",
    "\n",
    "# Adam paras\n",
    "alpha = 0.01\n",
    "# beta1 = 0.2 #momentum rate\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "pilot_length = 128\n",
    "\n",
    "beta1 = 0\n",
    "\n",
    "SD_mean_performance = np.zeros(len(SNR_list))\n",
    "QNN_mean_performance_128 = np.zeros(len(SNR_list))\n",
    "\n",
    "H_list = [np.sqrt(1/2)*(np.random.randn(Nr,Nt)+1j*np.random.randn(Nr,Nt)) for ii in range(iter_num)]\n",
    "\n",
    "for ii in range(len(SNR_list)):\n",
    "    SNR_dB = SNR_list[ii]\n",
    "    print(\"SNR_dB: \"+str(SNR_dB))\n",
    "    \n",
    "    SD_performance = np.zeros(iter_num)\n",
    "    QNN_performance_128 = np.zeros(iter_num)\n",
    "\n",
    "    \n",
    "\n",
    "    for jj in range(iter_num):\n",
    "        # print(\"current iter num: \" +str(jj))\n",
    "        H = H_list[jj]\n",
    "\n",
    "        bits_sequence_testing, x_sequence_testing, y_sequence_testing = generate_data(Nr,Nt,SNR_dB,1024,H)\n",
    "        SD_performance[jj] = sphere_decoding_BER(H, y_sequence_testing, bits_sequence_testing, 1)\n",
    "        print(\"SD: \"+str(SD_performance[jj]))\n",
    "\n",
    "        bits_sequence, x_sequence, y_sequence = generate_data(Nr,Nt,SNR_dB,pilot_length,H)\n",
    "        H_trained = training(max_iter)\n",
    "\n",
    "        BER = calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing)\n",
    "\n",
    "        QNN_performance_128[jj] = BER\n",
    "        print(\"QNN (beta=0.1): \"+str(BER))\n",
    "\n",
    "    SD_mean_performance[ii] = np.mean(SD_performance)\n",
    "    QNN_mean_performance_128[ii] = np.mean(QNN_performance_128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newqnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
