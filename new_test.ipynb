{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "from scipy.linalg import orth\n",
    "from sphere_decoding.new_sphereDecodingUseC import sphere_decoding_BER\n",
    "import matplotlib.pyplot as plt\n",
    "# from timeit import default_timer as time\n",
    "\n",
    "# 交叉熵正常训练\n",
    "\n",
    "\n",
    "Nt = 2\n",
    "Nr = 4\n",
    "\n",
    "iter_num = 30\n",
    "channel_list = np.load(\"channel_list_4_2.npy\")\n",
    "H_list = channel_list[0:iter_num]\n",
    "cov_list = np.load(\"covmatrix_list_4.npy\")\n",
    "\n",
    "SNR_list = np.array([10])\n",
    "\n",
    "\n",
    "# Adam\n",
    "# beta1 = 0.8 \n",
    "# beta2 = 0.999\n",
    "# episilon = 1e-8\n",
    "\n",
    "max_iter = 100\n",
    "\n",
    "pilot_length = 128\n",
    "\n",
    "beta1 = 0\n",
    "\n",
    "SD_mean_performance = np.zeros(len(SNR_list))\n",
    "SD_mean_performance_estimated = np.zeros(len(SNR_list))\n",
    "QNN_mean_performance_128 = np.zeros(len(SNR_list))\n",
    "\n",
    "save_loss = np.empty((len(SNR_list), iter_num))\n",
    "save_BER = np.empty((len(SNR_list), iter_num))\n",
    "save_channel = np.empty((len(SNR_list), iter_num, Nr, Nt), dtype=np.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate signals for simulation\n",
    "def generate_random_bit_sequence(length):\n",
    "    return ''.join(random.choice('01') for _ in range(length))\n",
    "\n",
    "def qam16_modulation(binary_input):\n",
    "    mapping = {\n",
    "        '0000': (1+1j),\n",
    "        '0001': (1+3j),\n",
    "        '0010': (3+1j),\n",
    "        '0011': (3+3j),\n",
    "        '0100': (1-1j),\n",
    "        '0101': (1-3j),\n",
    "        '0110': (3-1j),\n",
    "        '0111': (3-3j),\n",
    "        '1000': (-1+1j),\n",
    "        '1001': (-1+3j),\n",
    "        '1010': (-3+1j),\n",
    "        '1011': (-3+3j),\n",
    "        '1100': (-1-1j),\n",
    "        '1101': (-1-3j),\n",
    "        '1110': (-3-1j),\n",
    "        '1111': (-3-3j)\n",
    "    }\n",
    "    return mapping.get(binary_input, \"Invalid binary input\")/np.sqrt(10)\n",
    "\n",
    "def generate_x_sequence(length, Nt):\n",
    "    total_bits_sequence = generate_random_bit_sequence(length*Nt*4)\n",
    "    bits_sequence = [total_bits_sequence[i:i+4] for i in range(0, len(total_bits_sequence), 4)]\n",
    "    x_sequence = np.empty((Nt, length), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        x_sequence[:,ii] = [qam16_modulation(bits_sequence[ii*Nt+jj]) for jj in range(Nt)]\n",
    "    return bits_sequence, x_sequence\n",
    "\n",
    "def generate_channel(SNR):\n",
    "    return np.sqrt(SNR)*H_list\n",
    "\n",
    "def generate_covmatrix(dimension):\n",
    "    U = orth(np.random.randn(dimension,dimension))\n",
    "    x = np.random.rand(dimension)\n",
    "    x = (x/np.sum(x))*dimension\n",
    "    V = np.diag(x)\n",
    "    whitening_matrix = np.dot(U, np.sqrt(V))\n",
    "    cov_matrix = np.dot(whitening_matrix, whitening_matrix.conj().T)\n",
    "    return cov_matrix\n",
    "\n",
    "def generate_noise(cov_matrix,Nr):\n",
    "    real_part = np.random.multivariate_normal(np.zeros(Nr), cov_matrix/2)\n",
    "    imag_part = np.random.multivariate_normal(np.zeros(Nr), cov_matrix/2)\n",
    "    return (real_part+1j*imag_part).reshape(Nr,1)\n",
    "\n",
    "def generate_data(Nr,Nt,length,H_channel,cov_matrix):\n",
    "    bits_sequence, x_sequence = generate_x_sequence(length, Nt)\n",
    "    n_sequence = np.empty((length,Nr,1), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        n_sequence[ii] = generate_noise(cov_matrix,Nr)\n",
    "    y_sequence = np.empty((Nr, length), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        s = np.dot(H_channel, x_sequence[:,ii].reshape(Nt,1))\n",
    "        y_sequence[:, ii] = (s + n_sequence[ii]).reshape(Nr)\n",
    "    return bits_sequence, x_sequence, y_sequence\n",
    "\n",
    "def whiten_matrix(cov_matrix, H):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    diagmatrix = np.sqrt(np.diag(eigenvalues))\n",
    "    whitening_matrix = np.linalg.inv(np.dot(eigenvectors, diagmatrix))\n",
    "    return np.dot(whitening_matrix, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training H_hat\n",
    "\n",
    "def bits2signals(bits):\n",
    "    # bits: input binary string with length of (4*Nt) \n",
    "    return np.array([qam16_modulation(bits[i:i+4]) for i in range(0, len(bits), 4)]).reshape(Nt,1)\n",
    "\n",
    "def calculate_layer1_training(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "    output = np.empty(dimension_layer1)\n",
    "    # calculate gradient components in layer1\n",
    "    gradients = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    gradient_component = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        # s_conjugate_transpose = s.conj().T\n",
    "        y = y.reshape(Nr, 1)\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        error_norm[index] = np.square(np.linalg.norm(error))\n",
    "        gradient_component[index] = np.dot(error, s.conj().T)\n",
    "\n",
    "    min_error_norm = np.min(error_norm)\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        value =  np.exp(-error_norm[index]+min_error_norm)\n",
    "        output[index] = value\n",
    "        gradients[index] = -value*(-gradient_component[index])\n",
    "    # print(output)\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "def layer2_matrix(n):\n",
    "    if n == 1:\n",
    "        return np.array([0,1])\n",
    "    else:\n",
    "        last_ = layer2_matrix(n-1)\n",
    "        half_cols_num = 2**(n-1)\n",
    "        first_row = np.concatenate((np.zeros(half_cols_num), np.ones(half_cols_num)))\n",
    "        remain_rows = np.hstack((last_, last_))\n",
    "        # print(remain_rows)\n",
    "        return np.vstack((first_row, remain_rows))\n",
    "\n",
    "\n",
    "def calculate_layer2_training(layer1_output, true_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = sum_prob_1/total_prob\n",
    "    # calculate gradient components in layer2\n",
    "    gradients = np.zeros(2**(4*Nt))\n",
    "    # print(output)\n",
    "    epsilon = 1e-10  # 为了防止log(0)的情况，添加一个小的常数\n",
    "    output = np.clip(output, epsilon, 1. - epsilon)\n",
    "    for ii in range(len(gradients)):\n",
    "        # gradient1 = true_output/output\n",
    "        # gradient2 = (np.ones(len(true_output))-true_output)/(np.ones(len(output))-output)\n",
    "        for jj in range(4*Nt):\n",
    "            gradient1 = true_output[jj]/output[jj]\n",
    "            gradient2 = (1-true_output[jj])/(1-output[jj])\n",
    "            gradient3 = A[jj][ii]/total_prob\n",
    "            gradient4 = sum_prob_1[jj]/np.square(total_prob)\n",
    "            # gradients for cross entropy\n",
    "            gradients[ii] += (-1/(4*Nt))*(gradient1-gradient2)*(gradient3-gradient4)\n",
    "            # gradients for MSE\n",
    "            # gradients[ii] += (1/(4*Nt))*2*(output[jj]-true_output[jj])*(gradient3-gradient4)\n",
    "\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "def calculate_square_error(layer2_output, true_sequence):\n",
    "    return np.linalg.norm(layer2_output-true_sequence)**2\n",
    "\n",
    "def calculate_cross_entropy(layer2_output, true_sequence):\n",
    "    epsilon = 1e-10  # 为了防止log(0)的情况，添加一个小的常数\n",
    "    layer2_output = np.clip(layer2_output, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -np.mean(true_sequence * np.log(layer2_output) + (1 - true_sequence) * np.log(1 - layer2_output))\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def calculate_cost_function(H_hat):\n",
    "    total_loss = 0\n",
    "    total_gradients = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    training_length = len(y_sequence[0])\n",
    "    for ii in range(training_length):\n",
    "        # print(ii)\n",
    "        true_sequence = ''.join(bits_sequence[ii*Nt+jj] for jj in range(Nt))\n",
    "        true_sequence = np.array([eval(ii) for ii in true_sequence])\n",
    "        layer1_output, layer1_gradients = calculate_layer1_training(H_hat, y_sequence[:, ii])\n",
    "        layer2_output, layer2_gradients = calculate_layer2_training(layer1_output, true_sequence)\n",
    "        total_loss += calculate_cross_entropy(layer2_output,true_sequence)\n",
    "        # SGD\n",
    "        if np.random.rand() < 0.9:\n",
    "            for jj in range(2**(4*Nt)):\n",
    "                total_gradients += (layer2_gradients[jj]*layer1_gradients[jj])\n",
    "    mean_loss = total_loss/training_length\n",
    "    return mean_loss, total_gradients\n",
    "\n",
    "\n",
    "def training(max_iter):\n",
    "    H_hat = np.sqrt(1/2)*(np.random.randn(Nr,Nt)+1j*np.random.randn(Nr,Nt))\n",
    "    # H_hat = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    # H_hat = np.copy(H_estimated)\n",
    "    momentum = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    last_loss = -100\n",
    "    mean_loss = -200\n",
    "    m = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    v = np.zeros((Nr,Nt))\n",
    "    for iter_num in range(max_iter):\n",
    "        # solve the gradient\n",
    "        mean_loss, total_gradients = calculate_cost_function(H_hat)\n",
    "        print(\"loss: \"+str(mean_loss))\n",
    "        if np.abs(last_loss-mean_loss) < 1e-4  and mean_loss < 1:\n",
    "            return H_hat, mean_loss\n",
    "        else:\n",
    "            last_loss = mean_loss\n",
    "        # update H_hat\n",
    "        momentum = (1-beta1)*total_gradients + beta1*momentum\n",
    "        H_hat -= alpha * momentum\n",
    "\n",
    "        # Adaptive momentum to update H_hat\n",
    "        # m = beta1*m + (1-beta1)*total_gradients # update biased first moment estimate\n",
    "        # gradients_square = np.abs(total_gradients)**2 # elementwise square of gradients matrix\n",
    "        # v = beta2*v + (1-beta2)*gradients_square # update biased second raw moment estimate\n",
    "        # m_hat = m/(1-beta1**(iter_num+1)) # compute bias-corrected first moment estimate\n",
    "        # v_hat = v/(1-beta2**(iter_num+1)) # compute bias-corrected second raw moment estimate\n",
    "        # print(\"v:\"+str(np.sqrt(v_hat)))\n",
    "        # H_hat -= alpha * m_hat / (np.sqrt(v_hat)+episilon) # update H_hat\n",
    "        # print(H_hat)\n",
    "    return training(max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing QNN for detection\n",
    "def calculate_layer1_testing(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    output = np.zeros(dimension_layer1)\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        y = y.reshape(Nr,1)\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        error_norm[index] = np.square(np.linalg.norm(error))\n",
    "\n",
    "    min_error_norm = np.min(error_norm)\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        value =  np.exp(-error_norm[index]+min_error_norm)\n",
    "        output[index] = value\n",
    "    return output\n",
    "\n",
    "\n",
    "def calculate_layer2_testing(layer1_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = np.array([sum_prob_1[ii]/total_prob for ii in range(4*Nt)])\n",
    "    return output\n",
    "\n",
    "def detection(y, H_trained):\n",
    "    layer1_output = calculate_layer1_testing(H_trained, y)\n",
    "    layer2_output = calculate_layer2_testing(layer1_output)\n",
    "    detect_result = ''\n",
    "    for ii in range(len(layer2_output)):\n",
    "        if(layer2_output[ii]>0.5):\n",
    "            detect_result += '1'\n",
    "        else:\n",
    "            detect_result += '0'\n",
    "    return(detect_result)\n",
    "\n",
    "def count_differences(str1, str2):\n",
    "    return sum(a != b for a, b in zip(str1, str2))\n",
    "\n",
    "def calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing):\n",
    "    error = 0\n",
    "    for ii in range(len(y_sequence_testing[0])):\n",
    "        detect_result = detection(y_sequence_testing[:,ii], H_trained)\n",
    "        true_sequence = ''.join(bits_sequence_testing[ii*Nt+jj] for jj in range(Nt))\n",
    "        error += count_differences(detect_result, true_sequence)\n",
    "    BER = error/(len(y_sequence_testing[0])*len(detect_result))\n",
    "    return BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 0\n",
      "SD (estimated CSI): 0.0186767578125\n",
      "loss: 2.5909248349054907\n",
      "loss: 2.8821210786839866\n",
      "loss: 1.1047330222192933\n",
      "loss: 1.2125590938515518\n",
      "loss: 0.4654490930833626\n",
      "loss: 0.06175034480188487\n",
      "loss: 0.02650427571571808\n",
      "loss: 0.02365480153378772\n",
      "loss: 0.022615777489986593\n",
      "loss: 0.021083082222853405\n",
      "loss: 0.020039500328550446\n",
      "loss: 0.01947529159818148\n",
      "loss: 0.01909544811481202\n",
      "loss: 0.018901729004999694\n",
      "loss: 0.018674835895025364\n",
      "loss: 0.018502488317749692\n",
      "loss: 0.018308504436374336\n",
      "loss: 0.018210435121776967\n",
      "QNN: 0.00732421875\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 1\n",
      "SD (estimated CSI): 0.112060546875\n",
      "loss: 3.6153150916530947\n",
      "loss: 5.695641618966915\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 36\u001b[0m\n\u001b[0;32m     32\u001b[0m H_w \u001b[38;5;241m=\u001b[39m whiten_matrix(cov, H)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# print(\"白化信道\")\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# print(H_w)\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m H_trained, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m BER \u001b[38;5;241m=\u001b[39m calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# print(\"真实信道\")\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# print(H)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# print(\"QNN信道\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# save_BER[ii][jj] = BER\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[43], line 114\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(max_iter)\u001b[0m\n\u001b[0;32m    111\u001b[0m v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((Nr,Nt))\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# solve the gradient\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     mean_loss, total_gradients \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_cost_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(mean_loss))\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mabs(last_loss\u001b[38;5;241m-\u001b[39mmean_loss) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-4\u001b[39m  \u001b[38;5;129;01mand\u001b[39;00m mean_loss \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[1;32mIn[43], line 92\u001b[0m, in \u001b[0;36mcalculate_cost_function\u001b[1;34m(H_hat)\u001b[0m\n\u001b[0;32m     90\u001b[0m true_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(bits_sequence[ii\u001b[38;5;241m*\u001b[39mNt\u001b[38;5;241m+\u001b[39mjj] \u001b[38;5;28;01mfor\u001b[39;00m jj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Nt))\n\u001b[0;32m     91\u001b[0m true_sequence \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28meval\u001b[39m(ii) \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m true_sequence])\n\u001b[1;32m---> 92\u001b[0m layer1_output, layer1_gradients \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_layer1_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m layer2_output, layer2_gradients \u001b[38;5;241m=\u001b[39m calculate_layer2_training(layer1_output, true_sequence)\n\u001b[0;32m     94\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m calculate_cross_entropy(layer2_output,true_sequence)\n",
      "Cell \u001b[1;32mIn[43], line 21\u001b[0m, in \u001b[0;36mcalculate_layer1_training\u001b[1;34m(H_hat, y)\u001b[0m\n\u001b[0;32m     19\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(Nr, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m     error \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(H_hat,s)\n\u001b[1;32m---> 21\u001b[0m     error_norm[index] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msquare(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m     gradient_component[index] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(error, s\u001b[38;5;241m.\u001b[39mconj()\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     24\u001b[0m min_error_norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(error_norm)\n",
      "File \u001b[1;32mc:\\Users\\29265\\anaconda3\\envs\\py39\\lib\\site-packages\\numpy\\linalg\\linalg.py:2550\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2548\u001b[0m     x_real \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreal\n\u001b[0;32m   2549\u001b[0m     x_imag \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mimag\n\u001b[1;32m-> 2550\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m \u001b[43mx_real\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_real\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m x_imag\u001b[38;5;241m.\u001b[39mdot(x_imag)\n\u001b[0;32m   2551\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2552\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdot(x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ii in range(len(SNR_list)):\n",
    "    SNR_dB = SNR_list[ii]\n",
    "    SNR = 10**(SNR_dB / 10)\n",
    "    \n",
    "    SD_performance = np.zeros(iter_num)\n",
    "    SD_performance_estimated = np.zeros(iter_num)\n",
    "    QNN_performance_128 = np.zeros(iter_num)\n",
    "\n",
    "    alpha = 0.005*SNR\n",
    "\n",
    "    for jj in range(iter_num):\n",
    "        print(\"----------------------------current SNR_dB: \" +str(SNR_dB))\n",
    "        print(\"----------------------------current iter num: \" +str(jj))\n",
    "\n",
    "        H = H_list[jj] * np.sqrt(SNR)\n",
    "        # cov = cov_list[0]\n",
    "        cov = np.eye(Nr)\n",
    "\n",
    "        bits_sequence_testing, x_sequence_testing, y_sequence_testing = generate_data(Nr,Nt,1024,H,cov)\n",
    "        bits_sequence, x_sequence, y_sequence = generate_data(Nr,Nt,pilot_length,H,cov)\n",
    "        H_estimated = np.dot(y_sequence, np.linalg.pinv(x_sequence))\n",
    "        # print(\"估计信道\")\n",
    "        # print(H_estimated)\n",
    "\n",
    "        # SD_performance[jj] = sphere_decoding_BER(H, y_sequence_testing, bits_sequence_testing, 1)\n",
    "        # print(\"SD (perfect CSI): \"+str(SD_performance[jj]))\n",
    "\n",
    "\n",
    "        SD_performance_estimated[jj] = sphere_decoding_BER(H_estimated, y_sequence_testing, bits_sequence_testing, 10000)\n",
    "        print(\"SD (estimated CSI): \"+str(SD_performance_estimated[jj]))\n",
    "\n",
    "        H_w = whiten_matrix(cov, H)\n",
    "        # print(\"白化信道\")\n",
    "        # print(H_w)\n",
    "\n",
    "        H_trained, loss = training(max_iter)\n",
    "        BER = calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing)\n",
    "\n",
    "        # print(\"真实信道\")\n",
    "        # print(H)\n",
    "        # print(\"QNN信道\")\n",
    "        # print(H_trained)\n",
    "        # print(\"白化信道\")\n",
    "        # print(H_w)\n",
    "        \n",
    "\n",
    "        # save_BER[ii][jj] = BER\n",
    "\n",
    "        QNN_performance_128[jj] = BER\n",
    "        print(\"QNN: \"+str(BER))\n",
    "\n",
    "    # SD_mean_performance[ii] = np.mean(SD_performance)\n",
    "    SD_mean_performance_estimated[ii] = np.mean(SD_performance_estimated)\n",
    "    QNN_mean_performance_128[ii] = np.mean(QNN_performance_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "lns1 = ax1.plot(SNR_list, SD_mean_performance_estimated, '-ro', linewidth=2.0, label=\"Max Log (estimated CSI)\")\n",
    "lns2 = ax1.plot(SNR_list, QNN_mean_performance_128, '-bo', linewidth=2.0, label=\"QNN Decoding (128 pilot)\")\n",
    "\n",
    "\n",
    "\n",
    "lns = lns1+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, loc=\"lower left\")\n",
    "\n",
    "# ax1.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs='auto'))\n",
    "# ax1.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "# ax1.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
    "\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax1.set_xticks(SNR_list)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_adjustable(\"datalim\")\n",
    "ax1.set_xlim(-0.5,16.5)\n",
    "ax1.set_ylim(1e-4, 0.8)\n",
    "ax1.set_ylabel(\"BER\")\n",
    "ax1.set_xlabel(\"SNR(dB)\")\n",
    "plt.title(\"covariance matrix = I\")\n",
    "\n",
    "# plt.savefig('BER.png',dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
