{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "from scipy.linalg import orth\n",
    "from sphere_decoding.new_sphereDecodingUseC import sphere_decoding_BER\n",
    "import matplotlib.pyplot as plt\n",
    "# from timeit import default_timer as time\n",
    "\n",
    "# 交叉熵正常训练\n",
    "\n",
    "\n",
    "Nt = 2\n",
    "Nr = 4\n",
    "\n",
    "iter_num = 30\n",
    "channel_list = np.load(\"channel_list_4_2.npy\")\n",
    "H_list = channel_list[0:iter_num]\n",
    "cov_list = np.load(\"covmatrix_list_4.npy\")\n",
    "\n",
    "SNR_list = np.array([0,4,8,12,16])\n",
    "\n",
    "\n",
    "# Adam\n",
    "# beta1 = 0.8 \n",
    "# beta2 = 0.999\n",
    "# episilon = 1e-8\n",
    "\n",
    "max_iter = 100\n",
    "\n",
    "pilot_length = 128\n",
    "\n",
    "beta1 = 0\n",
    "\n",
    "# SD_mean_performance = np.zeros(len(SNR_list))\n",
    "# SD_mean_performance_estimated = np.zeros(len(SNR_list))\n",
    "MAP_mean_performance = np.zeros(len(SNR_list))\n",
    "MaxLog_mean_performance = np.zeros(len(SNR_list))\n",
    "QNN_mean_performance_128 = np.zeros(len(SNR_list))\n",
    "\n",
    "save_loss = np.empty((len(SNR_list), iter_num))\n",
    "save_BER = np.empty((len(SNR_list), iter_num))\n",
    "save_channel = np.empty((len(SNR_list), iter_num, Nr, Nt), dtype=np.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate signals for simulation\n",
    "def generate_random_bit_sequence(length):\n",
    "    return ''.join(random.choice('01') for _ in range(length))\n",
    "\n",
    "def qam16_modulation(binary_input):\n",
    "    mapping = {\n",
    "        '0000': (1+1j),\n",
    "        '0001': (1+3j),\n",
    "        '0010': (3+1j),\n",
    "        '0011': (3+3j),\n",
    "        '0100': (1-1j),\n",
    "        '0101': (1-3j),\n",
    "        '0110': (3-1j),\n",
    "        '0111': (3-3j),\n",
    "        '1000': (-1+1j),\n",
    "        '1001': (-1+3j),\n",
    "        '1010': (-3+1j),\n",
    "        '1011': (-3+3j),\n",
    "        '1100': (-1-1j),\n",
    "        '1101': (-1-3j),\n",
    "        '1110': (-3-1j),\n",
    "        '1111': (-3-3j)\n",
    "    }\n",
    "    return mapping.get(binary_input, \"Invalid binary input\")/np.sqrt(10)\n",
    "\n",
    "def generate_x_sequence(length, Nt):\n",
    "    total_bits_sequence = generate_random_bit_sequence(length*Nt*4)\n",
    "    bits_sequence = [total_bits_sequence[i:i+4] for i in range(0, len(total_bits_sequence), 4)]\n",
    "    x_sequence = np.empty((Nt, length), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        x_sequence[:,ii] = [qam16_modulation(bits_sequence[ii*Nt+jj]) for jj in range(Nt)]\n",
    "    return bits_sequence, x_sequence\n",
    "\n",
    "def generate_channel(SNR):\n",
    "    return np.sqrt(SNR)*H_list\n",
    "\n",
    "def generate_covmatrix(dimension):\n",
    "    U = orth(np.random.randn(dimension,dimension))\n",
    "    x = np.random.rand(dimension)\n",
    "    x = (x/np.sum(x))*dimension\n",
    "    V = np.diag(x)\n",
    "    whitening_matrix = np.dot(U, np.sqrt(V))\n",
    "    cov_matrix = np.dot(whitening_matrix, whitening_matrix.conj().T)\n",
    "    return cov_matrix\n",
    "\n",
    "def generate_noise(cov_matrix,Nr):\n",
    "    real_part = np.random.multivariate_normal(np.zeros(Nr), cov_matrix/2)\n",
    "    imag_part = np.random.multivariate_normal(np.zeros(Nr), cov_matrix/2)\n",
    "    return (real_part+1j*imag_part).reshape(Nr,1)\n",
    "\n",
    "def generate_data(Nr,Nt,length,H_channel,cov_matrix):\n",
    "    bits_sequence, x_sequence = generate_x_sequence(length, Nt)\n",
    "    n_sequence = np.empty((length,Nr,1), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        n_sequence[ii] = generate_noise(cov_matrix,Nr)\n",
    "    y_sequence = np.empty((Nr, length), dtype=np.complex128)\n",
    "    for ii in range(length):\n",
    "        s = np.dot(H_channel, x_sequence[:,ii].reshape(Nt,1))\n",
    "        y_sequence[:, ii] = (s + n_sequence[ii]).reshape(Nr)\n",
    "    return bits_sequence, x_sequence, y_sequence\n",
    "\n",
    "def whiten_matrix(cov_matrix, H):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    diagmatrix = np.sqrt(np.diag(eigenvalues))\n",
    "    whitening_matrix = np.linalg.inv(np.dot(eigenvectors, diagmatrix))\n",
    "    return np.dot(whitening_matrix, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training H_hat\n",
    "\n",
    "def bits2signals(bits):\n",
    "    # bits: input binary string with length of (4*Nt) \n",
    "    return np.array([qam16_modulation(bits[i:i+4]) for i in range(0, len(bits), 4)]).reshape(Nt,1)\n",
    "\n",
    "def calculate_layer1_training(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "    output = np.empty(dimension_layer1)\n",
    "    # calculate gradient components in layer1\n",
    "    gradients = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    gradient_component = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        # s_conjugate_transpose = s.conj().T\n",
    "        y = y.reshape(Nr, 1)\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        error_norm[index] = np.square(np.linalg.norm(error))\n",
    "        gradient_component[index] = np.dot(error, s.conj().T)\n",
    "\n",
    "    min_error_norm = np.min(error_norm)\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        value =  np.exp(-error_norm[index]+min_error_norm)\n",
    "        output[index] = value\n",
    "        gradients[index] = -value*(-gradient_component[index])\n",
    "    # print(output)\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "def layer2_matrix(n):\n",
    "    if n == 1:\n",
    "        return np.array([0,1])\n",
    "    else:\n",
    "        last_ = layer2_matrix(n-1)\n",
    "        half_cols_num = 2**(n-1)\n",
    "        first_row = np.concatenate((np.zeros(half_cols_num), np.ones(half_cols_num)))\n",
    "        remain_rows = np.hstack((last_, last_))\n",
    "        # print(remain_rows)\n",
    "        return np.vstack((first_row, remain_rows))\n",
    "\n",
    "\n",
    "def calculate_layer2_training(layer1_output, true_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = sum_prob_1/total_prob\n",
    "    # calculate gradient components in layer2\n",
    "    gradients = np.zeros(2**(4*Nt))\n",
    "    # print(output)\n",
    "    epsilon = 1e-10  # 为了防止log(0)的情况，添加一个小的常数\n",
    "    output = np.clip(output, epsilon, 1. - epsilon)\n",
    "    for ii in range(len(gradients)):\n",
    "        # gradient1 = true_output/output\n",
    "        # gradient2 = (np.ones(len(true_output))-true_output)/(np.ones(len(output))-output)\n",
    "        for jj in range(4*Nt):\n",
    "            gradient1 = true_output[jj]/output[jj]\n",
    "            gradient2 = (1-true_output[jj])/(1-output[jj])\n",
    "            gradient3 = A[jj][ii]/total_prob\n",
    "            gradient4 = sum_prob_1[jj]/np.square(total_prob)\n",
    "            # gradients for cross entropy\n",
    "            gradients[ii] += (-1/(4*Nt))*(gradient1-gradient2)*(gradient3-gradient4)\n",
    "            # gradients for MSE\n",
    "            # gradients[ii] += (1/(4*Nt))*2*(output[jj]-true_output[jj])*(gradient3-gradient4)\n",
    "\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "def calculate_square_error(layer2_output, true_sequence):\n",
    "    return np.linalg.norm(layer2_output-true_sequence)**2\n",
    "\n",
    "def calculate_cross_entropy(layer2_output, true_sequence):\n",
    "    epsilon = 1e-10  # 为了防止log(0)的情况，添加一个小的常数\n",
    "    layer2_output = np.clip(layer2_output, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -np.mean(true_sequence * np.log(layer2_output) + (1 - true_sequence) * np.log(1 - layer2_output))\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def calculate_cost_function(H_hat):\n",
    "    total_loss = 0\n",
    "    total_gradients = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    training_length = len(y_sequence[0])\n",
    "    for ii in range(training_length):\n",
    "        # print(ii)\n",
    "        true_sequence = ''.join(bits_sequence[ii*Nt+jj] for jj in range(Nt))\n",
    "        true_sequence = np.array([eval(ii) for ii in true_sequence])\n",
    "        layer1_output, layer1_gradients = calculate_layer1_training(H_hat, y_sequence[:, ii])\n",
    "        layer2_output, layer2_gradients = calculate_layer2_training(layer1_output, true_sequence)\n",
    "        total_loss += calculate_cross_entropy(layer2_output,true_sequence)\n",
    "        # SGD\n",
    "        if np.random.rand() < 0.9:\n",
    "            for jj in range(2**(4*Nt)):\n",
    "                total_gradients += (layer2_gradients[jj]*layer1_gradients[jj])\n",
    "    mean_loss = total_loss/training_length\n",
    "    return mean_loss, total_gradients\n",
    "\n",
    "\n",
    "def training(max_iter):\n",
    "    H_hat = np.sqrt(1/2)*(np.random.randn(Nr,Nt)+1j*np.random.randn(Nr,Nt))\n",
    "    # H_hat = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    # H_hat = np.copy(H_estimated)\n",
    "    momentum = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    last_loss = -100\n",
    "    mean_loss = -200\n",
    "    m = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    v = np.zeros((Nr,Nt))\n",
    "    for iter_num in range(max_iter):\n",
    "        # solve the gradient\n",
    "        mean_loss, total_gradients = calculate_cost_function(H_hat)\n",
    "        print(\"loss: \"+str(mean_loss))\n",
    "        if np.abs(last_loss-mean_loss) < 1e-4  and mean_loss < 1 and iter_num > 29:\n",
    "            return H_hat, mean_loss\n",
    "        if np.abs(last_loss-mean_loss) < 1e-4  and mean_loss > 1:\n",
    "            return training(max_iter)\n",
    "        else:\n",
    "            last_loss = mean_loss\n",
    "        # update H_hat\n",
    "        momentum = (1-beta1)*total_gradients + beta1*momentum\n",
    "        H_hat -= alpha * momentum\n",
    "\n",
    "        # Adaptive momentum to update H_hat\n",
    "        # m = beta1*m + (1-beta1)*total_gradients # update biased first moment estimate\n",
    "        # gradients_square = np.abs(total_gradients)**2 # elementwise square of gradients matrix\n",
    "        # v = beta2*v + (1-beta2)*gradients_square # update biased second raw moment estimate\n",
    "        # m_hat = m/(1-beta1**(iter_num+1)) # compute bias-corrected first moment estimate\n",
    "        # v_hat = v/(1-beta2**(iter_num+1)) # compute bias-corrected second raw moment estimate\n",
    "        # print(\"v:\"+str(np.sqrt(v_hat)))\n",
    "        # H_hat -= alpha * m_hat / (np.sqrt(v_hat)+episilon) # update H_hat\n",
    "        # print(H_hat)\n",
    "    return training(max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing QNN for detection\n",
    "def calculate_layer1_testing(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    output = np.zeros(dimension_layer1)\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        y = y.reshape(Nr,1)\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        error_norm[index] = np.square(np.linalg.norm(error))\n",
    "\n",
    "    min_error_norm = np.min(error_norm)\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        value =  np.exp(-error_norm[index]+min_error_norm)\n",
    "        output[index] = value\n",
    "    return output\n",
    "\n",
    "\n",
    "def calculate_layer2_testing(layer1_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = np.array([sum_prob_1[ii]/total_prob for ii in range(4*Nt)])\n",
    "    return output\n",
    "\n",
    "def detection_QNN(y, H_trained):\n",
    "    layer1_output = calculate_layer1_testing(H_trained, y)\n",
    "    layer2_output = calculate_layer2_testing(layer1_output)\n",
    "    QNN_detect_result = ''\n",
    "    for ii in range(len(layer2_output)):\n",
    "        if(layer2_output[ii]>0.5):\n",
    "            QNN_detect_result += '1'\n",
    "        else:\n",
    "            QNN_detect_result += '0'\n",
    "    return QNN_detect_result\n",
    "\n",
    "\n",
    "def detection_MAP_MaxLog(H_estimated, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    error_norm = np.empty(dimension_layer1)\n",
    "\n",
    "    min_error_norm_1 = np.ones(4*Nt)*10000\n",
    "    min_error_norm_0 = np.ones(4*Nt)*10000\n",
    "\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        y = y.reshape(Nr,1)\n",
    "        error = y - np.dot(H_estimated, s)\n",
    "        error_norm_value = np.square(np.linalg.norm(error))\n",
    "        error_norm[index] = error_norm_value\n",
    "        for ii in range(4*Nt):\n",
    "            bit = bits[ii]\n",
    "            if bit == '1':\n",
    "                if error_norm_value<min_error_norm_1[ii]:\n",
    "                    min_error_norm_1[ii] = error_norm_value\n",
    "            if bit == '0':\n",
    "                if error_norm_value<min_error_norm_0[ii]:\n",
    "                    min_error_norm_0[ii] = error_norm_value\n",
    "    MaxLog_detect_result = ''\n",
    "    for ii in range(4*Nt):\n",
    "        if min_error_norm_0[ii] - min_error_norm_1[ii] > 0:\n",
    "            MaxLog_detect_result += '1'\n",
    "        else:\n",
    "            MaxLog_detect_result += '0'\n",
    "            \n",
    "    MAP_detect_result = str(bin(np.argmin(error_norm))[2:].zfill(4*Nt))\n",
    "    \n",
    "    return MaxLog_detect_result, MAP_detect_result\n",
    "\n",
    "def count_differences(str1, str2):\n",
    "    return sum(a != b for a, b in zip(str1, str2))\n",
    "\n",
    "def calculate_BER(H_trained, H_estimated, bits_sequence_testing, y_sequence_testing):\n",
    "    error_QNN = 0\n",
    "    error_MAP = 0\n",
    "    error_MaxLog = 0\n",
    "    for ii in range(len(y_sequence_testing[0])):\n",
    "        detect_result_QNN = detection_QNN(y_sequence_testing[:,ii], H_trained)\n",
    "        MaxLog_detect_result, MAP_detect_result = detection_MAP_MaxLog(H_estimated, y_sequence_testing[:,ii])\n",
    "        true_sequence = ''.join(bits_sequence_testing[ii*Nt+jj] for jj in range(Nt))\n",
    "        error_QNN += count_differences(detect_result_QNN, true_sequence)\n",
    "        error_MAP += count_differences(MAP_detect_result, true_sequence)\n",
    "        error_MaxLog += count_differences(MaxLog_detect_result, true_sequence)\n",
    "    BER_QNN = error_QNN/(len(y_sequence_testing[0])*len(detect_result_QNN))\n",
    "    BER_MAP = error_MAP/(len(y_sequence_testing[0])*len(MAP_detect_result))\n",
    "    BER_MaxLog = error_MaxLog/(len(y_sequence_testing[0])*len(MaxLog_detect_result))\n",
    "    \n",
    "    return BER_QNN, BER_MAP, BER_MaxLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0.05\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 0\n",
      "loss: 1.3474192422906144\n",
      "loss: 0.5858318910024346\n",
      "loss: 0.4129993800360377\n",
      "loss: 0.3318576679050751\n",
      "loss: 0.30541788998875685\n",
      "loss: 0.29448093999880826\n",
      "loss: 0.2872893373233824\n",
      "loss: 0.28401055522071433\n",
      "loss: 0.28118416766640764\n",
      "loss: 0.2795610329226917\n",
      "loss: 0.27855894690826666\n",
      "loss: 0.2779737996022276\n",
      "loss: 0.2775647512533482\n",
      "loss: 0.2773916927154948\n",
      "loss: 0.27727562205698464\n",
      "loss: 0.27691499138030157\n",
      "loss: 0.27694043450110856\n",
      "loss: 0.27673655161019595\n",
      "loss: 0.27683182398915435\n",
      "loss: 0.2767939384921441\n",
      "loss: 0.27670254556672313\n",
      "loss: 0.2767207003955074\n",
      "loss: 0.27700719826536563\n",
      "loss: 0.27664162958465693\n",
      "loss: 0.27660599546915526\n",
      "loss: 0.27664278073254006\n",
      "loss: 0.276653894020385\n",
      "loss: 0.276515607786838\n",
      "loss: 0.27649358770094473\n",
      "loss: 0.2765433691467381\n",
      "loss: 0.2767039744780481\n",
      "loss: 0.27659175324365376\n",
      "loss: 0.2766056404083975\n",
      "MAP: 0.14599609375\n",
      "MaxLog: 0.14599609375\n",
      "QNN: 0.149169921875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 1\n",
      "loss: 0.9440270289416095\n",
      "loss: 0.6482838408086739\n",
      "loss: 0.5128078519376343\n",
      "loss: 0.45830667119177976\n",
      "loss: 0.42859790465249714\n",
      "loss: 0.4034129233787874\n",
      "loss: 0.3869157661996167\n",
      "loss: 0.3788106319581047\n",
      "loss: 0.37316587085941666\n",
      "loss: 0.3685058378920989\n",
      "loss: 0.36517693387189476\n",
      "loss: 0.3626655364509057\n",
      "loss: 0.3607811842905843\n",
      "loss: 0.3589916773531352\n",
      "loss: 0.3576410214477693\n",
      "loss: 0.3564639300133535\n",
      "loss: 0.35542255423547825\n",
      "loss: 0.35479985632162936\n",
      "loss: 0.35419911967237855\n",
      "loss: 0.35364547355331544\n",
      "loss: 0.35315725185996044\n",
      "loss: 0.3529316830764662\n",
      "loss: 0.352783996597157\n",
      "loss: 0.3525599340672336\n",
      "loss: 0.35223873170388775\n",
      "loss: 0.3522031601011795\n",
      "loss: 0.3519133770398737\n",
      "loss: 0.35189047729209305\n",
      "loss: 0.351619872259396\n",
      "loss: 0.3516656432217736\n",
      "loss: 0.3515811966181688\n",
      "MAP: 0.170166015625\n",
      "MaxLog: 0.170166015625\n",
      "QNN: 0.1739501953125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 2\n",
      "loss: 1.1215010579207079\n",
      "loss: 0.7523060980560919\n",
      "loss: 0.6068433357012979\n",
      "loss: 0.5768920236275275\n",
      "loss: 0.5475716020655618\n",
      "loss: 0.472781106322816\n",
      "loss: 0.4438749111537898\n",
      "loss: 0.43220402695134824\n",
      "loss: 0.42315486386024226\n",
      "loss: 0.417153529739976\n",
      "loss: 0.41297983058681903\n",
      "loss: 0.4089186735948006\n",
      "loss: 0.40643698273637074\n",
      "loss: 0.40403472959249365\n",
      "loss: 0.40245048835254527\n",
      "loss: 0.40132841898121463\n",
      "loss: 0.40022795668153155\n",
      "loss: 0.3996299759505525\n",
      "loss: 0.3990518181482428\n",
      "loss: 0.39883411917931655\n",
      "loss: 0.3985614278102336\n",
      "loss: 0.39815797328414415\n",
      "loss: 0.3980492974798772\n",
      "loss: 0.39791374773635124\n",
      "loss: 0.3977931013596572\n",
      "loss: 0.39801985070715273\n",
      "loss: 0.3975629046778229\n",
      "loss: 0.3975322904939142\n",
      "loss: 0.39732863702973603\n",
      "loss: 0.397352263192142\n",
      "loss: 0.3974061146765511\n",
      "MAP: 0.2039794921875\n",
      "MaxLog: 0.2039794921875\n",
      "QNN: 0.2017822265625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 3\n",
      "loss: 1.6389053252804306\n",
      "loss: 0.7723522936308467\n",
      "loss: 0.46901630014558116\n",
      "loss: 0.38110780346043616\n",
      "loss: 0.3593082640845435\n",
      "loss: 0.34715246742114\n",
      "loss: 0.33871940324377775\n",
      "loss: 0.3324842302446129\n",
      "loss: 0.32790614824300063\n",
      "loss: 0.324724159466574\n",
      "loss: 0.3230534270179799\n",
      "loss: 0.32119432315940366\n",
      "loss: 0.320069705238572\n",
      "loss: 0.3188248267438491\n",
      "loss: 0.31789679117517644\n",
      "loss: 0.31699323260731216\n",
      "loss: 0.3164930966790032\n",
      "loss: 0.3161868466916183\n",
      "loss: 0.3158891263644239\n",
      "loss: 0.3157102759524963\n",
      "loss: 0.31555491845526573\n",
      "loss: 0.3156873520320502\n",
      "loss: 0.3153469025653394\n",
      "loss: 0.3152420839505845\n",
      "loss: 0.31511516754617963\n",
      "loss: 0.3151521290629238\n",
      "loss: 0.3151441534555551\n",
      "loss: 0.3149905201106507\n",
      "loss: 0.3152134821216996\n",
      "loss: 0.315172793073518\n",
      "loss: 0.3150988381661868\n",
      "MAP: 0.1553955078125\n",
      "MaxLog: 0.1553955078125\n",
      "QNN: 0.152099609375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 4\n",
      "loss: 1.4307036659812666\n",
      "loss: 0.9650169644267944\n",
      "loss: 0.38504061012080215\n",
      "loss: 0.3429735037296951\n",
      "loss: 0.3286940610688937\n",
      "loss: 0.3192606785049401\n",
      "loss: 0.313208535823318\n",
      "loss: 0.30906440737161545\n",
      "loss: 0.30642974179840926\n",
      "loss: 0.3040758474734064\n",
      "loss: 0.3026267487760532\n",
      "loss: 0.3011993957754728\n",
      "loss: 0.3001791718602342\n",
      "loss: 0.2996060220033476\n",
      "loss: 0.29884159879513944\n",
      "loss: 0.29837541128231093\n",
      "loss: 0.2981026180834972\n",
      "loss: 0.29762625513099455\n",
      "loss: 0.2974383277913577\n",
      "loss: 0.29724850111770157\n",
      "loss: 0.29744623780371954\n",
      "loss: 0.29691174501789025\n",
      "loss: 0.2968232143597992\n",
      "loss: 0.2967132938061791\n",
      "loss: 0.2967590451620864\n",
      "loss: 0.29648016739221045\n",
      "loss: 0.2963359492227123\n",
      "loss: 0.29630855904451386\n",
      "loss: 0.29616253766866524\n",
      "loss: 0.2961231546587294\n",
      "loss: 0.29623468715475326\n",
      "loss: 0.29612956955036707\n",
      "loss: 0.29610776789360693\n",
      "MAP: 0.1407470703125\n",
      "MaxLog: 0.1407470703125\n",
      "QNN: 0.1441650390625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 5\n",
      "loss: 1.262895911286306\n",
      "loss: 1.0156665278210455\n",
      "loss: 0.729839516330932\n",
      "loss: 0.7591601035351899\n",
      "loss: 0.5319342585883562\n",
      "loss: 0.4418726181111523\n",
      "loss: 0.39348592001518473\n",
      "loss: 0.36699000918062813\n",
      "loss: 0.3541312861683872\n",
      "loss: 0.3471242155567752\n",
      "loss: 0.3423650509419094\n",
      "loss: 0.33966774635198405\n",
      "loss: 0.33765822581131916\n",
      "loss: 0.33629832357224576\n",
      "loss: 0.33573647095365183\n",
      "loss: 0.3347574031534834\n",
      "loss: 0.3346556136846208\n",
      "loss: 0.3338623296666986\n",
      "loss: 0.333451685760212\n",
      "loss: 0.33341999958258084\n",
      "loss: 0.3334614303215088\n",
      "loss: 0.3330994555399247\n",
      "loss: 0.3327959394951831\n",
      "loss: 0.3326452861723461\n",
      "loss: 0.3326033801610675\n",
      "loss: 0.3326101161248689\n",
      "loss: 0.3324922465874456\n",
      "loss: 0.332819458891936\n",
      "loss: 0.3325368699295107\n",
      "loss: 0.332460658342982\n",
      "loss: 0.33234727491772437\n",
      "loss: 0.3323225726621603\n",
      "MAP: 0.156494140625\n",
      "MaxLog: 0.156494140625\n",
      "QNN: 0.155517578125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 6\n",
      "loss: 1.095652484312093\n",
      "loss: 0.7400723389489978\n",
      "loss: 0.42788459238441906\n",
      "loss: 0.3779208466502802\n",
      "loss: 0.36238919175066475\n",
      "loss: 0.354403601777505\n",
      "loss: 0.3508138594255083\n",
      "loss: 0.34754572683025414\n",
      "loss: 0.3454823586739942\n",
      "loss: 0.34436922631200706\n",
      "loss: 0.34392353658265445\n",
      "loss: 0.34314222327742866\n",
      "loss: 0.3427323490839817\n",
      "loss: 0.34223867417532694\n",
      "loss: 0.3420955234413619\n",
      "loss: 0.34148593749547695\n",
      "loss: 0.3414911007464845\n",
      "loss: 0.34124167283083534\n",
      "loss: 0.34094792461999046\n",
      "loss: 0.34103169273307504\n",
      "loss: 0.3409472811503807\n",
      "loss: 0.34063783545627446\n",
      "loss: 0.34057258638984467\n",
      "loss: 0.34067225874558843\n",
      "loss: 0.34141895632868924\n",
      "loss: 0.3403482658552621\n",
      "loss: 0.3402945334758415\n",
      "loss: 0.34015359277049756\n",
      "loss: 0.3401206068356647\n",
      "loss: 0.34045586841682834\n",
      "loss: 0.3400990761164694\n",
      "loss: 0.3400717897135159\n",
      "MAP: 0.161376953125\n",
      "MaxLog: 0.161376953125\n",
      "QNN: 0.159423828125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 7\n",
      "loss: 1.7417597475408062\n",
      "loss: 0.994962803455681\n",
      "loss: 1.306845411250443\n",
      "loss: 0.9468503468647139\n",
      "loss: 1.1296455572825077\n",
      "loss: 0.6149444400559521\n",
      "loss: 0.5481750047672791\n",
      "loss: 0.5148739765974464\n",
      "loss: 0.4898727882058306\n",
      "loss: 0.47150506977569134\n",
      "loss: 0.4633791355508821\n",
      "loss: 0.4602490564247699\n",
      "loss: 0.4576705986251969\n",
      "loss: 0.4562606320658541\n",
      "loss: 0.4548830857459196\n",
      "loss: 0.454304717531853\n",
      "loss: 0.45261051867366736\n",
      "loss: 0.4523356380291531\n",
      "loss: 0.4528845271685608\n",
      "loss: 0.45102711581973953\n",
      "loss: 0.4498894262805645\n",
      "loss: 0.44962934117537345\n",
      "loss: 0.44946628127030386\n",
      "loss: 0.44850320458003157\n",
      "loss: 0.4476509823748189\n",
      "loss: 0.4476644851641315\n",
      "loss: 0.44752585799076017\n",
      "loss: 0.44688839544770176\n",
      "loss: 0.4469353972868222\n",
      "loss: 0.4462154245091577\n",
      "loss: 0.44604729558285583\n",
      "loss: 0.446083035173878\n",
      "MAP: 0.221923828125\n",
      "MaxLog: 0.221923828125\n",
      "QNN: 0.2142333984375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 8\n",
      "loss: 1.2998883775043322\n",
      "loss: 0.7327554754561256\n",
      "loss: 0.691605348666691\n",
      "loss: 0.7977491572252734\n",
      "loss: 0.5794051983867211\n",
      "loss: 0.5403417304393262\n",
      "loss: 0.5170159284427162\n",
      "loss: 0.4899166291631419\n",
      "loss: 0.4480826673314596\n",
      "loss: 0.4291141154080131\n",
      "loss: 0.419795508428713\n",
      "loss: 0.41375837139722\n",
      "loss: 0.40982494906929606\n",
      "loss: 0.40734196857207217\n",
      "loss: 0.4056768009006886\n",
      "loss: 0.4045684650994318\n",
      "loss: 0.40369095657264925\n",
      "loss: 0.40290168377143987\n",
      "loss: 0.40247445759734013\n",
      "loss: 0.402271302056234\n",
      "loss: 0.40181797833851346\n",
      "loss: 0.4019072122040038\n",
      "loss: 0.4015744041549283\n",
      "loss: 0.4014637758950086\n",
      "loss: 0.40134054331562274\n",
      "loss: 0.4014431978234262\n",
      "loss: 0.4010378907899479\n",
      "loss: 0.40097214857186314\n",
      "loss: 0.40104418979224365\n",
      "loss: 0.4010505132838997\n",
      "loss: 0.4010670990253009\n",
      "MAP: 0.20751953125\n",
      "MaxLog: 0.20751953125\n",
      "QNN: 0.2034912109375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 9\n",
      "loss: 1.1354365918706433\n",
      "loss: 0.711290625215227\n",
      "loss: 0.5738339048566593\n",
      "loss: 0.5506740234425739\n",
      "loss: 0.6506639668733849\n",
      "loss: 0.5815040771201941\n",
      "loss: 0.4614944702123885\n",
      "loss: 0.4407761642897123\n",
      "loss: 0.4297543407199028\n",
      "loss: 0.4239562557112044\n",
      "loss: 0.42030749340898604\n",
      "loss: 0.41735968557683223\n",
      "loss: 0.4155761994526714\n",
      "loss: 0.41409863292440907\n",
      "loss: 0.4126816774301128\n",
      "loss: 0.4120020271740824\n",
      "loss: 0.41142184126697295\n",
      "loss: 0.41091912941930153\n",
      "loss: 0.4112682184660466\n",
      "loss: 0.41070565876694937\n",
      "loss: 0.4113638073997077\n",
      "loss: 0.4105703062546838\n",
      "loss: 0.4107844079673306\n",
      "loss: 0.41087949141637076\n",
      "loss: 0.41046242644964587\n",
      "loss: 0.4103815144164039\n",
      "loss: 0.41022042140733306\n",
      "loss: 0.410348739729465\n",
      "loss: 0.4104928058295922\n",
      "loss: 0.41062131802073815\n",
      "loss: 0.41010636957983904\n",
      "loss: 0.41011561757833603\n",
      "MAP: 0.2042236328125\n",
      "MaxLog: 0.2042236328125\n",
      "QNN: 0.201171875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 10\n",
      "loss: 0.9998555713180594\n",
      "loss: 1.1269525518955772\n",
      "loss: 0.7448717906880103\n",
      "loss: 0.7618107227305254\n",
      "loss: 1.029387340136216\n",
      "loss: 0.6709354787870889\n",
      "loss: 0.5955813333618409\n",
      "loss: 0.57246877475353\n",
      "loss: 0.5852022172490737\n",
      "loss: 0.6088163884399308\n",
      "loss: 0.5081805804100971\n",
      "loss: 0.4879520233077652\n",
      "loss: 0.47244699630691483\n",
      "loss: 0.4615969607849667\n",
      "loss: 0.45360491637632827\n",
      "loss: 0.4478222214572517\n",
      "loss: 0.4433156232306177\n",
      "loss: 0.44039661456707424\n",
      "loss: 0.43830147228760397\n",
      "loss: 0.43680436070313466\n",
      "loss: 0.43571868493131366\n",
      "loss: 0.43501344970903305\n",
      "loss: 0.43395741874304544\n",
      "loss: 0.4331731405928436\n",
      "loss: 0.4330116931120007\n",
      "loss: 0.43252016159327267\n",
      "loss: 0.43244735443935245\n",
      "loss: 0.43207749252389904\n",
      "loss: 0.43186560820567205\n",
      "loss: 0.4318956457083843\n",
      "loss: 0.43168022020645397\n",
      "loss: 0.43147294476116604\n",
      "loss: 0.43184307663927246\n",
      "loss: 0.4314734520164718\n",
      "loss: 0.4315489531343104\n",
      "MAP: 0.2318115234375\n",
      "MaxLog: 0.2318115234375\n",
      "QNN: 0.23046875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 11\n",
      "loss: 1.5720249719342272\n",
      "loss: 0.9054299805193995\n",
      "loss: 0.5702304085796587\n",
      "loss: 0.4867153241179841\n",
      "loss: 0.4463831989863531\n",
      "loss: 0.42333333941993984\n",
      "loss: 0.40048166554644465\n",
      "loss: 0.38041939783538303\n",
      "loss: 0.3694895120830201\n",
      "loss: 0.36092627117398945\n",
      "loss: 0.3569752142084133\n",
      "loss: 0.35310999190930814\n",
      "loss: 0.3497367959302827\n",
      "loss: 0.3472284284801027\n",
      "loss: 0.3457699660885891\n",
      "loss: 0.34411892273379807\n",
      "loss: 0.34282095001018303\n",
      "loss: 0.34209975965773054\n",
      "loss: 0.3416579404513659\n",
      "loss: 0.34101929611166415\n",
      "loss: 0.34042084331209643\n",
      "loss: 0.3402091934315531\n",
      "loss: 0.34014284442789183\n",
      "loss: 0.33956559994118535\n",
      "loss: 0.3392565305837791\n",
      "loss: 0.3392264099835264\n",
      "loss: 0.33898066217745115\n",
      "loss: 0.3387260108041772\n",
      "loss: 0.3386833990747791\n",
      "loss: 0.3384811389344299\n",
      "loss: 0.3384681191070985\n",
      "MAP: 0.15673828125\n",
      "MaxLog: 0.15673828125\n",
      "QNN: 0.1571044921875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 12\n",
      "loss: 1.3178043450979509\n",
      "loss: 1.4552457730145205\n",
      "loss: 0.581170386723768\n",
      "loss: 0.3080995785476355\n",
      "loss: 0.26858868658124363\n",
      "loss: 0.2544348916436872\n",
      "loss: 0.2472371546145347\n",
      "loss: 0.24067994840053647\n",
      "loss: 0.23591160788967516\n",
      "loss: 0.2331693633050527\n",
      "loss: 0.2306600146334444\n",
      "loss: 0.22768148600954458\n",
      "loss: 0.22562952980316606\n",
      "loss: 0.2239808624238629\n",
      "loss: 0.22239237281286448\n",
      "loss: 0.22083235764419773\n",
      "loss: 0.21956138855830878\n",
      "loss: 0.21867238709698011\n",
      "loss: 0.21827500671661837\n",
      "loss: 0.21771823541333638\n",
      "loss: 0.21646500932703297\n",
      "loss: 0.21593676263173467\n",
      "loss: 0.2154256943739662\n",
      "loss: 0.21490294461231224\n",
      "loss: 0.21470683558480108\n",
      "loss: 0.21431145866748794\n",
      "loss: 0.21377203736032124\n",
      "loss: 0.21350769662485192\n",
      "loss: 0.2133311810815014\n",
      "loss: 0.21308065993709602\n",
      "loss: 0.2127809480552333\n",
      "loss: 0.2127075462098593\n",
      "MAP: 0.089111328125\n",
      "MaxLog: 0.089111328125\n",
      "QNN: 0.09130859375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 13\n",
      "loss: 1.6559493215992205\n",
      "loss: 0.6821750539650333\n",
      "loss: 0.6576632578023333\n",
      "loss: 0.7714135771361447\n",
      "loss: 0.8848707017434676\n",
      "loss: 0.5582800462652482\n",
      "loss: 0.4832081344415745\n",
      "loss: 0.44290711747735645\n",
      "loss: 0.41430429522913415\n",
      "loss: 0.392329581877324\n",
      "loss: 0.37350998703246385\n",
      "loss: 0.35832565183863757\n",
      "loss: 0.34693444806153706\n",
      "loss: 0.33780283179923287\n",
      "loss: 0.33138555098242845\n",
      "loss: 0.32738361202957594\n",
      "loss: 0.32455706393633205\n",
      "loss: 0.3229018531311847\n",
      "loss: 0.3217669532369988\n",
      "loss: 0.32106725206117337\n",
      "loss: 0.3208404217918577\n",
      "loss: 0.3205617832668392\n",
      "loss: 0.3203266404699687\n",
      "loss: 0.3202007163862294\n",
      "loss: 0.31995254842982623\n",
      "loss: 0.3198337249510878\n",
      "loss: 0.31982712495789883\n",
      "loss: 0.31965783149552346\n",
      "loss: 0.3196265537949911\n",
      "loss: 0.31952184235386377\n",
      "loss: 0.31956081911205286\n",
      "MAP: 0.1552734375\n",
      "MaxLog: 0.1552734375\n",
      "QNN: 0.1549072265625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 14\n",
      "loss: 1.2146415086548807\n",
      "loss: 0.6643702291025697\n",
      "loss: 0.7743053328280418\n",
      "loss: 0.517519438122741\n",
      "loss: 0.4980021944542349\n",
      "loss: 0.4881562914970445\n",
      "loss: 0.4837938961618862\n",
      "loss: 0.48069117234762626\n",
      "loss: 0.47848001169033094\n",
      "loss: 0.48265247662465405\n",
      "loss: 0.48882851251728326\n",
      "loss: 0.5008067389974266\n",
      "loss: 0.48649993309951733\n",
      "loss: 0.4810415985698516\n",
      "loss: 0.47240651872885453\n",
      "loss: 0.4715625315065407\n",
      "loss: 0.4707252314095265\n",
      "loss: 0.4694643227516539\n",
      "loss: 0.46977774365276076\n",
      "loss: 0.46903292729839474\n",
      "loss: 0.46976506971040777\n",
      "loss: 0.468038906990896\n",
      "loss: 0.46750935608799465\n",
      "loss: 0.4675464208766149\n",
      "loss: 0.4666066153698617\n",
      "loss: 0.46747993598338883\n",
      "loss: 0.46692649100010797\n",
      "loss: 0.4659005304595793\n",
      "loss: 0.46555070974480495\n",
      "loss: 0.46610881380341596\n",
      "loss: 0.4655007680112439\n",
      "loss: 0.46628221406166503\n",
      "loss: 0.4656267255090881\n",
      "loss: 0.46500172925974675\n",
      "loss: 0.46556442152266503\n",
      "loss: 0.46521178720399253\n",
      "loss: 0.46442404429223305\n",
      "loss: 0.46519637416044135\n",
      "loss: 0.464567917910898\n",
      "loss: 0.4651100234035675\n",
      "loss: 0.46448416373051604\n",
      "loss: 0.46428144857239084\n",
      "loss: 0.4640643424753399\n",
      "loss: 0.4641229298695941\n",
      "MAP: 0.27001953125\n",
      "MaxLog: 0.27001953125\n",
      "QNN: 0.2545166015625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 15\n",
      "loss: 1.305373321585939\n",
      "loss: 1.0210976589278489\n",
      "loss: 0.8979311973693027\n",
      "loss: 0.6658366107853649\n",
      "loss: 0.4735764596989839\n",
      "loss: 0.42561926647510195\n",
      "loss: 0.3987520119251685\n",
      "loss: 0.38567796887574224\n",
      "loss: 0.37720209419677087\n",
      "loss: 0.3707879703170324\n",
      "loss: 0.3672914533856305\n",
      "loss: 0.36454217861158145\n",
      "loss: 0.3627460764431113\n",
      "loss: 0.36140832705502013\n",
      "loss: 0.3602592697057434\n",
      "loss: 0.35979837147149557\n",
      "loss: 0.3592665993769405\n",
      "loss: 0.3589962284875373\n",
      "loss: 0.35883685756436423\n",
      "loss: 0.3587554190232619\n",
      "loss: 0.35853704208683496\n",
      "loss: 0.3583439699421568\n",
      "loss: 0.358462741324312\n",
      "loss: 0.35826602665972496\n",
      "loss: 0.35814726069233377\n",
      "loss: 0.3584367401698988\n",
      "loss: 0.3580217578002413\n",
      "loss: 0.3579962302269966\n",
      "loss: 0.358084287588102\n",
      "loss: 0.3581503041020809\n",
      "loss: 0.35793312197350774\n",
      "loss: 0.3580037360179569\n",
      "MAP: 0.1617431640625\n",
      "MaxLog: 0.1617431640625\n",
      "QNN: 0.1614990234375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 16\n",
      "loss: 0.8945288110212187\n",
      "loss: 0.5342535639128791\n",
      "loss: 0.4336159169090655\n",
      "loss: 0.40706443112868984\n",
      "loss: 0.3970406001307952\n",
      "loss: 0.39043469276015813\n",
      "loss: 0.3846686090569909\n",
      "loss: 0.3805012455572682\n",
      "loss: 0.3762381079537642\n",
      "loss: 0.3737257545891946\n",
      "loss: 0.3710036271975396\n",
      "loss: 0.3693644614284993\n",
      "loss: 0.36791431738822644\n",
      "loss: 0.3666259496890354\n",
      "loss: 0.3658782009866317\n",
      "loss: 0.3651946390976331\n",
      "loss: 0.3643420957078369\n",
      "loss: 0.36392188710423334\n",
      "loss: 0.36336185985926966\n",
      "loss: 0.3632306102876293\n",
      "loss: 0.3627726551175796\n",
      "loss: 0.36279550272580574\n",
      "loss: 0.3630794175191603\n",
      "loss: 0.3625935858544505\n",
      "loss: 0.3622686062189527\n",
      "loss: 0.3623324234170381\n",
      "loss: 0.36188755399402206\n",
      "loss: 0.3619760935425983\n",
      "loss: 0.3617956463078785\n",
      "loss: 0.36199133667598454\n",
      "loss: 0.36153001360353193\n",
      "loss: 0.3617186233841541\n",
      "loss: 0.3618875314110868\n",
      "loss: 0.36190337624343705\n",
      "MAP: 0.1666259765625\n",
      "MaxLog: 0.1666259765625\n",
      "QNN: 0.1640625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 17\n",
      "loss: 1.4666891418683488\n",
      "loss: 1.0463435604886846\n",
      "loss: 0.7688980901293693\n",
      "loss: 0.6115915886122731\n",
      "loss: 0.6447779585732405\n",
      "loss: 1.0313228656744475\n",
      "loss: 0.7244834105567474\n",
      "loss: 0.6145476637540792\n",
      "loss: 0.5642136214638886\n",
      "loss: 0.5451730117426432\n",
      "loss: 0.5876548738475019\n",
      "loss: 0.7616305020218207\n",
      "loss: 0.5446099813627243\n",
      "loss: 0.49730040029127515\n",
      "loss: 0.4734349717685732\n",
      "loss: 0.4584614214221604\n",
      "loss: 0.4495054536210004\n",
      "loss: 0.44116938184140225\n",
      "loss: 0.4362040405615115\n",
      "loss: 0.4310499169903598\n",
      "loss: 0.4289568531157629\n",
      "loss: 0.42627143658480415\n",
      "loss: 0.4241525987614681\n",
      "loss: 0.42433715307071124\n",
      "loss: 0.42216201667166553\n",
      "loss: 0.42156797656929423\n",
      "loss: 0.4217433306617525\n",
      "loss: 0.42073922862387314\n",
      "loss: 0.4201542234668863\n",
      "loss: 0.4200976333857622\n",
      "loss: 0.4192446023942629\n",
      "loss: 0.41857975807200376\n",
      "loss: 0.418408582883675\n",
      "loss: 0.4186461667000757\n",
      "loss: 0.41815177647978347\n",
      "loss: 0.4180735979657757\n",
      "MAP: 0.2291259765625\n",
      "MaxLog: 0.2291259765625\n",
      "QNN: 0.2275390625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 18\n",
      "loss: 2.0947243357282574\n",
      "loss: 0.9066690416942078\n",
      "loss: 0.4492480090339879\n",
      "loss: 0.3784804173281938\n",
      "loss: 0.35734740596749576\n",
      "loss: 0.3466825615038208\n",
      "loss: 0.34020485388729726\n",
      "loss: 0.33658126291049933\n",
      "loss: 0.3344402810116713\n",
      "loss: 0.3327185492029275\n",
      "loss: 0.3318439715706185\n",
      "loss: 0.3314669479890462\n",
      "loss: 0.3309005150651532\n",
      "loss: 0.33040813676967223\n",
      "loss: 0.33013048016113755\n",
      "loss: 0.3299808896494935\n",
      "loss: 0.32958451123587096\n",
      "loss: 0.32951759189295127\n",
      "loss: 0.32938542245984287\n",
      "loss: 0.3296437955970297\n",
      "loss: 0.3293454350490302\n",
      "loss: 0.32901271476486516\n",
      "loss: 0.3289977873547693\n",
      "loss: 0.32867724301288664\n",
      "loss: 0.3288413378615496\n",
      "loss: 0.3285236402239392\n",
      "loss: 0.32858103183031734\n",
      "loss: 0.32853930048778074\n",
      "loss: 0.32840251199365533\n",
      "loss: 0.32852564234012777\n",
      "loss: 0.329008209813984\n",
      "loss: 0.3285513998465694\n",
      "loss: 0.3283260963869366\n",
      "loss: 0.32872234698355635\n",
      "loss: 0.3283606300822703\n",
      "loss: 0.32835232842234363\n",
      "MAP: 0.161865234375\n",
      "MaxLog: 0.161865234375\n",
      "QNN: 0.1571044921875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 19\n",
      "loss: 1.6263334960772384\n",
      "loss: 0.7924915103485016\n",
      "loss: 0.657728115934348\n",
      "loss: 0.6085306198138305\n",
      "loss: 0.6182302980631222\n",
      "loss: 0.646328163322354\n",
      "loss: 0.5985450168947197\n",
      "loss: 0.4806962823360426\n",
      "loss: 0.45908178244000647\n",
      "loss: 0.44783071705047856\n",
      "loss: 0.4405653876234348\n",
      "loss: 0.43727141298448446\n",
      "loss: 0.4348885729478391\n",
      "loss: 0.43314159102701905\n",
      "loss: 0.4319976351490176\n",
      "loss: 0.43130349695373066\n",
      "loss: 0.4301091335817144\n",
      "loss: 0.42982103760186574\n",
      "loss: 0.42905147017483986\n",
      "loss: 0.4288943569866728\n",
      "loss: 0.4281620540216093\n",
      "loss: 0.42782615647670924\n",
      "loss: 0.4275315433163194\n",
      "loss: 0.4273265993616675\n",
      "loss: 0.4271779135925787\n",
      "loss: 0.42696127429675074\n",
      "loss: 0.4269058511352036\n",
      "loss: 0.42679649902579747\n",
      "loss: 0.42679718026586194\n",
      "loss: 0.4266254160713841\n",
      "loss: 0.4268258622184988\n",
      "loss: 0.4264929894458144\n",
      "loss: 0.4265439036715562\n",
      "MAP: 0.235595703125\n",
      "MaxLog: 0.235595703125\n",
      "QNN: 0.2296142578125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 20\n",
      "loss: 1.907886828209223\n",
      "loss: 0.9123049833382194\n",
      "loss: 1.0031407192364312\n",
      "loss: 1.1937074701823511\n",
      "loss: 0.6675365366827344\n",
      "loss: 0.4832352871130452\n",
      "loss: 0.4118995151619839\n",
      "loss: 0.38206343552130295\n",
      "loss: 0.3642531211278806\n",
      "loss: 0.3560163666585435\n",
      "loss: 0.3509679664093368\n",
      "loss: 0.3485644029868681\n",
      "loss: 0.3466757422329909\n",
      "loss: 0.34525575005216874\n",
      "loss: 0.34448895297085996\n",
      "loss: 0.34388142304642116\n",
      "loss: 0.34357111094542403\n",
      "loss: 0.3432167509103717\n",
      "loss: 0.34293795220649764\n",
      "loss: 0.3428375502441228\n",
      "loss: 0.34284179559627087\n",
      "loss: 0.3428958685833218\n",
      "loss: 0.34267843417247706\n",
      "loss: 0.342734573900095\n",
      "loss: 0.3430294498443419\n",
      "loss: 0.34257056823829696\n",
      "loss: 0.34283549738434876\n",
      "loss: 0.3425808985342965\n",
      "loss: 0.34249466914699656\n",
      "loss: 0.3426075023674459\n",
      "loss: 0.3425310136633177\n",
      "MAP: 0.1649169921875\n",
      "MaxLog: 0.1649169921875\n",
      "QNN: 0.1671142578125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 21\n",
      "loss: 1.7939974231918987\n",
      "loss: 1.3149476015447514\n",
      "loss: 1.564837593302746\n",
      "loss: 0.6665995707418771\n",
      "loss: 0.3805240978968381\n",
      "loss: 0.3375251968326627\n",
      "loss: 0.3218992786841186\n",
      "loss: 0.31327615339171533\n",
      "loss: 0.30703254497291016\n",
      "loss: 0.302477463185055\n",
      "loss: 0.29907028212152403\n",
      "loss: 0.2962661430408879\n",
      "loss: 0.29438778170504076\n",
      "loss: 0.29240898772870355\n",
      "loss: 0.2910800209605063\n",
      "loss: 0.2904838863387909\n",
      "loss: 0.2898844241842959\n"
     ]
    }
   ],
   "source": [
    "for ii in range(len(SNR_list)):\n",
    "    SNR_dB = SNR_list[ii]\n",
    "    SNR = 10**(SNR_dB / 10)\n",
    "    \n",
    "    # SD_performance = np.zeros(iter_num)\n",
    "    # SD_performance_estimated = np.zeros(iter_num)\n",
    "    MAP_performance = np.zeros(iter_num)\n",
    "    MaxLog_performance = np.zeros(iter_num)\n",
    "    QNN_performance_128 = np.zeros(iter_num)\n",
    "\n",
    "    alpha = 0.05\n",
    "    print(\"step: \"+ str(alpha))\n",
    "\n",
    "    for jj in range(iter_num):\n",
    "        print(\"----------------------------current SNR_dB: \" +str(SNR_dB))\n",
    "        print(\"----------------------------current iter num: \" +str(jj))\n",
    "\n",
    "        H = H_list[jj] * np.sqrt(SNR)\n",
    "        # cov = cov_list[0]\n",
    "        cov = np.eye(Nr)\n",
    "\n",
    "        bits_sequence_testing, x_sequence_testing, y_sequence_testing = generate_data(Nr,Nt,1024,H,cov)\n",
    "        bits_sequence, x_sequence, y_sequence = generate_data(Nr,Nt,pilot_length,H,cov)\n",
    "        H_estimated = np.dot(y_sequence, np.linalg.pinv(x_sequence))\n",
    "        # print(\"估计信道\")\n",
    "        # print(H_estimated)\n",
    "\n",
    "        # SD_performance[jj] = sphere_decoding_BER(H, y_sequence_testing, bits_sequence_testing, 1)\n",
    "        # print(\"SD (perfect CSI): \"+str(SD_performance[jj]))\n",
    "\n",
    "\n",
    "        # SD_performance_estimated[jj] = sphere_decoding_BER(H_estimated, y_sequence_testing, bits_sequence_testing, 10000)\n",
    "        # print(\"SD (estimated CSI): \"+str(SD_performance_estimated[jj]))\n",
    "\n",
    "        # H_w = whiten_matrix(cov, H)\n",
    "        # print(\"白化信道\")\n",
    "        # print(H_w)\n",
    "\n",
    "        H_trained, loss = training(max_iter)\n",
    "        BER_QNN, BER_MAP, BER_MaxLog = calculate_BER(H_trained, H_estimated, bits_sequence_testing, y_sequence_testing)\n",
    "\n",
    "        # print(\"真实信道\")\n",
    "        # print(H)\n",
    "        # print(\"QNN信道\")\n",
    "        # print(H_trained)\n",
    "        # print(\"白化信道\")\n",
    "        # print(H_w)\n",
    "        \n",
    "\n",
    "        # save_BER[ii][jj] = BER\n",
    "        MAP_performance[jj] = BER_MAP\n",
    "        print(\"MAP: \"+str(BER_MAP))\n",
    "\n",
    "        MaxLog_performance[jj] = BER_MaxLog\n",
    "        print(\"MaxLog: \"+str(BER_MaxLog))\n",
    "\n",
    "        QNN_performance_128[jj] = BER_QNN\n",
    "        print(\"QNN: \"+str(BER_QNN))\n",
    "\n",
    "    # SD_mean_performance[ii] = np.mean(SD_performance)\n",
    "    # SD_mean_performance_estimated[ii] = np.mean(SD_performance_estimated)\n",
    "    MAP_mean_performance[ii] = np.mean(MAP_performance)\n",
    "    MaxLog_mean_performance[ii] = np.mean(MaxLog_performance)\n",
    "    QNN_mean_performance_128[ii] = np.mean(QNN_performance_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "lns1 = ax1.plot(SNR_list, SD_mean_performance_estimated, '-ro', linewidth=2.0, label=\"Max Log (estimated CSI)\")\n",
    "lns2 = ax1.plot(SNR_list, QNN_mean_performance_128, '-bo', linewidth=2.0, label=\"QNN Decoding (128 pilot)\")\n",
    "\n",
    "\n",
    "\n",
    "lns = lns1+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, loc=\"lower left\")\n",
    "\n",
    "# ax1.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs='auto'))\n",
    "# ax1.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "# ax1.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
    "\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax1.set_xticks(SNR_list)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_adjustable(\"datalim\")\n",
    "ax1.set_xlim(-0.5,16.5)\n",
    "ax1.set_ylim(1e-4, 0.8)\n",
    "ax1.set_ylabel(\"BER\")\n",
    "ax1.set_xlabel(\"SNR(dB)\")\n",
    "plt.title(\"covariance matrix = I\")\n",
    "\n",
    "# plt.savefig('BER.png',dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
