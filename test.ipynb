{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "from scipy.optimize import minimize\n",
    "from sphere_decoding.sphereDecodingUseC import sphere_decoding_BER\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as time\n",
    "\n",
    "# 交叉熵正常训练\n",
    "\n",
    "\n",
    "Nt = 2\n",
    "Nr = 4\n",
    "\n",
    "iter_num = 30\n",
    "channel_list = np.load(\"channel_list_4_2.npy\")\n",
    "H_list = channel_list[0:iter_num]\n",
    "\n",
    "SNR_list = np.array([0,5,10,15,20,25])\n",
    "\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "pilot_length = 128\n",
    "\n",
    "beta1 = 0\n",
    "\n",
    "SD_mean_performance = np.zeros(len(SNR_list))\n",
    "QNN_mean_performance_128 = np.zeros(len(SNR_list))\n",
    "\n",
    "save_loss = np.empty((len(SNR_list), iter_num))\n",
    "save_BER = np.empty((len(SNR_list), iter_num))\n",
    "save_channel = np.empty((len(SNR_list), iter_num, Nr, Nt), dtype=np.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate signals for simulation\n",
    "def generate_random_bit_sequence(length):\n",
    "    return ''.join(random.choice('01') for _ in range(length))\n",
    "\n",
    "def qam16_modulation(binary_input):\n",
    "    mapping = {\n",
    "        '0000': (1+1j),\n",
    "        '0001': (1+3j),\n",
    "        '0010': (3+1j),\n",
    "        '0011': (3+3j),\n",
    "        '0100': (1-1j),\n",
    "        '0101': (1-3j),\n",
    "        '0110': (3-1j),\n",
    "        '0111': (3-3j),\n",
    "        '1000': (-1+1j),\n",
    "        '1001': (-1+3j),\n",
    "        '1010': (-3+1j),\n",
    "        '1011': (-3+3j),\n",
    "        '1100': (-1-1j),\n",
    "        '1101': (-1-3j),\n",
    "        '1110': (-3-1j),\n",
    "        '1111': (-3-3j)\n",
    "    }\n",
    "    return mapping.get(binary_input, \"Invalid binary input\")/np.sqrt(10)\n",
    "\n",
    "def generate_x_sequence(length, Nt):\n",
    "    total_bits_sequence = generate_random_bit_sequence(length*Nt*4)\n",
    "    bits_sequence = [total_bits_sequence[i:i+4] for i in range(0, len(total_bits_sequence), 4)]\n",
    "    x_sequence = [np.array([qam16_modulation(bits_sequence[i+j]) for j in range(Nt)]) for i in range(0, len(bits_sequence), Nt)]\n",
    "    return bits_sequence, x_sequence\n",
    "\n",
    "def generate_noise(SNR, Nr):\n",
    "    return np.sqrt(1/(2*SNR))*(np.random.randn(Nr,1)+1j*np.random.randn(Nr,1))\n",
    "\n",
    "def generate_data(Nr,Nt,SNR_dB,length,H_channel):\n",
    "    bits_sequence, x_sequence = generate_x_sequence(length, Nt)\n",
    "    SNR= 10**(SNR_dB/10)\n",
    "    n_sequence = [generate_noise(SNR, Nr) for i in range(length)]\n",
    "    y_sequence = [(np.dot(H_channel, x_sequence[i].reshape(Nt,1)) + n_sequence[i])*np.sqrt(1) for i in range(length)]\n",
    "    return bits_sequence, x_sequence, y_sequence\n",
    "\n",
    "\n",
    "\n",
    "# training H_hat\n",
    "\n",
    "def bits2signals(bits):\n",
    "    # bits: input binary string with length of (4*Nt) \n",
    "    return np.array([qam16_modulation(bits[i:i+4]) for i in range(0, len(bits), 4)]).reshape(Nt,1)\n",
    "\n",
    "def calculate_layer1_training(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    output = np.empty(dimension_layer1)\n",
    "    # calculate gradient components in layer1\n",
    "    gradients = np.zeros((dimension_layer1, Nr, Nt), dtype=np.complex128)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        # s_conjugate_transpose = s.conj().T\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        value =  np.exp(-np.square(np.linalg.norm(error)))\n",
    "        output[index] = value\n",
    "        gradient_component = np.dot(error, s.conj().T)\n",
    "        gradients[index] = -value*(-gradient_component)\n",
    "    return output, gradients\n",
    "\n",
    "def layer2_matrix(n):\n",
    "    if n == 1:\n",
    "        return np.array([0,1])\n",
    "    else:\n",
    "        last_ = layer2_matrix(n-1)\n",
    "        half_cols_num = 2**(n-1)\n",
    "        first_row = np.concatenate((np.zeros(half_cols_num), np.ones(half_cols_num)))\n",
    "        remain_rows = np.hstack((last_, last_))\n",
    "        # print(remain_rows)\n",
    "        return np.vstack((first_row, remain_rows))\n",
    "\n",
    "\n",
    "def calculate_layer2_training(layer1_output, true_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    # print(total_prob)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = np.array([sum_prob_1[ii]/total_prob for ii in range(4*Nt)])\n",
    "    # calculate gradient components in layer2\n",
    "    gradients = np.zeros(2**(4*Nt))\n",
    "    for ii in range(len(gradients)):\n",
    "        for jj in range(4*Nt):\n",
    "            gradients[ii] += (-1/(4*Nt))*((true_output[jj]/output[jj])-((1-true_output[jj])/(1-output[jj])))*((A[jj][ii]/total_prob)-(sum_prob_1[jj]/np.square(total_prob)))\n",
    "    return output, gradients\n",
    "\n",
    "\n",
    "# def calculate_square_error(layer2_output, true_sequence):\n",
    "#     return np.linalg.norm(layer2_output-true_sequence)**2\n",
    "\n",
    "def calculate_cross_entropy(layer2_output, true_sequence):\n",
    "    epsilon = 1e-30  # 为了防止log(0)的情况，添加一个小的常数\n",
    "    layer2_output = np.clip(layer2_output, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -np.mean(true_sequence * np.log(layer2_output) + (1 - true_sequence) * np.log(1 - layer2_output))\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def calculate_cost_function(H_hat):\n",
    "    total_loss = 0\n",
    "    total_gradients = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    training_length = len(y_sequence)\n",
    "    for ii in range(training_length):\n",
    "        # print(ii)\n",
    "        true_sequence = ''.join(bits_sequence[ii*Nt+jj] for jj in range(Nt))\n",
    "        true_sequence = np.array([eval(ii) for ii in true_sequence])\n",
    "        layer1_output, layer1_gradients = calculate_layer1_training(H_hat, y_sequence[ii])\n",
    "        layer2_output, layer2_gradients = calculate_layer2_training(layer1_output, true_sequence)\n",
    "        total_loss += calculate_cross_entropy(layer2_output,true_sequence)\n",
    "        # SGD\n",
    "        if np.random.rand() < 0.9:\n",
    "            for jj in range(2**(4*Nt)):\n",
    "                total_gradients += (layer2_gradients[jj]*layer1_gradients[jj])\n",
    "    mean_loss = total_loss/training_length\n",
    "    return mean_loss, total_gradients\n",
    "\n",
    "\n",
    "def training(max_iter):\n",
    "    # H_hat = np.sqrt(1/2)*(np.random.randn(Nr,Nt)+1j*np.random.randn(Nr,Nt))\n",
    "    H_hat = np.zeros((Nr,Nt), dtype=np.complex128)\n",
    "    # H_hat = np.copy(H)\n",
    "    momentum = np.zeros((Nr,Nt),dtype=np.complex128)\n",
    "    last_loss = -100\n",
    "    mean_loss = -200\n",
    "    for iter_num in range(max_iter):\n",
    "        # solve the gradient\n",
    "        mean_loss, total_gradients = calculate_cost_function(H_hat)\n",
    "        print(\"loss: \"+str(mean_loss))\n",
    "        if iter_num % 10 == 9:\n",
    "            # print(\"loss: \"+str(mean_loss))\n",
    "            if np.abs(last_loss-mean_loss) < 0.001:\n",
    "                return H_hat, mean_loss\n",
    "            else:\n",
    "                last_loss = mean_loss\n",
    "        # update H_hat\n",
    "        momentum = (1-beta1)*total_gradients + beta1*momentum\n",
    "        H_hat -= alpha * momentum\n",
    "        # print(H_hat)\n",
    "    return H_hat, mean_loss\n",
    "\n",
    "\n",
    "\n",
    "# testing QNN for detection\n",
    "def calculate_layer1_testing(H_hat, y):\n",
    "    dimension_layer1 = 2**(4*Nt)\n",
    "    # layer1 output\n",
    "    output = np.zeros(dimension_layer1)\n",
    "    for index in range(dimension_layer1):\n",
    "        bits = str(bin(index)[2:].zfill(4*Nt))\n",
    "        s = bits2signals(bits)\n",
    "        s_conjugate_transpose = s.conj().T\n",
    "        error = y - np.dot(H_hat,s)\n",
    "        value =  np.exp(-np.square(np.linalg.norm(error)))\n",
    "        output[index] = value\n",
    "    return output\n",
    "\n",
    "def calculate_layer2_testing(layer1_output):\n",
    "    total_prob = np.sum(layer1_output)\n",
    "    A = layer2_matrix(4*Nt)\n",
    "    sum_prob_1 = np.dot(A, layer1_output)\n",
    "    # layer2 output\n",
    "    output = np.array([sum_prob_1[ii]/total_prob for ii in range(4*Nt)])\n",
    "    return output\n",
    "\n",
    "def detection(y, H_trained):\n",
    "    layer1_output = calculate_layer1_testing(H_trained, y)\n",
    "    layer2_output = calculate_layer2_testing(layer1_output)\n",
    "    detect_result = ''\n",
    "    for ii in range(len(layer2_output)):\n",
    "        if(layer2_output[ii]>0.5):\n",
    "            detect_result += '1'\n",
    "        else:\n",
    "            detect_result += '0'\n",
    "    return(detect_result)\n",
    "\n",
    "def count_differences(str1, str2):\n",
    "    return sum(a != b for a, b in zip(str1, str2))\n",
    "\n",
    "def calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing):\n",
    "    error = 0\n",
    "    for ii in range(len(y_sequence_testing)):\n",
    "        detect_result = detection(y_sequence_testing[ii], H_trained)\n",
    "        true_sequence = ''.join(bits_sequence_testing[ii*Nt+jj] for jj in range(Nt))\n",
    "        error += count_differences(detect_result, true_sequence)\n",
    "    BER = error/(len(y_sequence_testing)*len(detect_result))\n",
    "    return BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 0\n",
      "SD: 0.05322265625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.34277437301345187\n",
      "loss: 0.31147433326678975\n",
      "loss: 0.3042542236395964\n",
      "loss: 0.303029202340625\n",
      "loss: 0.301759354567989\n",
      "loss: 0.30256451317085054\n",
      "loss: 0.30218209064350304\n",
      "loss: 0.3014067864351765\n",
      "loss: 0.3026021518182395\n",
      "loss: 0.3021390974977398\n",
      "loss: 0.302663440962646\n",
      "loss: 0.301636584169918\n",
      "loss: 0.30184642871944944\n",
      "loss: 0.30282135078126593\n",
      "loss: 0.3056834163534567\n",
      "loss: 0.3021496763609939\n",
      "loss: 0.3021178438347461\n",
      "loss: 0.3037346910835884\n",
      "loss: 0.30274556984637985\n",
      "QNN: 0.1444091796875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 1\n",
      "SD: 0.1053466796875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3791780724425253\n",
      "loss: 0.3605477672427865\n",
      "loss: 0.3565359849583167\n",
      "loss: 0.3557980978780517\n",
      "loss: 0.35575552581285397\n",
      "loss: 0.3552207913560648\n",
      "loss: 0.35584303381630167\n",
      "loss: 0.3558663686122898\n",
      "loss: 0.3561036562995136\n",
      "loss: 0.35529736883098917\n",
      "loss: 0.3550845623479201\n",
      "loss: 0.3552796817977724\n",
      "loss: 0.3556534291797553\n",
      "loss: 0.35535839006233416\n",
      "loss: 0.3572549505210943\n",
      "loss: 0.35597039871849495\n",
      "loss: 0.35530912362575195\n",
      "loss: 0.35515054270628316\n",
      "loss: 0.35543058061413674\n",
      "QNN: 0.177001953125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 2\n",
      "SD: 0.1221923828125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.4140537852986775\n",
      "loss: 0.3966295510856197\n",
      "loss: 0.39539696250430545\n",
      "loss: 0.39670464748988454\n",
      "loss: 0.39726874860400707\n",
      "loss: 0.3952440236262414\n",
      "loss: 0.39386659446567635\n",
      "loss: 0.3982667836644426\n",
      "loss: 0.4001106289778599\n",
      "loss: 0.39767995763389774\n",
      "loss: 0.39350949404032703\n",
      "loss: 0.3964765909008292\n",
      "loss: 0.3965724258583789\n",
      "loss: 0.3965128236019188\n",
      "loss: 0.3974034889554901\n",
      "loss: 0.39792822347810114\n",
      "loss: 0.39620214693079714\n",
      "loss: 0.3957553673166251\n",
      "loss: 0.39332217265871405\n",
      "loss: 0.39194617892420164\n",
      "loss: 0.39295711300718755\n",
      "loss: 0.39361106282221736\n",
      "loss: 0.39196997254970395\n",
      "loss: 0.39170797510218536\n",
      "loss: 0.391103807237811\n",
      "loss: 0.39117867373968507\n",
      "loss: 0.39223133529570403\n",
      "loss: 0.39183288802097443\n",
      "loss: 0.3917858714738445\n",
      "loss: 0.39157777261742144\n",
      "loss: 0.39235058710999987\n",
      "loss: 0.39337768132466744\n",
      "loss: 0.39282985696114414\n",
      "loss: 0.3948511949349847\n",
      "loss: 0.3937074446448187\n",
      "loss: 0.39352024643449063\n",
      "loss: 0.39495100374514824\n",
      "loss: 0.3952083720790922\n",
      "loss: 0.39304087768297863\n",
      "loss: 0.39789379143616627\n",
      "loss: 0.3977160142606033\n",
      "loss: 0.3989483350571602\n",
      "loss: 0.4007327094848391\n",
      "loss: 0.4040027940147536\n",
      "loss: 0.4026562713274082\n",
      "loss: 0.40385532502532007\n",
      "loss: 0.40198461590715007\n",
      "loss: 0.3993846371093712\n",
      "loss: 0.3989265979414703\n",
      "loss: 0.39194776058381475\n",
      "loss: 0.39210092414975983\n",
      "loss: 0.3925820291877281\n",
      "loss: 0.3926156347767794\n",
      "loss: 0.39328544782095043\n",
      "loss: 0.3926354443157373\n",
      "loss: 0.3918157807279755\n",
      "loss: 0.3921566308798324\n",
      "loss: 0.3919405215654742\n",
      "loss: 0.3922366477250424\n",
      "loss: 0.39131151324046154\n",
      "loss: 0.3913672834062792\n",
      "loss: 0.39273958299733525\n",
      "loss: 0.39211735400159553\n",
      "loss: 0.3919661893624853\n",
      "loss: 0.39171784117672614\n",
      "loss: 0.3911508566595661\n",
      "loss: 0.3914722583037594\n",
      "loss: 0.3913690265962171\n",
      "loss: 0.3927413943818859\n",
      "QNN: 0.199462890625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 3\n",
      "SD: 0.1295166015625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.34770651906423206\n",
      "loss: 0.31952068718645704\n",
      "loss: 0.3184026864309023\n",
      "loss: 0.31826725130390593\n",
      "loss: 0.31830077300030174\n",
      "loss: 0.3187656972789276\n",
      "loss: 0.31869894912136\n",
      "loss: 0.3178606540461935\n",
      "loss: 0.3179077732218154\n",
      "loss: 0.31865902660918166\n",
      "loss: 0.31920060263082495\n",
      "loss: 0.3180828843342345\n",
      "loss: 0.31780906740659404\n",
      "loss: 0.3176940368276336\n",
      "loss: 0.3176007848493082\n",
      "loss: 0.3175568391609583\n",
      "loss: 0.3189957951295153\n",
      "loss: 0.3180483533799024\n",
      "loss: 0.3191884064816085\n",
      "loss: 0.3183563378235445\n",
      "loss: 0.3181575514593353\n",
      "loss: 0.31753556308966285\n",
      "loss: 0.3178867203662114\n",
      "loss: 0.3176118249623973\n",
      "loss: 0.31758204824908054\n",
      "loss: 0.3178964266380116\n",
      "loss: 0.31828629939245034\n",
      "loss: 0.3181233261379808\n",
      "loss: 0.31835444486182907\n",
      "QNN: 0.1505126953125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 4\n",
      "SD: 0.1214599609375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.31813687402942026\n",
      "loss: 0.2954587601027046\n",
      "loss: 0.29390578349537744\n",
      "loss: 0.2931832142412121\n",
      "loss: 0.29573539511945374\n",
      "loss: 0.29361297027156946\n",
      "loss: 0.293164439060751\n",
      "loss: 0.29262761886842087\n",
      "loss: 0.29318863920132093\n",
      "loss: 0.292413220884606\n",
      "loss: 0.293022359509216\n",
      "loss: 0.29250859840322857\n",
      "loss: 0.2939065204878607\n",
      "loss: 0.2930764170713119\n",
      "loss: 0.29265377576072177\n",
      "loss: 0.2927803162667848\n",
      "loss: 0.29259914145175614\n",
      "loss: 0.2927153313875067\n",
      "loss: 0.29328480061808554\n",
      "QNN: 0.1358642578125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 5\n",
      "SD: 0.1131591796875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.33504941887622874\n",
      "loss: 0.3190084839176663\n",
      "loss: 0.31837477601181297\n",
      "loss: 0.3176055653353785\n",
      "loss: 0.31758234911086364\n",
      "loss: 0.3173733634448446\n",
      "loss: 0.31684480006103016\n",
      "loss: 0.31699514886737407\n",
      "loss: 0.31685494988204965\n",
      "loss: 0.31881533146330465\n",
      "loss: 0.31844472856233697\n",
      "loss: 0.3172592135579907\n",
      "loss: 0.31733053539673844\n",
      "loss: 0.31706855457515853\n",
      "loss: 0.3175758693844129\n",
      "loss: 0.316921313743365\n",
      "loss: 0.31676475977800533\n",
      "loss: 0.31718206030653173\n",
      "loss: 0.3176468267710099\n",
      "QNN: 0.153564453125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 6\n",
      "SD: 0.1324462890625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3645027787253139\n",
      "loss: 0.3330791321785665\n",
      "loss: 0.32362268399203037\n",
      "loss: 0.31959906837929036\n",
      "loss: 0.31865432839778557\n",
      "loss: 0.31916946842808996\n",
      "loss: 0.31835582041179306\n",
      "loss: 0.3181807315316355\n",
      "loss: 0.3188264675389404\n",
      "loss: 0.31840633901003235\n",
      "loss: 0.3183587759530316\n",
      "loss: 0.31832467536303316\n",
      "loss: 0.31841361566576826\n",
      "loss: 0.318874214181643\n",
      "loss: 0.3187718644276656\n",
      "loss: 0.31834933556461303\n",
      "loss: 0.3183800936881262\n",
      "loss: 0.31884270492237743\n",
      "loss: 0.3182887537177413\n",
      "QNN: 0.1636962890625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 7\n",
      "SD: 0.1375732421875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.42522316479246514\n",
      "loss: 0.40953914276484166\n",
      "loss: 0.4075365978108468\n",
      "loss: 0.40715535211802\n",
      "loss: 0.40683720088673675\n",
      "loss: 0.4066447392975996\n",
      "loss: 0.405782643946095\n",
      "loss: 0.40726146157085247\n",
      "loss: 0.40635034236978\n",
      "loss: 0.40716863797328995\n",
      "loss: 0.40779528298152196\n",
      "loss: 0.40623039711954234\n",
      "loss: 0.40680312794521106\n",
      "loss: 0.40844969567150613\n",
      "loss: 0.40676247053425946\n",
      "loss: 0.4058843362698441\n",
      "loss: 0.4067321416786023\n",
      "loss: 0.4068494220413205\n",
      "loss: 0.4091108231297927\n",
      "loss: 0.4096501163558668\n",
      "loss: 0.40914208281178954\n",
      "loss: 0.4091972734634089\n",
      "loss: 0.41642840848769097\n",
      "loss: 0.4081460309935111\n",
      "loss: 0.41031434280368995\n",
      "loss: 0.4123610206319207\n",
      "loss: 0.41199192493837167\n",
      "loss: 0.40847649703851285\n",
      "loss: 0.40729335500647956\n",
      "loss: 0.40807466493388883\n",
      "loss: 0.4086196836655166\n",
      "loss: 0.41395677263763453\n",
      "loss: 0.4137344027915109\n",
      "loss: 0.40645506074847526\n",
      "loss: 0.4058152993671193\n",
      "loss: 0.40606558476828525\n",
      "loss: 0.4078289546141019\n",
      "loss: 0.407533221538464\n",
      "loss: 0.40656572607029623\n",
      "QNN: 0.2132568359375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 8\n",
      "SD: 0.1424560546875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.41354839439812674\n",
      "loss: 0.4027349677322116\n",
      "loss: 0.40080844551103284\n",
      "loss: 0.40099011141922997\n",
      "loss: 0.40046251396147164\n",
      "loss: 0.40034514454070275\n",
      "loss: 0.4012661602941781\n",
      "loss: 0.40333306713787503\n",
      "loss: 0.4044542863703058\n",
      "loss: 0.4085207545565741\n",
      "loss: 0.4092018683049224\n",
      "loss: 0.40592313622336995\n",
      "loss: 0.40686838403967956\n",
      "loss: 0.41043709674222717\n",
      "loss: 0.4157769770039253\n",
      "loss: 0.4125415353778036\n",
      "loss: 0.4065412259079201\n",
      "loss: 0.4076006298463245\n",
      "loss: 0.41056610666481097\n",
      "loss: 0.40639686506945094\n",
      "loss: 0.4047122413702764\n",
      "loss: 0.40503355970249744\n",
      "loss: 0.40241934663521656\n",
      "loss: 0.4022676139807986\n",
      "loss: 0.4042222497760895\n",
      "loss: 0.40062565251652904\n",
      "loss: 0.4001331426663642\n",
      "loss: 0.403780065666467\n",
      "loss: 0.40166796362739166\n",
      "loss: 0.39951871019247703\n",
      "loss: 0.39935712796426215\n",
      "loss: 0.39924455504458334\n",
      "loss: 0.3994672981679231\n",
      "loss: 0.40085162223854\n",
      "loss: 0.40100215121983684\n",
      "loss: 0.40076043266763833\n",
      "loss: 0.3991602013992617\n",
      "loss: 0.39904485365270487\n",
      "loss: 0.39937778735793145\n",
      "loss: 0.39923757712354463\n",
      "loss: 0.3995526965300195\n",
      "loss: 0.3995919883620421\n",
      "loss: 0.40036407390146894\n",
      "loss: 0.4001065169581283\n",
      "loss: 0.40344686245955425\n",
      "loss: 0.4030949399305509\n",
      "loss: 0.4003838671396764\n",
      "loss: 0.4013060963465484\n",
      "loss: 0.4015447936065752\n",
      "loss: 0.40022548293084625\n",
      "loss: 0.4029445662805163\n",
      "loss: 0.40155878691641966\n",
      "loss: 0.40104532573236534\n",
      "loss: 0.4006250957185511\n",
      "loss: 0.4008918134317577\n",
      "loss: 0.40207359254038194\n",
      "loss: 0.40033622140365266\n",
      "loss: 0.4009262039243904\n",
      "loss: 0.3999153116767649\n",
      "loss: 0.3997164702880069\n",
      "loss: 0.40036239372\n",
      "loss: 0.3995031240606318\n",
      "loss: 0.40075291087509846\n",
      "loss: 0.40247277820175137\n",
      "loss: 0.40224424968416395\n",
      "loss: 0.40262897000055037\n",
      "loss: 0.4085221825883128\n",
      "loss: 0.4088165359235693\n",
      "loss: 0.40192399196412687\n",
      "loss: 0.4034939450744387\n",
      "loss: 0.40372819673477767\n",
      "loss: 0.4006813737701901\n",
      "loss: 0.40226003611859157\n",
      "loss: 0.39986156645303933\n",
      "loss: 0.40001537492169675\n",
      "loss: 0.40056297739985974\n",
      "loss: 0.4000600922520012\n",
      "loss: 0.3994250042794943\n",
      "loss: 0.400654874458783\n",
      "loss: 0.40048879298136153\n",
      "loss: 0.4009547060644022\n",
      "loss: 0.40071071254796836\n",
      "loss: 0.40202836597615116\n",
      "loss: 0.4018923527579393\n",
      "loss: 0.40135686009741917\n",
      "loss: 0.4017648378814612\n",
      "loss: 0.4025078708779458\n",
      "loss: 0.40280698180715047\n",
      "loss: 0.40566916316884505\n",
      "loss: 0.4090585251116942\n",
      "loss: 0.4050126912569212\n",
      "loss: 0.40232473892279225\n",
      "loss: 0.40134391923815865\n",
      "loss: 0.4008274137035975\n",
      "loss: 0.40037406385339264\n",
      "loss: 0.3992829035190199\n",
      "loss: 0.3998502657849153\n",
      "loss: 0.4026723646857703\n",
      "loss: 0.4018362225623385\n",
      "loss: 0.4024106766057595\n",
      "loss: 0.40299076486021385\n",
      "loss: 0.4059741395193648\n",
      "loss: 0.40415508571179043\n",
      "loss: 0.4044188680176783\n",
      "loss: 0.4035835168089925\n",
      "loss: 0.4034179943603997\n",
      "loss: 0.4048039377225939\n",
      "loss: 0.40403638563618266\n",
      "loss: 0.40439279795159894\n",
      "loss: 0.40607197666723405\n",
      "loss: 0.4057446983920165\n",
      "loss: 0.4084491435364888\n",
      "loss: 0.4080668613369437\n",
      "loss: 0.40410765560501966\n",
      "loss: 0.40603420614455027\n",
      "loss: 0.4080887420715281\n",
      "loss: 0.4014877960071149\n",
      "loss: 0.40228660250308235\n",
      "loss: 0.39923572894318926\n",
      "loss: 0.4009782060579993\n",
      "loss: 0.39950602325447293\n",
      "loss: 0.3999872219390307\n",
      "loss: 0.39930203885034105\n",
      "loss: 0.3998024778493514\n",
      "loss: 0.3997244196781709\n",
      "loss: 0.3992512218159317\n",
      "loss: 0.4004211349543973\n",
      "loss: 0.40021148590354144\n",
      "loss: 0.4013669235961703\n",
      "loss: 0.4019989952840882\n",
      "loss: 0.4033596915457193\n",
      "loss: 0.39936660258057055\n",
      "loss: 0.39954927787553196\n",
      "loss: 0.4003654694256124\n",
      "loss: 0.3997976488543789\n",
      "loss: 0.40088700194865645\n",
      "loss: 0.4007523553195139\n",
      "loss: 0.3995369180582664\n",
      "loss: 0.3998823658833853\n",
      "loss: 0.4009082552174922\n",
      "loss: 0.40169407334573215\n",
      "loss: 0.4011436306950181\n",
      "loss: 0.40435284207797634\n",
      "loss: 0.40727826434351944\n",
      "loss: 0.4076379704333682\n",
      "loss: 0.404006401218018\n",
      "loss: 0.4051318872046614\n",
      "loss: 0.40018247836980425\n",
      "loss: 0.403662248135598\n",
      "loss: 0.40508151155107575\n",
      "loss: 0.4048244957665081\n",
      "loss: 0.4061110767334812\n",
      "loss: 0.4058769072932751\n",
      "loss: 0.40348136006651486\n",
      "loss: 0.40344268062792676\n",
      "loss: 0.4060297475668083\n",
      "loss: 0.40711068442289633\n",
      "loss: 0.4054557410758918\n",
      "loss: 0.40610833082824477\n",
      "loss: 0.4045447633118316\n",
      "loss: 0.40464238986092205\n",
      "loss: 0.40865515100925215\n",
      "loss: 0.4084088544660461\n",
      "loss: 0.40032210892420134\n",
      "loss: 0.399999704574072\n",
      "loss: 0.4015609429563259\n",
      "loss: 0.4024495853159935\n",
      "loss: 0.4023951588014122\n",
      "loss: 0.4047338271436196\n",
      "loss: 0.40542864197849304\n",
      "loss: 0.40261968951531524\n",
      "loss: 0.4048698223150332\n",
      "loss: 0.4037708402553263\n",
      "loss: 0.40361976912175446\n",
      "loss: 0.39965879501910856\n",
      "loss: 0.400404248739353\n",
      "loss: 0.40458744751671716\n",
      "loss: 0.4022047111132083\n",
      "loss: 0.40261594470089535\n",
      "loss: 0.4004803352062121\n",
      "loss: 0.4014345950784657\n",
      "loss: 0.4020103922565215\n",
      "loss: 0.4052831657553599\n",
      "loss: 0.40820865738705836\n",
      "loss: 0.41184257881360037\n",
      "loss: 0.41132745116849256\n",
      "loss: 0.4125134244325362\n",
      "loss: 0.4058385076689978\n",
      "loss: 0.40798571497081987\n",
      "loss: 0.4039955658103329\n",
      "loss: 0.4041514118585536\n",
      "loss: 0.4039404957244724\n",
      "loss: 0.4032257356704635\n",
      "loss: 0.40123677595768553\n",
      "loss: 0.4011223797851606\n",
      "loss: 0.39991999759830005\n",
      "loss: 0.4031425966440591\n",
      "loss: 0.40319179984602027\n",
      "loss: 0.40191121085196296\n",
      "loss: 0.40234237381404514\n",
      "loss: 0.4040108347883272\n",
      "loss: 0.400860666591314\n",
      "loss: 0.40031408026438836\n",
      "loss: 0.3998904291885602\n",
      "loss: 0.3999639298137175\n",
      "loss: 0.40119530480396853\n",
      "loss: 0.40087988016421044\n",
      "loss: 0.4039192591529171\n",
      "loss: 0.40184944078281176\n",
      "QNN: 0.215576171875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 9\n",
      "SD: 0.0919189453125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.43793371724250696\n",
      "loss: 0.43209462130518383\n",
      "loss: 0.4305881193881594\n",
      "loss: 0.42856728908061414\n",
      "loss: 0.4291878059652279\n",
      "loss: 0.42939924675707297\n",
      "loss: 0.42997609800160763\n",
      "loss: 0.4287670563633219\n",
      "loss: 0.4347023359771649\n",
      "loss: 0.4335212075371282\n",
      "loss: 0.429587771209369\n",
      "loss: 0.43767080767649275\n",
      "loss: 0.44881464606844107\n",
      "loss: 0.4469273037915006\n",
      "loss: 0.4405254382427873\n",
      "loss: 0.43308459760903967\n",
      "loss: 0.43208344443452484\n",
      "loss: 0.43135077879375844\n",
      "loss: 0.43217085964464363\n",
      "loss: 0.4300379229384074\n",
      "loss: 0.4272349996851845\n",
      "loss: 0.431042726925281\n",
      "loss: 0.43049835157836375\n",
      "loss: 0.43309292537714117\n",
      "loss: 0.43335380717247474\n",
      "loss: 0.4333609363551474\n",
      "loss: 0.43860241903444497\n",
      "loss: 0.43256052693085617\n",
      "loss: 0.4330338795695894\n",
      "QNN: 0.2110595703125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 10\n",
      "SD: 0.1708984375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.42733667425387145\n",
      "loss: 0.421262886984126\n",
      "loss: 0.4221715414502193\n",
      "loss: 0.42056427206968594\n",
      "loss: 0.4200357079547523\n",
      "loss: 0.42000291922939104\n",
      "loss: 0.4197651880467655\n",
      "loss: 0.42008063528829165\n",
      "loss: 0.41975470076368343\n",
      "loss: 0.42012217673054747\n",
      "loss: 0.4193992229049643\n",
      "loss: 0.41976097055055944\n",
      "loss: 0.4214369341169344\n",
      "loss: 0.4208149539013234\n",
      "loss: 0.41929297462277304\n",
      "loss: 0.4195583673508172\n",
      "loss: 0.4197129819225789\n",
      "loss: 0.4197273109608243\n",
      "loss: 0.4207784787468416\n",
      "loss: 0.4212262724626916\n",
      "loss: 0.4211154116714461\n",
      "loss: 0.41943873010034677\n",
      "loss: 0.4194695102113868\n",
      "loss: 0.4198060313936843\n",
      "loss: 0.4201502633805539\n",
      "loss: 0.4198150586352564\n",
      "loss: 0.42004991776421874\n",
      "loss: 0.41979650547824304\n",
      "loss: 0.4204043601747817\n",
      "QNN: 0.2156982421875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 11\n",
      "SD: 0.15283203125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.3688917429550328\n",
      "loss: 0.3463803022639423\n",
      "loss: 0.3425050301882854\n",
      "loss: 0.3427179130667268\n",
      "loss: 0.3417413620580281\n",
      "loss: 0.34111742098990666\n",
      "loss: 0.3405772893293739\n",
      "loss: 0.34028934838525626\n",
      "loss: 0.3420758560289247\n",
      "loss: 0.34313545827948644\n",
      "loss: 0.34750799510886904\n",
      "loss: 0.3472761214565188\n",
      "loss: 0.3464046601829332\n",
      "loss: 0.3475246505378307\n",
      "loss: 0.3458518712281134\n",
      "loss: 0.3432956888416666\n",
      "loss: 0.3471712899124864\n",
      "loss: 0.34308305488234775\n",
      "loss: 0.3436581532658671\n",
      "loss: 0.346226746564736\n",
      "loss: 0.3451554721098135\n",
      "loss: 0.3465319563897792\n",
      "loss: 0.3498679075160616\n",
      "loss: 0.3483533041217783\n",
      "loss: 0.34796126030498936\n",
      "loss: 0.3473616525327353\n",
      "loss: 0.3459980712561038\n",
      "loss: 0.3443808585333165\n",
      "loss: 0.3464313320552996\n",
      "loss: 0.34311979927091296\n",
      "loss: 0.34247454676575967\n",
      "loss: 0.3426524040432989\n",
      "loss: 0.34341202421130906\n",
      "loss: 0.3469430153442927\n",
      "loss: 0.3450426747573862\n",
      "loss: 0.34800854572356055\n",
      "loss: 0.350097540542833\n",
      "loss: 0.3481019845729442\n",
      "loss: 0.34525111465648883\n",
      "loss: 0.3435482892221137\n",
      "loss: 0.34255534100442336\n",
      "loss: 0.34062793257294866\n",
      "loss: 0.3406512937340285\n",
      "loss: 0.34043789275249287\n",
      "loss: 0.3407967633999806\n",
      "loss: 0.3404444223955287\n",
      "loss: 0.3406629718104904\n",
      "loss: 0.33998048345362303\n",
      "loss: 0.3418604833274104\n",
      "loss: 0.3412194384328128\n",
      "loss: 0.3411536673585063\n",
      "loss: 0.34070394938853416\n",
      "loss: 0.34136732000366315\n",
      "loss: 0.34065234622593643\n",
      "loss: 0.34101216305255355\n",
      "loss: 0.3435051068339558\n",
      "loss: 0.3471736140219809\n",
      "loss: 0.3451786309374429\n",
      "loss: 0.34378356789480247\n",
      "loss: 0.3437580933846169\n",
      "loss: 0.3455609735967745\n",
      "loss: 0.34379134915176185\n",
      "loss: 0.34245472388973985\n",
      "loss: 0.3418415013568167\n",
      "loss: 0.3435248380617291\n",
      "loss: 0.34741285096651203\n",
      "loss: 0.3485067233419622\n",
      "loss: 0.35008756131263513\n",
      "loss: 0.3483239504160182\n",
      "loss: 0.34776500640369157\n",
      "loss: 0.3483815783645033\n",
      "loss: 0.3483578336282841\n",
      "loss: 0.34915504546996745\n",
      "loss: 0.3441637810581661\n",
      "loss: 0.35093240340259024\n",
      "loss: 0.3530513864916944\n",
      "loss: 0.35540403808037263\n",
      "loss: 0.3537173023191574\n",
      "loss: 0.35087606096661766\n",
      "loss: 0.34529413672677073\n",
      "loss: 0.3437852932279858\n",
      "loss: 0.3427860096313754\n",
      "loss: 0.34314037038060696\n",
      "loss: 0.34533880821164975\n",
      "loss: 0.34848884706907074\n",
      "loss: 0.34893129157264424\n",
      "loss: 0.3465392057305905\n",
      "loss: 0.3412286767533525\n",
      "loss: 0.3401877695576309\n",
      "loss: 0.3404585055974723\n",
      "loss: 0.34068576954743995\n",
      "loss: 0.3410657581894405\n",
      "loss: 0.3409080204140865\n",
      "loss: 0.34092261376601946\n",
      "loss: 0.34164469220760246\n",
      "loss: 0.3432207298453451\n",
      "loss: 0.3467675855438202\n",
      "loss: 0.34551835304922324\n",
      "loss: 0.3469786360869584\n",
      "loss: 0.3527693307721598\n",
      "loss: 0.3473468340470229\n",
      "loss: 0.3486420139655873\n",
      "loss: 0.3464310235299363\n",
      "loss: 0.34085955764990594\n",
      "loss: 0.3408961565311417\n",
      "loss: 0.34242001478141326\n",
      "loss: 0.3443959712936318\n",
      "loss: 0.34114823819474016\n",
      "loss: 0.3422013508222285\n",
      "loss: 0.3429158969241576\n",
      "loss: 0.3437290083726532\n",
      "loss: 0.34262931073883385\n",
      "loss: 0.3422984628002806\n",
      "loss: 0.3428663923893365\n",
      "loss: 0.342867696478694\n",
      "loss: 0.340288558777182\n",
      "loss: 0.3405666817230981\n",
      "loss: 0.3408489933096452\n",
      "loss: 0.34076256827791546\n",
      "loss: 0.34210954735076315\n",
      "loss: 0.34183286797747814\n",
      "loss: 0.3416235264354754\n",
      "loss: 0.3446362237303046\n",
      "loss: 0.34826728391928075\n",
      "loss: 0.3524342574556354\n",
      "loss: 0.35254923065617005\n",
      "loss: 0.34708019384786243\n",
      "loss: 0.3536075642007578\n",
      "loss: 0.3471245707002007\n",
      "loss: 0.3429807012497788\n",
      "loss: 0.34368925548574664\n",
      "loss: 0.34238731269397665\n",
      "loss: 0.3490359263795522\n",
      "loss: 0.34797616228332406\n",
      "loss: 0.34482015727152504\n",
      "loss: 0.3451778148414947\n",
      "loss: 0.34497798550675335\n",
      "loss: 0.349388747171122\n",
      "loss: 0.35345181830249783\n",
      "loss: 0.3480616427599702\n",
      "loss: 0.34464518648444264\n",
      "loss: 0.34632949893667675\n",
      "loss: 0.34411300014286045\n",
      "loss: 0.3476131077655701\n",
      "loss: 0.3462247943787153\n",
      "loss: 0.3471301686603337\n",
      "loss: 0.349419526062909\n",
      "loss: 0.3440771853888416\n",
      "loss: 0.3476613821669913\n",
      "loss: 0.34866618929963655\n",
      "loss: 0.34679480781294275\n",
      "loss: 0.3467759360791631\n",
      "loss: 0.3491375023149844\n",
      "loss: 0.34847400609288226\n",
      "loss: 0.3487932267508458\n",
      "loss: 0.3495697661926687\n",
      "loss: 0.35516338665924785\n",
      "loss: 0.3491712168894518\n",
      "loss: 0.3504784476318016\n",
      "loss: 0.35316969076062854\n",
      "loss: 0.3494075666973489\n",
      "loss: 0.34323074242381274\n",
      "loss: 0.3448989387286318\n",
      "loss: 0.3415171260868382\n",
      "loss: 0.3419831028398062\n",
      "loss: 0.34042457982823465\n",
      "loss: 0.3406180302769691\n",
      "loss: 0.34215425769023294\n",
      "loss: 0.3416738272221048\n",
      "loss: 0.3421861003761283\n",
      "loss: 0.3421208091158211\n",
      "loss: 0.3455989150139302\n",
      "loss: 0.3438813635958298\n",
      "loss: 0.3492777326195492\n",
      "loss: 0.34250225788118155\n",
      "loss: 0.3406437747419049\n",
      "loss: 0.34213243063590487\n",
      "loss: 0.34203769293611824\n",
      "loss: 0.33999758673945696\n",
      "loss: 0.34087769563996695\n",
      "loss: 0.3401941794666244\n",
      "loss: 0.3404328142304821\n",
      "loss: 0.34070726510873794\n",
      "loss: 0.34243903052437363\n",
      "loss: 0.34082101003494597\n",
      "loss: 0.3423475341411776\n",
      "loss: 0.34416347190527374\n",
      "loss: 0.3464407596211692\n",
      "loss: 0.3426637635903689\n",
      "loss: 0.3459945689456468\n",
      "loss: 0.3452679992312812\n",
      "loss: 0.3478531529839002\n",
      "loss: 0.3521518430539203\n",
      "loss: 0.3553671388123569\n",
      "loss: 0.3493687656792962\n",
      "loss: 0.3472219159654572\n",
      "loss: 0.3467007128669546\n",
      "loss: 0.3437139415531542\n",
      "loss: 0.34115108062600374\n",
      "loss: 0.3408982043071589\n",
      "loss: 0.3419096346554733\n",
      "loss: 0.3417316754038929\n",
      "loss: 0.3412521648511382\n",
      "loss: 0.34012554597512246\n",
      "loss: 0.3409733704574438\n",
      "loss: 0.3407191904252837\n",
      "loss: 0.3400431896749874\n",
      "loss: 0.3406393504158727\n",
      "loss: 0.34016621306425066\n",
      "QNN: 0.168212890625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 12\n",
      "SD: 0.1043701171875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2601808043488091\n",
      "loss: 0.2231266379344874\n",
      "loss: 0.21487223315870113\n",
      "loss: 0.21212034450457498\n",
      "loss: 0.21091267591301882\n",
      "loss: 0.2104391588427019\n",
      "loss: 0.21047792806946178\n",
      "loss: 0.21030435197152433\n",
      "loss: 0.21024873392498913\n",
      "loss: 0.20965092740538288\n",
      "loss: 0.21002659981082777\n",
      "loss: 0.21047658475066464\n",
      "loss: 0.21027556458532606\n",
      "loss: 0.20960656172917913\n",
      "loss: 0.21000817311717238\n",
      "loss: 0.20980673282257\n",
      "loss: 0.20952265441189577\n",
      "loss: 0.20990879441126722\n",
      "loss: 0.20945864372475556\n",
      "QNN: 0.0933837890625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 13\n",
      "SD: 0.067138671875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.38127967991840833\n",
      "loss: 0.36086501943948146\n",
      "loss: 0.3534897517635476\n",
      "loss: 0.35151978905057457\n",
      "loss: 0.3507691172233255\n",
      "loss: 0.3507368683468127\n",
      "loss: 0.35012680180592287\n",
      "loss: 0.35012534894730635\n",
      "loss: 0.35077470443342335\n",
      "loss: 0.3498949093542529\n",
      "loss: 0.34997688441805014\n",
      "loss: 0.35069096687357365\n",
      "loss: 0.35014721430735707\n",
      "loss: 0.3506936553090162\n",
      "loss: 0.3501368004575561\n",
      "loss: 0.3523377232611265\n",
      "loss: 0.3518145264263212\n",
      "loss: 0.3504225007751824\n",
      "loss: 0.35114634427934854\n",
      "QNN: 0.155029296875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 14\n",
      "SD: 0.1402587890625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.48433535564109886\n",
      "loss: 0.4798859874073189\n",
      "loss: 0.48151233978794944\n",
      "loss: 0.4828294868193153\n",
      "loss: 0.483862919365895\n",
      "loss: 0.48086081463833663\n",
      "loss: 0.48276156229893885\n",
      "loss: 0.49025011039055777\n",
      "loss: 0.4951795604840116\n",
      "loss: 0.5083869078335979\n",
      "loss: 0.51176252206083\n",
      "loss: 0.5043991064566244\n",
      "loss: 0.5011423414229591\n",
      "loss: 0.5117939055015871\n",
      "loss: 0.4893708527213282\n",
      "loss: 0.49121285844005175\n",
      "loss: 0.47919699197835824\n",
      "loss: 0.5040683096630083\n",
      "loss: 0.49370666604180163\n",
      "loss: 0.49061723507377114\n",
      "loss: 0.5006060875993913\n",
      "loss: 0.5192181035276936\n",
      "loss: 0.49341608835603307\n",
      "loss: 0.4893069482456996\n",
      "loss: 0.49074114670439206\n",
      "loss: 0.4956414006949218\n",
      "loss: 0.5028613931452374\n",
      "loss: 0.5162223174719011\n",
      "loss: 0.48981261007313787\n",
      "loss: 0.4919267980936658\n",
      "loss: 0.5067106541290634\n",
      "loss: 0.5208298480008985\n",
      "loss: 0.503608003503575\n",
      "loss: 0.5019711510981225\n",
      "loss: 0.5050831206744107\n",
      "loss: 0.5079363267466372\n",
      "loss: 0.5012969368055512\n",
      "loss: 0.5042409615070488\n",
      "loss: 0.509449330237387\n",
      "loss: 0.515011364038762\n",
      "loss: 0.49444461876729906\n",
      "loss: 0.4979619419999114\n",
      "loss: 0.4942713909888842\n",
      "loss: 0.49226478658807116\n",
      "loss: 0.5072185049233834\n",
      "loss: 0.5124617555839909\n",
      "loss: 0.4911994903626551\n",
      "loss: 0.48790663426465725\n",
      "loss: 0.4851889593417522\n",
      "loss: 0.49725053408936737\n",
      "loss: 0.4945496146600342\n",
      "loss: 0.4993252898453493\n",
      "loss: 0.4985691382235723\n",
      "loss: 0.5158820651698035\n",
      "loss: 0.5068310096000694\n",
      "loss: 0.5113893454238198\n",
      "loss: 0.48961804445021595\n",
      "loss: 0.4860207133662052\n",
      "loss: 0.5034351685584784\n",
      "loss: 0.5082816921800715\n",
      "loss: 0.5122494911196133\n",
      "loss: 0.5149029627992979\n",
      "loss: 0.49858316153134496\n",
      "loss: 0.500517527914949\n",
      "loss: 0.48733686255341424\n",
      "loss: 0.5010401118357938\n",
      "loss: 0.4973895841298676\n",
      "loss: 0.5067476653216486\n",
      "loss: 0.49946439710741064\n",
      "loss: 0.5036510582512747\n",
      "loss: 0.5033207766585935\n",
      "loss: 0.5019163454427055\n",
      "loss: 0.5232342875628114\n",
      "loss: 0.5046320910068628\n",
      "loss: 0.48888743506506765\n",
      "loss: 0.49630170007114366\n",
      "loss: 0.4855258044230345\n",
      "loss: 0.4941926567319684\n",
      "loss: 0.4980330664357869\n",
      "loss: 0.5004958040083727\n",
      "loss: 0.49564275535081964\n",
      "loss: 0.5052541524564104\n",
      "loss: 0.49959747716630465\n",
      "loss: 0.5052193658818004\n",
      "loss: 0.5151035150527308\n",
      "loss: 0.5063157867869968\n",
      "loss: 0.494327914458031\n",
      "loss: 0.4942866560786023\n",
      "loss: 0.49986561395885903\n",
      "loss: 0.5018169419094142\n",
      "loss: 0.5134658313485821\n",
      "loss: 0.5093521139143499\n",
      "loss: 0.5063092101323186\n",
      "loss: 0.5031240204538198\n",
      "loss: 0.5055347419532392\n",
      "loss: 0.5047088053652617\n",
      "loss: 0.4986417596107135\n",
      "loss: 0.5018895247566999\n",
      "loss: 0.5009093700018018\n",
      "loss: 0.5160176510934965\n",
      "loss: 0.4887733633934726\n",
      "loss: 0.5023203765144659\n",
      "loss: 0.5060051854504052\n",
      "loss: 0.5116920678627178\n",
      "loss: 0.4997208986002756\n",
      "loss: 0.4956090555142659\n",
      "loss: 0.5040364819347014\n",
      "loss: 0.5076873500760888\n",
      "loss: 0.5113704664420062\n",
      "loss: 0.5060134834120679\n",
      "loss: 0.4928125608107928\n",
      "loss: 0.4853430660377476\n",
      "loss: 0.49556421837002584\n",
      "loss: 0.507419993819413\n",
      "loss: 0.4895369441998517\n",
      "loss: 0.49998169301420836\n",
      "loss: 0.5090848215967755\n",
      "loss: 0.512444023106585\n",
      "loss: 0.5004383813960556\n",
      "loss: 0.49814458050228816\n",
      "loss: 0.49200050750269203\n",
      "loss: 0.4978579450929418\n",
      "loss: 0.5045779065824476\n",
      "loss: 0.5007568099071901\n",
      "loss: 0.4888437164596439\n",
      "loss: 0.4955193280408386\n",
      "loss: 0.49304470219133506\n",
      "loss: 0.5113572848414223\n",
      "loss: 0.4951123351655895\n",
      "loss: 0.4979347128191661\n",
      "loss: 0.5087474119111292\n",
      "loss: 0.5117616289246613\n",
      "loss: 0.49789931980281615\n",
      "loss: 0.49719459339077526\n",
      "loss: 0.5001034496023424\n",
      "loss: 0.5086133097873446\n",
      "loss: 0.49100238264438184\n",
      "loss: 0.49326600683988475\n",
      "loss: 0.5078279731613573\n",
      "loss: 0.5278035794358703\n",
      "loss: 0.49980579103840106\n",
      "loss: 0.49538575356228387\n",
      "loss: 0.5039741604528083\n",
      "loss: 0.5130512676251912\n",
      "loss: 0.48800387551725255\n",
      "loss: 0.5014120273251844\n",
      "loss: 0.48811007688849783\n",
      "loss: 0.4960629418476094\n",
      "loss: 0.5055641892473381\n",
      "loss: 0.49865685684806277\n",
      "loss: 0.507091924047395\n",
      "loss: 0.504549732819607\n",
      "loss: 0.49664228597167664\n",
      "loss: 0.5071430238704411\n",
      "loss: 0.5024280957179992\n",
      "loss: 0.5095074014357286\n",
      "loss: 0.5000013574399894\n",
      "loss: 0.4945944955462296\n",
      "loss: 0.4924581865294477\n",
      "loss: 0.4932388233795296\n",
      "loss: 0.5062595905689314\n",
      "loss: 0.505949587041464\n",
      "loss: 0.49625257580872895\n",
      "loss: 0.4953601840676588\n",
      "loss: 0.4955865620574391\n",
      "loss: 0.4948926131123668\n",
      "loss: 0.49421406026496534\n",
      "loss: 0.4886600596031163\n",
      "loss: 0.48918229363200477\n",
      "loss: 0.4979689884758533\n",
      "loss: 0.4971898687085079\n",
      "loss: 0.5137814781432679\n",
      "loss: 0.5094049076144296\n",
      "loss: 0.5050165342828092\n",
      "loss: 0.501787386437919\n",
      "loss: 0.496717154482934\n",
      "loss: 0.5220170299021116\n",
      "loss: 0.5125249861688509\n",
      "loss: 0.5012583309775445\n",
      "loss: 0.4917114115493947\n",
      "loss: 0.4853147158180696\n",
      "loss: 0.49485391537394446\n",
      "loss: 0.4967836690220103\n",
      "loss: 0.5043862585236538\n",
      "loss: 0.49465411129530784\n",
      "loss: 0.48817949704742464\n",
      "loss: 0.49171506036011436\n",
      "loss: 0.5209523310455401\n",
      "loss: 0.5053274012634994\n",
      "loss: 0.5054897987801197\n",
      "loss: 0.488073230515743\n",
      "loss: 0.4965482710793246\n",
      "loss: 0.5071546800477412\n",
      "loss: 0.5173894907349019\n",
      "loss: 0.48927350675165276\n",
      "loss: 0.49599424255274205\n",
      "loss: 0.5043838983829133\n",
      "loss: 0.5058808309565164\n",
      "loss: 0.5127811782117356\n",
      "loss: 0.5156450589838256\n",
      "loss: 0.5029483937654258\n",
      "loss: 0.5008441033474349\n",
      "loss: 0.5010965195518914\n",
      "loss: 0.4908562407809762\n",
      "loss: 0.491062202379648\n",
      "loss: 0.4973899269753305\n",
      "loss: 0.48913412897515246\n",
      "loss: 0.4969816311834452\n",
      "loss: 0.4985605399596504\n",
      "loss: 0.5135399786265822\n",
      "loss: 0.4920563735584637\n",
      "loss: 0.4932396172820704\n",
      "loss: 0.4994799556057119\n",
      "loss: 0.5045430926800095\n",
      "loss: 0.5015870890421473\n",
      "loss: 0.5099589834318657\n",
      "loss: 0.48346452582002114\n",
      "loss: 0.48506352071015346\n",
      "loss: 0.4986453294746994\n",
      "QNN: 0.2655029296875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 15\n",
      "SD: 0.129150390625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.3689862557248139\n",
      "loss: 0.33757428174824666\n",
      "loss: 0.33258426918878375\n",
      "loss: 0.3320219320677311\n",
      "loss: 0.33120378309875526\n",
      "loss: 0.33408983576453977\n",
      "loss: 0.3324169307704111\n",
      "loss: 0.3318625110985634\n",
      "loss: 0.3309390553736451\n",
      "loss: 0.3320748932088716\n",
      "loss: 0.3335113433647102\n",
      "loss: 0.33542702081627307\n",
      "loss: 0.3334430488470029\n",
      "loss: 0.33139700839927544\n",
      "loss: 0.3306869273767239\n",
      "loss: 0.3309528995029298\n",
      "loss: 0.3308258590382657\n",
      "loss: 0.330648582706838\n",
      "loss: 0.3311873697377857\n",
      "QNN: 0.1624755859375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 16\n",
      "SD: 0.075439453125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.35045487204794606\n",
      "loss: 0.33824269589106387\n",
      "loss: 0.3367483768261578\n",
      "loss: 0.33623368392933856\n",
      "loss: 0.3357145903723216\n",
      "loss: 0.33630257114646067\n",
      "loss: 0.33519445585538227\n",
      "loss: 0.33563732459240014\n",
      "loss: 0.33573714276812244\n",
      "loss: 0.3364731188104066\n",
      "loss: 0.33608465851816327\n",
      "loss: 0.33676983758518914\n",
      "loss: 0.3410577545802652\n",
      "loss: 0.3427520995056882\n",
      "loss: 0.3459082343163496\n",
      "loss: 0.3463205064379057\n",
      "loss: 0.340987284698992\n",
      "loss: 0.3404725634487243\n",
      "loss: 0.34663344501543236\n",
      "loss: 0.34667221830021666\n",
      "loss: 0.33831685545068124\n",
      "loss: 0.3416352372329418\n",
      "loss: 0.3407079016090295\n",
      "loss: 0.34605691980177844\n",
      "loss: 0.33707211768243006\n",
      "loss: 0.3364718142671207\n",
      "loss: 0.33606352093128844\n",
      "loss: 0.3385342463956479\n",
      "loss: 0.3395787098653385\n",
      "loss: 0.33784746949008815\n",
      "loss: 0.3378492546303729\n",
      "loss: 0.34248462279355135\n",
      "loss: 0.3493437444192936\n",
      "loss: 0.3489829491289305\n",
      "loss: 0.34365505151708153\n",
      "loss: 0.3413326973630731\n",
      "loss: 0.33720368026133757\n",
      "loss: 0.34307872270964673\n",
      "loss: 0.34332730198455996\n",
      "loss: 0.342759518255377\n",
      "loss: 0.3397624588891802\n",
      "loss: 0.3440928177065378\n",
      "loss: 0.3438711241698928\n",
      "loss: 0.3439019394613158\n",
      "loss: 0.3414372128012977\n",
      "loss: 0.3379811823599603\n",
      "loss: 0.3374496070846508\n",
      "loss: 0.33758848500014194\n",
      "loss: 0.33854928420060526\n",
      "loss: 0.3365768882264498\n",
      "loss: 0.33664625754561\n",
      "loss: 0.3350953017933146\n",
      "loss: 0.3352495608853311\n",
      "loss: 0.337111435994563\n",
      "loss: 0.33681366179181166\n",
      "loss: 0.3358107385930452\n",
      "loss: 0.3363834153994448\n",
      "loss: 0.3386706123785204\n",
      "loss: 0.33948118332881955\n",
      "QNN: 0.1612548828125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 17\n",
      "SD: 0.1446533203125\n",
      "loss: 0.6931471805599462\n",
      "loss: 0.44149545621194436\n",
      "loss: 0.4362046115442417\n",
      "loss: 0.44374475346552206\n",
      "loss: 0.43854007537563355\n",
      "loss: 0.44475020148988387\n",
      "loss: 0.4416761859169883\n",
      "loss: 0.4500229829248586\n",
      "loss: 0.4551543548775573\n",
      "loss: 0.4521304893360933\n",
      "loss: 0.45101470414301437\n",
      "loss: 0.441016494774006\n",
      "loss: 0.4454181530233044\n",
      "loss: 0.44544777757537607\n",
      "loss: 0.4376409011194518\n",
      "loss: 0.43638997391195894\n",
      "loss: 0.4377411704388314\n",
      "loss: 0.43801605045157066\n",
      "loss: 0.4324983026576737\n",
      "loss: 0.4321651451451909\n",
      "loss: 0.43368232451330674\n",
      "loss: 0.4448803708143951\n",
      "loss: 0.4473799622301436\n",
      "loss: 0.4397402353449048\n",
      "loss: 0.4374476397611156\n",
      "loss: 0.44576724121702044\n",
      "loss: 0.44197389925570785\n",
      "loss: 0.4451655383365114\n",
      "loss: 0.4442927132863144\n",
      "loss: 0.438164366975754\n",
      "loss: 0.43747089773660836\n",
      "loss: 0.43465679707657623\n",
      "loss: 0.4348750640810928\n",
      "loss: 0.4413019675997489\n",
      "loss: 0.43788567880136287\n",
      "loss: 0.4382205457665444\n",
      "loss: 0.4366304005321284\n",
      "loss: 0.4342578440073599\n",
      "loss: 0.43293580329359077\n",
      "loss: 0.42855025945877473\n",
      "loss: 0.42829937241471366\n",
      "loss: 0.432781888153798\n",
      "loss: 0.42955949700722673\n",
      "loss: 0.43048948801948383\n",
      "loss: 0.4355521365954662\n",
      "loss: 0.4418239221883363\n",
      "loss: 0.44345661394963365\n",
      "loss: 0.4458332264435935\n",
      "loss: 0.45425819877866724\n",
      "loss: 0.4630097506917939\n",
      "loss: 0.4458871026851127\n",
      "loss: 0.43629744642450874\n",
      "loss: 0.43305168130979393\n",
      "loss: 0.4331935155298114\n",
      "loss: 0.43518095061478207\n",
      "loss: 0.43720194180575706\n",
      "loss: 0.44617578266445673\n",
      "loss: 0.4450488968839049\n",
      "loss: 0.44248186416464286\n",
      "loss: 0.4379460388702531\n",
      "loss: 0.43829075007700935\n",
      "loss: 0.43798850971812153\n",
      "loss: 0.4469290756021531\n",
      "loss: 0.44850378316925915\n",
      "loss: 0.45099158517303845\n",
      "loss: 0.4576586104353584\n",
      "loss: 0.4415765895352527\n",
      "loss: 0.4430772482128279\n",
      "loss: 0.4357413716759376\n",
      "loss: 0.4306253168974929\n",
      "loss: 0.43582043866477244\n",
      "loss: 0.43889291238354233\n",
      "loss: 0.4304450598991621\n",
      "loss: 0.43051673485789743\n",
      "loss: 0.4330567132859904\n",
      "loss: 0.4332350028879957\n",
      "loss: 0.43388236331678626\n",
      "loss: 0.4366875182325309\n",
      "loss: 0.4340813995608583\n",
      "loss: 0.43782514061232247\n",
      "loss: 0.4418478486999508\n",
      "loss: 0.43818264202857554\n",
      "loss: 0.4439726049351654\n",
      "loss: 0.4387800369415658\n",
      "loss: 0.43721339448635826\n",
      "loss: 0.43549456692371913\n",
      "loss: 0.43112932877081556\n",
      "loss: 0.4365852339088646\n",
      "loss: 0.440756463661075\n",
      "loss: 0.44573882822627725\n",
      "loss: 0.4339157289386659\n",
      "loss: 0.4328898992742198\n",
      "loss: 0.43169115629692034\n",
      "loss: 0.4316747158184466\n",
      "loss: 0.43478765002008635\n",
      "loss: 0.45061144526093533\n",
      "loss: 0.44749068146919707\n",
      "loss: 0.43988690160215377\n",
      "loss: 0.4368239964464564\n",
      "loss: 0.43555123802579165\n",
      "loss: 0.443958425197414\n",
      "loss: 0.44499983702890233\n",
      "loss: 0.4358251313194241\n",
      "loss: 0.4285470931177596\n",
      "loss: 0.4293739548983885\n",
      "loss: 0.43579414648776144\n",
      "loss: 0.4311023731612306\n",
      "loss: 0.4348641188271489\n",
      "loss: 0.43081850211404904\n",
      "loss: 0.4343779880503483\n",
      "loss: 0.43958959977607803\n",
      "loss: 0.44911997788068825\n",
      "loss: 0.4373253822130399\n",
      "loss: 0.4404623783879256\n",
      "loss: 0.4360330783979712\n",
      "loss: 0.43608036833034264\n",
      "loss: 0.4325027963262645\n",
      "loss: 0.43298598443355446\n",
      "loss: 0.43692337740093745\n",
      "loss: 0.4379553201510567\n",
      "loss: 0.44617297054381283\n",
      "loss: 0.44347012241896194\n",
      "loss: 0.43994968343017715\n",
      "loss: 0.4413783036682247\n",
      "loss: 0.43557948519465634\n",
      "loss: 0.43202536740758235\n",
      "loss: 0.4311561659891119\n",
      "loss: 0.42998757191027304\n",
      "loss: 0.4331459828930426\n",
      "loss: 0.43782360592994074\n",
      "QNN: 0.220947265625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 18\n",
      "SD: 0.1304931640625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3748109944633961\n",
      "loss: 0.3452114787643012\n",
      "loss: 0.3412517695032038\n",
      "loss: 0.3385604284981494\n",
      "loss: 0.3356236337119669\n",
      "loss: 0.3357745654486057\n",
      "loss: 0.3360274685524767\n",
      "loss: 0.33721268823494305\n",
      "loss: 0.3375460754459392\n",
      "loss: 0.3369569774869371\n",
      "loss: 0.33754383980953434\n",
      "loss: 0.33536336621675944\n",
      "loss: 0.3356892705813288\n",
      "loss: 0.3357462478882506\n",
      "loss: 0.33620021995074006\n",
      "loss: 0.3387252221219461\n",
      "loss: 0.34310630053834235\n",
      "loss: 0.34121396465675025\n",
      "loss: 0.34185605110322614\n",
      "loss: 0.33733355397848996\n",
      "loss: 0.3411860588062302\n",
      "loss: 0.34045874979720936\n",
      "loss: 0.34018534720311566\n",
      "loss: 0.34027090132240906\n",
      "loss: 0.3407172103851171\n",
      "loss: 0.34100453381380136\n",
      "loss: 0.34054930251417787\n",
      "loss: 0.3401861885815929\n",
      "loss: 0.343844327097713\n",
      "loss: 0.34501942827881465\n",
      "loss: 0.34090980258700443\n",
      "loss: 0.34770216915725694\n",
      "loss: 0.34870900782760017\n",
      "loss: 0.34195368863819237\n",
      "loss: 0.3415372940473264\n",
      "loss: 0.34063598620695335\n",
      "loss: 0.3398237319971932\n",
      "loss: 0.3416715208468388\n",
      "loss: 0.34705696524802676\n",
      "loss: 0.3433668504844296\n",
      "loss: 0.3376006497687735\n",
      "loss: 0.33705771429107634\n",
      "loss: 0.335686746653885\n",
      "loss: 0.33683351975055864\n",
      "loss: 0.34069573545582954\n",
      "loss: 0.3437155294423405\n",
      "loss: 0.3469308313843037\n",
      "loss: 0.34149951044172\n",
      "loss: 0.3399740911666648\n",
      "loss: 0.33783932901003555\n",
      "loss: 0.33926527776445803\n",
      "loss: 0.3433106881218778\n",
      "loss: 0.34364561551722056\n",
      "loss: 0.3418586663067756\n",
      "loss: 0.3416084401125219\n",
      "loss: 0.3399472521564785\n",
      "loss: 0.3444028091908111\n",
      "loss: 0.34378018827859574\n",
      "loss: 0.34084399605006144\n",
      "QNN: 0.15625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 19\n",
      "SD: 0.1337890625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.45071836628140355\n",
      "loss: 0.44247505060669357\n",
      "loss: 0.44155940694952217\n",
      "loss: 0.4404843682847796\n",
      "loss: 0.4396293691900241\n",
      "loss: 0.44028395435084877\n",
      "loss: 0.44070269716758487\n",
      "loss: 0.43947879559687947\n",
      "loss: 0.43890781685685804\n",
      "loss: 0.43935214472332784\n",
      "loss: 0.4404385656976056\n",
      "loss: 0.44306820666986474\n",
      "loss: 0.44279259718277997\n",
      "loss: 0.4460588463306519\n",
      "loss: 0.4418338584767385\n",
      "loss: 0.4459351322617271\n",
      "loss: 0.4427133528414636\n",
      "loss: 0.4421157785718059\n",
      "loss: 0.43833105107627846\n",
      "QNN: 0.2347412109375\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 20\n",
      "SD: 0.0517578125\n",
      "loss: 0.6931471805599465\n",
      "loss: 0.36702384518200554\n",
      "loss: 0.3550102630678003\n",
      "loss: 0.35506228321547434\n",
      "loss: 0.36172211028561513\n",
      "loss: 0.36294541489404525\n",
      "loss: 0.3678946802860739\n",
      "loss: 0.3667473973710567\n",
      "loss: 0.3591563047454925\n",
      "loss: 0.3590223975309166\n",
      "loss: 0.3555937898630875\n",
      "loss: 0.35713704087615744\n",
      "loss: 0.3589637666016552\n",
      "loss: 0.365678348037134\n",
      "loss: 0.3656338957226762\n",
      "loss: 0.36186405265383687\n",
      "loss: 0.36003440804052694\n",
      "loss: 0.3626228361974497\n",
      "loss: 0.3596825736043077\n",
      "loss: 0.3636760400660828\n",
      "loss: 0.363754613878579\n",
      "loss: 0.36638716093485596\n",
      "loss: 0.3651870102393104\n",
      "loss: 0.3665680438826676\n",
      "loss: 0.3629677462085167\n",
      "loss: 0.36165235461662826\n",
      "loss: 0.3566780302549068\n",
      "loss: 0.3535582697477871\n",
      "loss: 0.3555386476851543\n",
      "loss: 0.36266670792763506\n",
      "loss: 0.3584676205968481\n",
      "loss: 0.35722415337855434\n",
      "loss: 0.3662947137326351\n",
      "loss: 0.36292359337489016\n",
      "loss: 0.3659354174195313\n",
      "loss: 0.3695638669941778\n",
      "loss: 0.35927259927557564\n",
      "loss: 0.3550314452519196\n",
      "loss: 0.35610348522703705\n",
      "loss: 0.3593216621715247\n",
      "loss: 0.35541318720062276\n",
      "loss: 0.3572924036816813\n",
      "loss: 0.35745781266588883\n",
      "loss: 0.3557169603190053\n",
      "loss: 0.35457120054340296\n",
      "loss: 0.3537840361713291\n",
      "loss: 0.3507458891869164\n",
      "loss: 0.3512101508703044\n",
      "loss: 0.3527598533074502\n",
      "loss: 0.3539913091474169\n",
      "loss: 0.3553914008753255\n",
      "loss: 0.3583334281227755\n",
      "loss: 0.3573608459017883\n",
      "loss: 0.3593096210198131\n",
      "loss: 0.36153753620525314\n",
      "loss: 0.36696481864281844\n",
      "loss: 0.3715878005442253\n",
      "loss: 0.36986663797745883\n",
      "loss: 0.3609531959686348\n",
      "loss: 0.3666442203006957\n",
      "loss: 0.35894005665394246\n",
      "loss: 0.3592611042196729\n",
      "loss: 0.35493969521936725\n",
      "loss: 0.35831916888994053\n",
      "loss: 0.36024947530796003\n",
      "loss: 0.35779596904691746\n",
      "loss: 0.3537758324353337\n",
      "loss: 0.3563148672249356\n",
      "loss: 0.3526629359875277\n",
      "loss: 0.35280247339500087\n",
      "loss: 0.3556964588769886\n",
      "loss: 0.3546620960070249\n",
      "loss: 0.3520585660547117\n",
      "loss: 0.3538657415446927\n",
      "loss: 0.3549671292235194\n",
      "loss: 0.36911668988863416\n",
      "loss: 0.3617258592272063\n",
      "loss: 0.3683557987520483\n",
      "loss: 0.3680249633676254\n",
      "loss: 0.3647965386211737\n",
      "loss: 0.36284563211997556\n",
      "loss: 0.3598128396616793\n",
      "loss: 0.3549464877403844\n",
      "loss: 0.35279504862543437\n",
      "loss: 0.35050908471120523\n",
      "loss: 0.3518450976650939\n",
      "loss: 0.3502490690215797\n",
      "loss: 0.35017816755498576\n",
      "loss: 0.35023852290759366\n",
      "loss: 0.35040034538467163\n",
      "loss: 0.35061983371225575\n",
      "loss: 0.35146604392296077\n",
      "loss: 0.35202672432277576\n",
      "loss: 0.352517028334886\n",
      "loss: 0.35117865226277806\n",
      "loss: 0.3518772279781216\n",
      "loss: 0.3508115292174691\n",
      "loss: 0.35075368448634686\n",
      "loss: 0.35049399299773126\n",
      "loss: 0.3506134892160926\n",
      "QNN: 0.1680908203125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 21\n",
      "SD: 0.1298828125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3364759510428172\n",
      "loss: 0.30735916441038885\n",
      "loss: 0.3016356242543105\n",
      "loss: 0.30130337627389664\n",
      "loss: 0.30079499628370504\n",
      "loss: 0.30051809791182643\n",
      "loss: 0.30042386529867116\n",
      "loss: 0.300935664966201\n",
      "loss: 0.3004021224975912\n",
      "loss: 0.3005401740734857\n",
      "loss: 0.3002608234224837\n",
      "loss: 0.301146889042445\n",
      "loss: 0.3006671259158074\n",
      "loss: 0.30030046729577786\n",
      "loss: 0.3004101498134779\n",
      "loss: 0.3003509415050979\n",
      "loss: 0.30043131110892596\n",
      "loss: 0.3004200966516183\n",
      "loss: 0.30036580701664833\n",
      "QNN: 0.1485595703125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 22\n",
      "SD: 0.119384765625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.39630253517037006\n",
      "loss: 0.36592916106362017\n",
      "loss: 0.36535437055640085\n",
      "loss: 0.3753410131442332\n",
      "loss: 0.39187306783393094\n",
      "loss: 0.4097484413233029\n",
      "loss: 0.3979704870478386\n",
      "loss: 0.40265204643398633\n",
      "loss: 0.38917059450053226\n",
      "loss: 0.3834882915259415\n",
      "loss: 0.37312674954892877\n",
      "loss: 0.38022900784544\n",
      "loss: 0.3743342290793667\n",
      "loss: 0.3865806037256519\n",
      "loss: 0.38847080035063003\n",
      "loss: 0.3825415815657887\n",
      "loss: 0.38612032816397285\n",
      "loss: 0.38202865102880335\n",
      "loss: 0.3773362083692306\n",
      "loss: 0.3905443733305625\n",
      "loss: 0.4071693546965718\n",
      "loss: 0.4053800290807911\n",
      "loss: 0.37068362518330145\n",
      "loss: 0.36260421653404884\n",
      "loss: 0.3726194454866028\n",
      "loss: 0.3889541717859463\n",
      "loss: 0.37832916098117136\n",
      "loss: 0.36301872739175534\n",
      "loss: 0.3677240848811589\n",
      "loss: 0.3845917372255837\n",
      "loss: 0.4008296258025024\n",
      "loss: 0.3895039537673508\n",
      "loss: 0.39109976986418427\n",
      "loss: 0.39582238063053665\n",
      "loss: 0.39016522405130566\n",
      "loss: 0.3842501001695682\n",
      "loss: 0.3876548559122919\n",
      "loss: 0.3848664298825886\n",
      "loss: 0.3873053911482598\n",
      "loss: 0.40714274539661954\n",
      "loss: 0.3904678705143196\n",
      "loss: 0.38884657950323365\n",
      "loss: 0.3855147487446437\n",
      "loss: 0.38126174057109946\n",
      "loss: 0.37952791310755807\n",
      "loss: 0.37851181762292474\n",
      "loss: 0.3792700512210113\n",
      "loss: 0.39846896726245556\n",
      "loss: 0.3948081718333642\n",
      "loss: 0.3916733780383739\n",
      "loss: 0.386998031090846\n",
      "loss: 0.389468849770744\n",
      "loss: 0.3934736752918629\n",
      "loss: 0.3883734893655597\n",
      "loss: 0.3979646505560578\n",
      "loss: 0.38569238653858556\n",
      "loss: 0.38571353925387114\n",
      "loss: 0.37589580573643033\n",
      "loss: 0.37041321593949983\n",
      "loss: 0.3780710698403294\n",
      "loss: 0.41138585590466503\n",
      "loss: 0.40075850438639926\n",
      "loss: 0.38384674408091735\n",
      "loss: 0.36970729282361825\n",
      "loss: 0.3639309423377324\n",
      "loss: 0.37848680715847854\n",
      "loss: 0.38104110554733056\n",
      "loss: 0.3789928943115504\n",
      "loss: 0.378038197185974\n",
      "loss: 0.36995660789110646\n",
      "loss: 0.390539616737801\n",
      "loss: 0.4165440056452838\n",
      "loss: 0.39993170354707014\n",
      "loss: 0.39041963292300513\n",
      "loss: 0.38282986469283137\n",
      "loss: 0.3801608704497749\n",
      "loss: 0.38790835022933234\n",
      "loss: 0.39869850521294936\n",
      "loss: 0.3836597997401278\n",
      "loss: 0.3758301616181744\n",
      "loss: 0.38282423989076775\n",
      "loss: 0.37981131793056383\n",
      "loss: 0.3971945449293635\n",
      "loss: 0.39085814239136446\n",
      "loss: 0.3959506293291335\n",
      "loss: 0.3861339156320259\n",
      "loss: 0.38328237606685656\n",
      "loss: 0.389584743239192\n",
      "loss: 0.37878681895734123\n",
      "loss: 0.3887600964639921\n",
      "loss: 0.3889131610734693\n",
      "loss: 0.38333925637741795\n",
      "loss: 0.37208820910523066\n",
      "loss: 0.370087165570973\n",
      "loss: 0.3750074695034308\n",
      "loss: 0.38720224345733023\n",
      "loss: 0.39636517118562187\n",
      "loss: 0.3941281101059093\n",
      "loss: 0.40130238983580563\n",
      "loss: 0.3837064553313769\n",
      "loss: 0.3787145520437322\n",
      "loss: 0.38513017687902945\n",
      "loss: 0.3900555726771548\n",
      "loss: 0.38540243996014667\n",
      "loss: 0.38353762787359674\n",
      "loss: 0.38509858061419194\n",
      "loss: 0.3852531445023383\n",
      "loss: 0.3890980668689873\n",
      "loss: 0.40155823465399093\n",
      "QNN: 0.203857421875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 23\n",
      "SD: 0.168701171875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.4419976697877965\n",
      "loss: 0.4257506374892478\n",
      "loss: 0.4227515931495335\n",
      "loss: 0.42266445479199455\n",
      "loss: 0.423458028959653\n",
      "loss: 0.4232148860755233\n",
      "loss: 0.4221542947503585\n",
      "loss: 0.4243189482368539\n",
      "loss: 0.42127645518053947\n",
      "loss: 0.4231008985365519\n",
      "loss: 0.42502152788206704\n",
      "loss: 0.4230231975933946\n",
      "loss: 0.4215516037799969\n",
      "loss: 0.42027043678188575\n",
      "loss: 0.4206426229323527\n",
      "loss: 0.4196752627591492\n",
      "loss: 0.4201950322912425\n",
      "loss: 0.4198794389650255\n",
      "loss: 0.41998018645132845\n",
      "loss: 0.4202286136454001\n",
      "loss: 0.4201379295484802\n",
      "loss: 0.42037584935334776\n",
      "loss: 0.4198526494280294\n",
      "loss: 0.4206708813623943\n",
      "loss: 0.4233966622900621\n",
      "loss: 0.4268279864647204\n",
      "loss: 0.42897334279574706\n",
      "loss: 0.42452025949077044\n",
      "loss: 0.42279629248410877\n",
      "loss: 0.42560467193997564\n",
      "loss: 0.42304609303803314\n",
      "loss: 0.4203267655729171\n",
      "loss: 0.42047345102170064\n",
      "loss: 0.42131012577165144\n",
      "loss: 0.420975240622506\n",
      "loss: 0.4203151014244658\n",
      "loss: 0.42017259347964314\n",
      "loss: 0.42092507857481504\n",
      "loss: 0.4211115830006079\n",
      "loss: 0.42103335224398625\n",
      "loss: 0.41995333910961563\n",
      "loss: 0.4207290058936266\n",
      "loss: 0.4200813061396915\n",
      "loss: 0.4213888537232898\n",
      "loss: 0.42009804965547626\n",
      "loss: 0.4203293934831035\n",
      "loss: 0.41979518624519896\n",
      "loss: 0.4203933613693996\n",
      "loss: 0.41994236368339377\n",
      "loss: 0.4211050291900205\n",
      "loss: 0.4230827470334895\n",
      "loss: 0.42068541395043546\n",
      "loss: 0.42140693647796146\n",
      "loss: 0.4203327587272244\n",
      "loss: 0.4209526865756827\n",
      "loss: 0.4225445782190526\n",
      "loss: 0.4218579209058614\n",
      "loss: 0.4215302167106673\n",
      "loss: 0.4222255634261242\n",
      "loss: 0.42257374619325433\n",
      "loss: 0.42063605347508004\n",
      "loss: 0.42074279631110795\n",
      "loss: 0.42235851871142405\n",
      "loss: 0.4230548004260881\n",
      "loss: 0.42280389407714614\n",
      "loss: 0.421010051018015\n",
      "loss: 0.42141531232099594\n",
      "loss: 0.42140329429447837\n",
      "loss: 0.42077833003108134\n",
      "loss: 0.4224697153883506\n",
      "loss: 0.42313380330935113\n",
      "loss: 0.4251209063565268\n",
      "loss: 0.42000658720946465\n",
      "loss: 0.4200113223235949\n",
      "loss: 0.41982528877513714\n",
      "loss: 0.42092242360441584\n",
      "loss: 0.42162603772123824\n",
      "loss: 0.42259108513971005\n",
      "loss: 0.4213646933449223\n",
      "QNN: 0.1998291015625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 24\n",
      "SD: 0.0860595703125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3076195365188119\n",
      "loss: 0.2871080229942847\n",
      "loss: 0.2866007969671348\n",
      "loss: 0.2846533169902319\n",
      "loss: 0.2807338493072669\n",
      "loss: 0.2827327882666847\n",
      "loss: 0.28659059558358485\n",
      "loss: 0.28897884419471265\n",
      "loss: 0.2881119123653144\n",
      "loss: 0.2830887211615039\n",
      "loss: 0.2806423029486514\n",
      "loss: 0.2794379414250567\n",
      "loss: 0.2809018673776156\n",
      "loss: 0.27997222142843053\n",
      "loss: 0.27930335989515626\n",
      "loss: 0.2799686167491938\n",
      "loss: 0.2795506402645836\n",
      "loss: 0.28135797050440525\n",
      "loss: 0.2813343159056267\n",
      "loss: 0.2819572007874705\n",
      "loss: 0.2834120936461797\n",
      "loss: 0.27847375065058866\n",
      "loss: 0.28015323946135234\n",
      "loss: 0.280926580583069\n",
      "loss: 0.27773501386947447\n",
      "loss: 0.2768754618176959\n",
      "loss: 0.27646246961807847\n",
      "loss: 0.27656347990282654\n",
      "loss: 0.2770691303021227\n",
      "loss: 0.276815873194581\n",
      "loss: 0.2768051335367404\n",
      "loss: 0.27660284476846114\n",
      "loss: 0.2771665431013456\n",
      "loss: 0.2769996972209263\n",
      "loss: 0.27641853748706313\n",
      "loss: 0.2792853554887009\n",
      "loss: 0.2790470238979265\n",
      "loss: 0.2804328674113092\n",
      "loss: 0.27807328503966133\n",
      "loss: 0.27965511806873866\n",
      "loss: 0.2782373853093135\n",
      "loss: 0.2783645691129641\n",
      "loss: 0.27971241919031536\n",
      "loss: 0.27987383727064197\n",
      "loss: 0.27970666568854824\n",
      "loss: 0.2785915545045875\n",
      "loss: 0.27836397907588\n",
      "loss: 0.27798532825634853\n",
      "loss: 0.2808460483988672\n",
      "loss: 0.2808124559091295\n",
      "loss: 0.2814608466705762\n",
      "loss: 0.2807446085713579\n",
      "loss: 0.28226004443451574\n",
      "loss: 0.28283710605790174\n",
      "loss: 0.28940465613042626\n",
      "loss: 0.28389303612364003\n",
      "loss: 0.28350107648207834\n",
      "loss: 0.2817822563313974\n",
      "loss: 0.284665988766957\n",
      "loss: 0.28222318279680736\n",
      "loss: 0.28201145965636604\n",
      "loss: 0.2814480477044803\n",
      "loss: 0.2813864931461205\n",
      "loss: 0.2780572150631302\n",
      "loss: 0.2798300328632719\n",
      "loss: 0.2801802262012402\n",
      "loss: 0.27697745533416995\n",
      "loss: 0.2777158401597928\n",
      "loss: 0.2774154229404643\n",
      "loss: 0.27787678965043655\n",
      "loss: 0.2787433663441203\n",
      "loss: 0.2772900613806039\n",
      "loss: 0.2795866721883355\n",
      "loss: 0.28276978744695785\n",
      "loss: 0.28495112319740806\n",
      "loss: 0.2787484571298891\n",
      "loss: 0.2794782788008003\n",
      "loss: 0.27904289345493205\n",
      "loss: 0.277075449862592\n",
      "QNN: 0.138916015625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 25\n",
      "SD: 0.139892578125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.41261721284635117\n",
      "loss: 0.3701859417617461\n",
      "loss: 0.3673497389723531\n",
      "loss: 0.36763027956699046\n",
      "loss: 0.3665777329331724\n",
      "loss: 0.3666754201099791\n",
      "loss: 0.3668727052147024\n",
      "loss: 0.3663556636278782\n",
      "loss: 0.36760809070601186\n",
      "loss: 0.36698627251725047\n",
      "loss: 0.3679697656743364\n",
      "loss: 0.36921799402478506\n",
      "loss: 0.3683461102584087\n",
      "loss: 0.36712633835405784\n",
      "loss: 0.3666702157527035\n",
      "loss: 0.36709152036137166\n",
      "loss: 0.36638882241275694\n",
      "loss: 0.3667985368973786\n",
      "loss: 0.36692634391025447\n",
      "QNN: 0.186279296875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 26\n",
      "SD: 0.113525390625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.47166371596522944\n",
      "loss: 0.4666248724306461\n",
      "loss: 0.46787574253849196\n",
      "loss: 0.46753839009422227\n",
      "loss: 0.46587306654760163\n",
      "loss: 0.46842297972653285\n",
      "loss: 0.46694786238090014\n",
      "loss: 0.46797256806998927\n",
      "loss: 0.4684780366792133\n",
      "loss: 0.46658987173795186\n",
      "loss: 0.4687428210344661\n",
      "loss: 0.4674964566743813\n",
      "loss: 0.4650620553373982\n",
      "loss: 0.46877022922212624\n",
      "loss: 0.4644321172091699\n",
      "loss: 0.46943975788507697\n",
      "loss: 0.46802079888978676\n",
      "loss: 0.46962323630086017\n",
      "loss: 0.46900672129048715\n",
      "QNN: 0.2291259765625\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 27\n",
      "SD: 0.098876953125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3158346143029495\n",
      "loss: 0.2974305012964481\n",
      "loss: 0.2912974243615583\n",
      "loss: 0.2913374527868739\n",
      "loss: 0.2901526731379181\n",
      "loss: 0.2882229061074715\n",
      "loss: 0.2875529947139684\n",
      "loss: 0.2869464382921782\n",
      "loss: 0.28661436322241496\n",
      "loss: 0.2867191600803955\n",
      "loss: 0.2862701543247232\n",
      "loss: 0.28650658581249616\n",
      "loss: 0.2860950357122307\n",
      "loss: 0.286636719747137\n",
      "loss: 0.2859516178022065\n",
      "loss: 0.2857996875550805\n",
      "loss: 0.2858638146262137\n",
      "loss: 0.2875589452158995\n",
      "loss: 0.286724395967899\n",
      "QNN: 0.12548828125\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 28\n",
      "SD: 0.1083984375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3453734789040024\n",
      "loss: 0.2982056936061858\n",
      "loss: 0.2920299768214743\n",
      "loss: 0.29197881686726274\n",
      "loss: 0.29374326795578537\n",
      "loss: 0.3036493971553514\n",
      "loss: 0.30683186402837676\n",
      "loss: 0.31508728544050746\n",
      "loss: 0.32394259556645383\n",
      "loss: 0.32264701241258864\n",
      "loss: 0.33119584069948643\n",
      "loss: 0.318383812395456\n",
      "loss: 0.3224811303109534\n",
      "loss: 0.31483103637055115\n",
      "loss: 0.29906186137264695\n",
      "loss: 0.2961298788874825\n",
      "loss: 0.2971490768967468\n",
      "loss: 0.30482469231028064\n",
      "loss: 0.3085017783132182\n",
      "loss: 0.30710819416457524\n",
      "loss: 0.3054402217727966\n",
      "loss: 0.3104042003520681\n",
      "loss: 0.305718298856633\n",
      "loss: 0.30858624661262657\n",
      "loss: 0.3297169728343407\n",
      "loss: 0.33079221213057886\n",
      "loss: 0.31999210221771746\n",
      "loss: 0.30445813050417303\n",
      "loss: 0.3091951228837703\n",
      "QNN: 0.137451171875\n",
      "----------------------------current SNR_dB: 0\n",
      "----------------------------current iter num: 29\n",
      "SD: 0.1451416015625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.3388008942863476\n",
      "loss: 0.32308246289877846\n",
      "loss: 0.32319914163112423\n",
      "loss: 0.3230341441113344\n",
      "loss: 0.3229182730108295\n",
      "loss: 0.3215707149596024\n",
      "loss: 0.321824946216493\n",
      "loss: 0.32301915579333995\n",
      "loss: 0.3216214854001689\n",
      "loss: 0.32192629198159256\n",
      "loss: 0.32123491362528794\n",
      "loss: 0.3209024690164264\n",
      "loss: 0.3211598196492849\n",
      "loss: 0.32104587400064116\n",
      "loss: 0.32071626438318\n",
      "loss: 0.32066548617666435\n",
      "loss: 0.32065240000334433\n",
      "loss: 0.32250238734219\n",
      "loss: 0.32107717823523035\n",
      "QNN: 0.144775390625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 0\n",
      "SD: 0.0372314453125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.19085436566189715\n",
      "loss: 0.17317593914783458\n",
      "loss: 0.1730928805587716\n",
      "loss: 0.17318139531378446\n",
      "loss: 0.1728764552583923\n",
      "loss: 0.1730265923000772\n",
      "loss: 0.1729728501097802\n",
      "loss: 0.17310748936860879\n",
      "loss: 0.17286611984007047\n",
      "loss: 0.17298234161303275\n",
      "loss: 0.17277870376111723\n",
      "loss: 0.1729039663148729\n",
      "loss: 0.17291378785387093\n",
      "loss: 0.1728392967243183\n",
      "loss: 0.1727715133211641\n",
      "loss: 0.17279819407817285\n",
      "loss: 0.1728506300263568\n",
      "loss: 0.1730095039052757\n",
      "loss: 0.17282656338612165\n",
      "QNN: 0.0560302734375\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 1\n",
      "SD: 0.140869140625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.23215895370161418\n",
      "loss: 0.2200440760567143\n",
      "loss: 0.21938183231832076\n",
      "loss: 0.21856735818510095\n",
      "loss: 0.2181787908592663\n",
      "loss: 0.21811904363528062\n",
      "loss: 0.21815745240651885\n",
      "loss: 0.21821374497561702\n",
      "loss: 0.2182651352754204\n",
      "loss: 0.21815332267647258\n",
      "loss: 0.21810130731810096\n",
      "loss: 0.21802656964519443\n",
      "loss: 0.21809514737099664\n",
      "loss: 0.21819916948977683\n",
      "loss: 0.21838741222748353\n",
      "loss: 0.21894418563450077\n",
      "loss: 0.2187212267527228\n",
      "loss: 0.21885327529098778\n",
      "loss: 0.21839247423924088\n",
      "QNN: 0.074951171875\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 2\n",
      "SD: 0.10107421875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.2784025793820436\n",
      "loss: 0.2691851499859789\n",
      "loss: 0.2686428630937581\n",
      "loss: 0.2684351593916862\n",
      "loss: 0.26830419367985514\n",
      "loss: 0.2684531044528695\n",
      "loss: 0.2683450889753044\n",
      "loss: 0.2683097750979113\n",
      "loss: 0.26824005186587874\n",
      "loss: 0.2684470240954606\n",
      "loss: 0.2684597556625753\n",
      "loss: 0.26856475911404964\n",
      "loss: 0.2683417828884479\n",
      "loss: 0.2686033682189687\n",
      "loss: 0.2683456886463782\n",
      "loss: 0.2683345496084448\n",
      "loss: 0.26857096430349436\n",
      "loss: 0.26925346484426876\n",
      "loss: 0.26832155958416726\n",
      "QNN: 0.1051025390625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 3\n",
      "SD: 0.195556640625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.22100392227104723\n",
      "loss: 0.2037705975035711\n",
      "loss: 0.20286645874249834\n",
      "loss: 0.20289526304511477\n",
      "loss: 0.2027788802255375\n",
      "loss: 0.2026120732954002\n",
      "loss: 0.2027704992889051\n",
      "loss: 0.20298631930258956\n",
      "loss: 0.2027261620045873\n",
      "loss: 0.20254867524038747\n",
      "loss: 0.202739627112279\n",
      "loss: 0.202763395311732\n",
      "loss: 0.20247164101347256\n",
      "loss: 0.20262212367344248\n",
      "loss: 0.20273156798349376\n",
      "loss: 0.20261352034696395\n",
      "loss: 0.20262292147691652\n",
      "loss: 0.20251713745074293\n",
      "loss: 0.20248567876613455\n",
      "QNN: 0.0640869140625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 4\n",
      "SD: 0.21240234375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.16739777435280695\n",
      "loss: 0.16631009170229868\n",
      "loss: 0.16618762931461206\n",
      "loss: 0.16605387195238114\n",
      "loss: 0.1660293737545014\n",
      "loss: 0.1659719974672018\n",
      "loss: 0.1659541884778204\n",
      "loss: 0.1661305719428241\n",
      "loss: 0.1659703789869763\n",
      "loss: 0.16616393043580996\n",
      "loss: 0.16599339902008498\n",
      "loss: 0.16599264571644082\n",
      "loss: 0.16598315736495903\n",
      "loss: 0.1660435015882422\n",
      "loss: 0.1660565915558361\n",
      "loss: 0.16601356386002464\n",
      "loss: 0.16608437571183907\n",
      "loss: 0.1659194673913499\n",
      "loss: 0.1660346190310746\n",
      "QNN: 0.045654296875\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 5\n",
      "SD: 0.0777587890625\n",
      "loss: 0.6931471805599465\n",
      "loss: 0.21993067136174746\n",
      "loss: 0.200718454742219\n",
      "loss: 0.19867288162496446\n",
      "loss: 0.19878009897745788\n",
      "loss: 0.19866870981669435\n",
      "loss: 0.19875167375979955\n",
      "loss: 0.19868244337906107\n",
      "loss: 0.19860483773079246\n",
      "loss: 0.19873016745660008\n",
      "loss: 0.1988644428591227\n",
      "loss: 0.19888260165548116\n",
      "loss: 0.19881229541797588\n",
      "loss: 0.1988151538252284\n",
      "loss: 0.1989661128150807\n",
      "loss: 0.19905153691125121\n",
      "loss: 0.19911465795290514\n",
      "loss: 0.19902736084166672\n",
      "loss: 0.1989056199589539\n",
      "loss: 0.19871437164203554\n",
      "QNN: 0.05810546875\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 6\n",
      "SD: 0.1181640625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.20976705908181423\n",
      "loss: 0.1962459665770153\n",
      "loss: 0.19554605489656526\n",
      "loss: 0.1955653520925565\n",
      "loss: 0.19553133214010568\n",
      "loss: 0.19564901422050027\n",
      "loss: 0.19553843448720093\n",
      "loss: 0.19540275040475658\n",
      "loss: 0.19536631666838336\n",
      "loss: 0.1956317773878346\n",
      "loss: 0.19538383858006458\n",
      "loss: 0.19541691265864197\n",
      "loss: 0.19544690889634533\n",
      "loss: 0.19531005631655962\n",
      "loss: 0.19551696403472413\n",
      "loss: 0.19542967775574926\n",
      "loss: 0.19590959385695322\n",
      "loss: 0.19536377931647925\n",
      "loss: 0.19566208713885908\n",
      "QNN: 0.0726318359375\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 7\n",
      "SD: 0.1944580078125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3439742723326431\n",
      "loss: 0.31554971327952513\n",
      "loss: 0.2997816221166142\n",
      "loss: 0.2951064484302047\n",
      "loss: 0.2941727923080492\n",
      "loss: 0.2942655335983852\n",
      "loss: 0.2940968705897945\n",
      "loss: 0.2941912511132308\n",
      "loss: 0.2941793745319544\n",
      "loss: 0.29425475087679753\n",
      "loss: 0.29432181957961495\n",
      "loss: 0.29436312486125366\n",
      "loss: 0.2941467237127141\n",
      "loss: 0.29426739707703603\n",
      "loss: 0.29422672659950033\n",
      "loss: 0.2941021933316416\n",
      "loss: 0.2944760321892098\n",
      "loss: 0.29422610725922765\n",
      "loss: 0.29410709330458495\n",
      "QNN: 0.1187744140625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 8\n",
      "SD: 0.17138671875\n",
      "loss: 0.6931471805599465\n",
      "loss: 0.34730790377417853\n",
      "loss: 0.31679770687350534\n",
      "loss: 0.3134974155343516\n",
      "loss: 0.312731319629545\n",
      "loss: 0.31263285199872387\n",
      "loss: 0.31284514886109555\n",
      "loss: 0.3129322719978054\n",
      "loss: 0.3126473021666488\n",
      "loss: 0.3125880299042984\n",
      "loss: 0.31274974935970423\n",
      "loss: 0.31282506654284775\n",
      "loss: 0.31389242674355583\n",
      "loss: 0.31339533890379767\n",
      "loss: 0.31323316871869417\n",
      "loss: 0.3128551470481308\n",
      "loss: 0.3129197732452115\n",
      "loss: 0.3140420188446735\n",
      "loss: 0.3132272971829816\n",
      "loss: 0.31331108438189476\n",
      "QNN: 0.1224365234375\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 9\n",
      "SD: 0.0662841796875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.29578834064577647\n",
      "loss: 0.2902206989143193\n",
      "loss: 0.28899020073719106\n",
      "loss: 0.2892595174228488\n",
      "loss: 0.2898367443186193\n",
      "loss: 0.28932377601517867\n",
      "loss: 0.2902647113498109\n",
      "loss: 0.28975917324320616\n",
      "loss: 0.28967373929095336\n",
      "loss: 0.2906361295060565\n",
      "loss: 0.29042488573803366\n",
      "loss: 0.2906355232971107\n",
      "loss: 0.29079581263832144\n",
      "loss: 0.2916567052857842\n",
      "loss: 0.2919162756535912\n",
      "loss: 0.29099036539851286\n",
      "loss: 0.29061272391548587\n",
      "loss: 0.29225945951386695\n",
      "loss: 0.2943671072417142\n",
      "loss: 0.2933536591868613\n",
      "loss: 0.2896469439663712\n",
      "loss: 0.2907802411909246\n",
      "loss: 0.2910189230121826\n",
      "loss: 0.29180884710776367\n",
      "loss: 0.29101864352421214\n",
      "loss: 0.29009338956550285\n",
      "loss: 0.289884400879238\n",
      "loss: 0.28878022597729003\n",
      "loss: 0.28893615706396975\n",
      "loss: 0.28886532831489864\n",
      "loss: 0.288675463617601\n",
      "loss: 0.2888756466900724\n",
      "loss: 0.28903474417830805\n",
      "loss: 0.28876671282353306\n",
      "loss: 0.2886634324858785\n",
      "loss: 0.28902682132657453\n",
      "loss: 0.288846423668119\n",
      "loss: 0.28882103717860486\n",
      "loss: 0.28877321146629936\n",
      "QNN: 0.10986328125\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 10\n",
      "SD: 0.1641845703125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.31855901351025206\n",
      "loss: 0.31342664299145084\n",
      "loss: 0.3133320349035677\n",
      "loss: 0.3134217202802637\n",
      "loss: 0.3133445678620051\n",
      "loss: 0.3132359208588935\n",
      "loss: 0.3131919430271875\n",
      "loss: 0.3131958800993183\n",
      "loss: 0.3136500216689101\n",
      "loss: 0.31376400410037597\n",
      "loss: 0.313762405093047\n",
      "loss: 0.313258253862517\n",
      "loss: 0.313132578859553\n",
      "loss: 0.3133402579964848\n",
      "loss: 0.31319099078920376\n",
      "loss: 0.31337091170803355\n",
      "loss: 0.3131908354720268\n",
      "loss: 0.3131104572048338\n",
      "loss: 0.3135358089564154\n",
      "QNN: 0.1351318359375\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 11\n",
      "SD: 0.132568359375\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.2249681853604323\n",
      "loss: 0.2040361452973132\n",
      "loss: 0.2035483932055858\n",
      "loss: 0.20326072346954255\n",
      "loss: 0.20315803934777527\n",
      "loss: 0.20311865464927392\n",
      "loss: 0.20324069299431416\n",
      "loss: 0.20312822398385952\n",
      "loss: 0.20315386228008395\n",
      "loss: 0.20311991156873146\n",
      "loss: 0.2029903359500517\n",
      "loss: 0.20311012872824266\n",
      "loss: 0.20314960671017038\n",
      "loss: 0.203186499842713\n",
      "loss: 0.2029649661995532\n",
      "loss: 0.20318611408733286\n",
      "loss: 0.20313345189639556\n",
      "loss: 0.20324178890883196\n",
      "loss: 0.2029658429728268\n",
      "QNN: 0.072265625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 12\n",
      "SD: 0.1834716796875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.09663556577375124\n",
      "loss: 0.08050889202085185\n",
      "loss: 0.0796068424265284\n",
      "loss: 0.07911668335467988\n",
      "loss: 0.07901961056265362\n",
      "loss: 0.07894546041655512\n",
      "loss: 0.0788943654097744\n",
      "loss: 0.07886748134391489\n",
      "loss: 0.07891922011173286\n",
      "loss: 0.07891388692119579\n",
      "loss: 0.07892232696843236\n",
      "loss: 0.07894192970475512\n",
      "loss: 0.0789935886967321\n",
      "loss: 0.07889050705684168\n",
      "loss: 0.07886390840101618\n",
      "loss: 0.07898657954133557\n",
      "loss: 0.07888832603034872\n",
      "loss: 0.07899150073189182\n",
      "loss: 0.07918125624470936\n",
      "QNN: 0.0146484375\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 13\n",
      "SD: 0.0389404296875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.21247808653397646\n",
      "loss: 0.2048666698303396\n",
      "loss: 0.20443682351503079\n",
      "loss: 0.20467836331743888\n",
      "loss: 0.2045708272504012\n",
      "loss: 0.2044145374919647\n",
      "loss: 0.2043888284175436\n",
      "loss: 0.20432058849923868\n",
      "loss: 0.2043552295683258\n",
      "loss: 0.204598722992495\n",
      "loss: 0.20430470584826438\n",
      "loss: 0.20427275039671394\n",
      "loss: 0.20428110195568264\n",
      "loss: 0.20449928980284676\n",
      "loss: 0.20426468537020906\n",
      "loss: 0.20423785898853863\n",
      "loss: 0.20425996925377712\n",
      "loss: 0.2043060020059463\n",
      "loss: 0.20456848766530164\n",
      "QNN: 0.0672607421875\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 14\n",
      "SD: 0.2041015625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.40210826368981145\n",
      "loss: 0.38517731566655705\n",
      "loss: 0.37742408469705224\n",
      "loss: 0.3768429919143563\n",
      "loss: 0.3747784994571623\n",
      "loss: 0.3753162279912286\n",
      "loss: 0.3748092189257899\n",
      "loss: 0.3773138375528607\n",
      "loss: 0.3763952978306528\n",
      "loss: 0.3755153828953675\n",
      "loss: 0.37494703829149373\n",
      "loss: 0.37470868246644046\n",
      "loss: 0.3752732620615349\n",
      "loss: 0.374896933141665\n",
      "loss: 0.37556446946652133\n",
      "loss: 0.3746443791804421\n",
      "loss: 0.37592530573720845\n",
      "loss: 0.3752557802499262\n",
      "loss: 0.37512358481193064\n",
      "loss: 0.3748805924670483\n",
      "loss: 0.37477536041003595\n",
      "loss: 0.3748967878089851\n",
      "loss: 0.3749228090206684\n",
      "loss: 0.37558250784544195\n",
      "loss: 0.3750537419267078\n",
      "loss: 0.374847651706881\n",
      "loss: 0.37526163576561977\n",
      "loss: 0.3750753281785901\n",
      "loss: 0.3764562160173883\n",
      "loss: 0.3756541979917751\n",
      "loss: 0.37649992359805584\n",
      "loss: 0.375244923926213\n",
      "loss: 0.37516602966405377\n",
      "loss: 0.3753203028851958\n",
      "loss: 0.3757193795689338\n",
      "loss: 0.37751863464947566\n",
      "loss: 0.3750653045295933\n",
      "loss: 0.37501025909390523\n",
      "loss: 0.3748154404689374\n",
      "loss: 0.37486414628335196\n",
      "loss: 0.3745960951431362\n",
      "loss: 0.3754965373514268\n",
      "loss: 0.3745621310513009\n",
      "loss: 0.37518002487307456\n",
      "loss: 0.3758304257637786\n",
      "loss: 0.37469412476121633\n",
      "loss: 0.3748217690796507\n",
      "loss: 0.37480412671569263\n",
      "loss: 0.3750123978939149\n",
      "QNN: 0.17822265625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 15\n",
      "SD: 0.154296875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2479014975605507\n",
      "loss: 0.23096692921590575\n",
      "loss: 0.22975243863339065\n",
      "loss: 0.2292923476506868\n",
      "loss: 0.229155257443423\n",
      "loss: 0.22929862618938715\n",
      "loss: 0.2293599834848482\n",
      "loss: 0.22950163197023313\n",
      "loss: 0.2290812673684937\n",
      "loss: 0.22904440359565692\n",
      "loss: 0.22899105161323802\n",
      "loss: 0.22906947344014322\n",
      "loss: 0.22931415024027063\n",
      "loss: 0.2289633892789369\n",
      "loss: 0.22924741999162437\n",
      "loss: 0.22916356684276465\n",
      "loss: 0.22910461319005204\n",
      "loss: 0.22889801709526145\n",
      "loss: 0.2289002689463797\n",
      "QNN: 0.0738525390625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 16\n",
      "SD: 0.05126953125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.24734742057790263\n",
      "loss: 0.23476523108523006\n",
      "loss: 0.23386100275746083\n",
      "loss: 0.2340456921050665\n",
      "loss: 0.23425280597597428\n",
      "loss: 0.2337116794597849\n",
      "loss: 0.23367960914222435\n",
      "loss: 0.23367412990384212\n",
      "loss: 0.2341610521571701\n",
      "loss: 0.2340639532872305\n",
      "loss: 0.23453645800718403\n",
      "loss: 0.23437419628984746\n",
      "loss: 0.23441964256303208\n",
      "loss: 0.2340876851732956\n",
      "loss: 0.23427457023401893\n",
      "loss: 0.23428390013026584\n",
      "loss: 0.23407226728283245\n",
      "loss: 0.23404967838026383\n",
      "loss: 0.2344886668646049\n",
      "QNN: 0.06884765625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 17\n",
      "SD: 0.19189453125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.3693342166648034\n",
      "loss: 0.31507148074194385\n",
      "loss: 0.3069464760883568\n",
      "loss: 0.305471940741145\n",
      "loss: 0.30508158067579644\n",
      "loss: 0.3050021734572436\n",
      "loss: 0.30507067727114534\n",
      "loss: 0.30508998655732844\n",
      "loss: 0.30601364607498993\n",
      "loss: 0.3060728033838882\n",
      "loss: 0.30545548906259545\n",
      "loss: 0.30500205489739757\n",
      "loss: 0.30587651929939785\n",
      "loss: 0.30530650373135787\n",
      "loss: 0.3050332894027668\n",
      "loss: 0.30505700924763407\n",
      "loss: 0.30507333273239834\n",
      "loss: 0.30538085910896146\n",
      "loss: 0.3057505013320089\n",
      "QNN: 0.146240234375\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 18\n",
      "SD: 0.1229248046875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.2643837622515308\n",
      "loss: 0.2249967085193313\n",
      "loss: 0.21088341680073877\n",
      "loss: 0.20804067880809127\n",
      "loss: 0.2077557900316869\n",
      "loss: 0.2079688535237407\n",
      "loss: 0.20757083293081044\n",
      "loss: 0.20818362382019767\n",
      "loss: 0.2081586119671718\n",
      "loss: 0.20779074166591488\n",
      "loss: 0.20763485582355987\n",
      "loss: 0.20736488728661703\n",
      "loss: 0.2079123950801443\n",
      "loss: 0.2076624452143046\n",
      "loss: 0.20747427693894993\n",
      "loss: 0.20767405067633277\n",
      "loss: 0.2083603821493429\n",
      "loss: 0.2073882843014803\n",
      "loss: 0.20740134994928933\n",
      "QNN: 0.0758056640625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 19\n",
      "SD: 0.19873046875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.38104270620521047\n",
      "loss: 0.3569284867172199\n",
      "loss: 0.35559732439236286\n",
      "loss: 0.35519352181190006\n",
      "loss: 0.35510825288052034\n",
      "loss: 0.3550404590395443\n",
      "loss: 0.35524463435261605\n",
      "loss: 0.3550451280825958\n",
      "loss: 0.35513536392847\n",
      "loss: 0.3551824698719494\n",
      "loss: 0.35515921884185553\n",
      "loss: 0.355169983281132\n",
      "loss: 0.3550418003124353\n",
      "loss: 0.3555920081198275\n",
      "loss: 0.35502916790866723\n",
      "loss: 0.3551208626603773\n",
      "loss: 0.35506831687947776\n",
      "loss: 0.35506814660063335\n",
      "loss: 0.3554672165144752\n",
      "QNN: 0.1593017578125\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 20\n",
      "SD: 0.0279541015625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.23293743815978124\n",
      "loss: 0.214073754092476\n",
      "loss: 0.2119542231433716\n",
      "loss: 0.21180328347385532\n",
      "loss: 0.21148585569346023\n",
      "loss: 0.2115496220704055\n",
      "loss: 0.21149258377461408\n",
      "loss: 0.211817348647417\n",
      "loss: 0.21152591132112422\n",
      "loss: 0.2116008504818669\n",
      "loss: 0.21167599370769902\n",
      "loss: 0.21156016124749719\n",
      "loss: 0.21140776530922462\n",
      "loss: 0.2114217837310151\n",
      "loss: 0.21143421163407164\n",
      "loss: 0.21171687390588667\n",
      "loss: 0.21176775692425415\n",
      "loss: 0.21137937199842716\n",
      "loss: 0.21184430213406094\n",
      "QNN: 0.07763671875\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 21\n",
      "SD: 0.162841796875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1975453587721136\n",
      "loss: 0.18234765064638278\n",
      "loss: 0.18169354949053848\n",
      "loss: 0.18175992937925003\n",
      "loss: 0.18157764446966035\n",
      "loss: 0.1815922197566493\n",
      "loss: 0.18163094903159718\n",
      "loss: 0.18163199294241386\n",
      "loss: 0.18151973383000397\n",
      "loss: 0.18174540436776865\n",
      "loss: 0.18161699316318447\n",
      "loss: 0.181508515482053\n",
      "loss: 0.18146739767532488\n",
      "loss: 0.181692521141289\n",
      "loss: 0.18161455775592725\n",
      "loss: 0.18157868160760185\n",
      "loss: 0.181953395338816\n",
      "loss: 0.18166458713274047\n",
      "loss: 0.18158913501701865\n",
      "QNN: 0.0523681640625\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 22\n",
      "SD: 0.122802734375\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.3077321288493594\n",
      "loss: 0.27854941170787867\n",
      "loss: 0.2743250934626374\n",
      "loss: 0.27371111778588036\n",
      "loss: 0.27357755495804525\n",
      "loss: 0.2740056506211811\n",
      "loss: 0.2740018856083529\n",
      "loss: 0.2733126271806827\n",
      "loss: 0.2737206828073141\n",
      "loss: 0.27329885680403376\n",
      "loss: 0.273491294346237\n",
      "loss: 0.2735301617817751\n",
      "loss: 0.2739254181226916\n",
      "loss: 0.274094853790509\n",
      "loss: 0.2736510517527549\n",
      "loss: 0.27347924114972827\n",
      "loss: 0.2734530614048905\n",
      "loss: 0.27360519151157564\n",
      "loss: 0.27397073610845984\n",
      "QNN: 0.1219482421875\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 23\n",
      "SD: 0.2039794921875\n",
      "loss: 0.6931471805599465\n",
      "loss: 0.2981103495790216\n",
      "loss: 0.2927389497735254\n",
      "loss: 0.29329435013988575\n",
      "loss: 0.29280245376373654\n",
      "loss: 0.2925594609816437\n",
      "loss: 0.2922726540514662\n",
      "loss: 0.2920261629410833\n",
      "loss: 0.2918247199604338\n",
      "loss: 0.2919628459259294\n",
      "loss: 0.2921280870762964\n",
      "loss: 0.2918944731212364\n",
      "loss: 0.29254979054338476\n",
      "loss: 0.2923006590076682\n",
      "loss: 0.29194858334017226\n",
      "loss: 0.29187759017727183\n",
      "loss: 0.29182908116711476\n",
      "loss: 0.2917811735974662\n",
      "loss: 0.29170871586823266\n",
      "loss: 0.2918197307114674\n",
      "QNN: 0.1064453125\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 24\n",
      "SD: 0.0645751953125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.21215697035215547\n",
      "loss: 0.17139419972644654\n",
      "loss: 0.1658466110429655\n",
      "loss: 0.16570037017509484\n",
      "loss: 0.16543863217612392\n",
      "loss: 0.16538127800031144\n",
      "loss: 0.1654240599060929\n",
      "loss: 0.165452384516422\n",
      "loss: 0.16539385921039437\n",
      "loss: 0.16538145620608743\n",
      "loss: 0.16549073795596356\n",
      "loss: 0.16537680194891852\n",
      "loss: 0.16541060300512817\n",
      "loss: 0.16555464981268672\n",
      "loss: 0.16550172429043064\n",
      "loss: 0.16536654064191017\n",
      "loss: 0.16555116710080175\n",
      "loss: 0.1655547602624083\n",
      "loss: 0.16531228194602673\n",
      "QNN: 0.042236328125\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 25\n",
      "SD: 0.1114501953125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2707949311119623\n",
      "loss: 0.24781474303183199\n",
      "loss: 0.2456254751183668\n",
      "loss: 0.24564780742261472\n",
      "loss: 0.2455566008434075\n",
      "loss: 0.24581866297145988\n",
      "loss: 0.24553456587751968\n",
      "loss: 0.2454861487714282\n",
      "loss: 0.2459329407671027\n",
      "loss: 0.24548004219024908\n",
      "loss: 0.24594686414571273\n",
      "loss: 0.2456084269527486\n",
      "loss: 0.24560968719545845\n",
      "loss: 0.2457211956961324\n",
      "loss: 0.24556597296583857\n",
      "loss: 0.24545066171648144\n",
      "loss: 0.24556157360564346\n",
      "loss: 0.24548922493546918\n",
      "loss: 0.24549461728471916\n",
      "QNN: 0.096923828125\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 26\n",
      "SD: 0.10791015625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.37971803519029873\n",
      "loss: 0.35121613817158703\n",
      "loss: 0.346474240942428\n",
      "loss: 0.3453255528605752\n",
      "loss: 0.34571492370016277\n",
      "loss: 0.34766167155149463\n",
      "loss: 0.3481217460087405\n",
      "loss: 0.34916644423970905\n",
      "loss: 0.3485920503511703\n",
      "loss: 0.3510776356888004\n",
      "loss: 0.35644590071465765\n",
      "loss: 0.3584279406464164\n",
      "loss: 0.3629763779336516\n",
      "loss: 0.3697375227569165\n",
      "loss: 0.37793356575076903\n",
      "loss: 0.369002377230266\n",
      "loss: 0.3620205775764458\n",
      "loss: 0.3576030285583647\n",
      "loss: 0.3594407038888573\n",
      "loss: 0.3696745660977768\n",
      "loss: 0.36061687307119805\n",
      "loss: 0.35729623892534124\n",
      "loss: 0.3532292055849812\n",
      "loss: 0.3509397256684027\n",
      "loss: 0.3490214602388371\n",
      "loss: 0.35274076156217526\n",
      "loss: 0.35143156202562703\n",
      "loss: 0.3604226847886663\n",
      "loss: 0.3659834189537074\n",
      "loss: 0.37920376254923654\n",
      "loss: 0.3766791031286464\n",
      "loss: 0.37916117641701813\n",
      "loss: 0.3718714750754389\n",
      "loss: 0.3647699493719614\n",
      "loss: 0.3652793365419073\n",
      "loss: 0.3567767923776206\n",
      "loss: 0.3590335001047461\n",
      "loss: 0.3614758227064777\n",
      "loss: 0.37713549891177006\n",
      "loss: 0.37753556741574057\n",
      "loss: 0.3713642501452596\n",
      "loss: 0.3684303416610731\n",
      "loss: 0.36173774739254727\n",
      "loss: 0.3619340632205717\n",
      "loss: 0.36357484720197353\n",
      "loss: 0.362631574276147\n",
      "loss: 0.3573798951108821\n",
      "loss: 0.354284536329773\n",
      "loss: 0.3542652913737199\n",
      "loss: 0.3590997548453335\n",
      "loss: 0.3636926881747789\n",
      "loss: 0.3680787637195937\n",
      "loss: 0.3617017301459846\n",
      "loss: 0.3725136640699626\n",
      "loss: 0.377581845505383\n",
      "loss: 0.37295543230072925\n",
      "loss: 0.37451118544459383\n",
      "loss: 0.38536323579170073\n",
      "loss: 0.38323959742142527\n",
      "loss: 0.36374916337982227\n",
      "loss: 0.36213916744023367\n",
      "loss: 0.3736085084492432\n",
      "loss: 0.37650569075489865\n",
      "loss: 0.3733629486481389\n",
      "loss: 0.3686681657134007\n",
      "loss: 0.3602358143977321\n",
      "loss: 0.35749990283541294\n",
      "loss: 0.3609148731517569\n",
      "loss: 0.362958458577293\n",
      "loss: 0.35572079290059866\n",
      "loss: 0.3611523290914306\n",
      "loss: 0.36933146385402893\n",
      "loss: 0.366471858077633\n",
      "loss: 0.3661553568175326\n",
      "loss: 0.36978388922113964\n",
      "loss: 0.3716830432174085\n",
      "loss: 0.36883875097443475\n",
      "loss: 0.3688855662954521\n",
      "loss: 0.36792900942455364\n",
      "loss: 0.3696360794871377\n",
      "loss: 0.3698748455408262\n",
      "loss: 0.37302537391307833\n",
      "loss: 0.37315553651195094\n",
      "loss: 0.36886386752489236\n",
      "loss: 0.3740567314842624\n",
      "loss: 0.3694464990985125\n",
      "loss: 0.36556324071997526\n",
      "loss: 0.3628756575523786\n",
      "loss: 0.36855865446562386\n",
      "QNN: 0.166748046875\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 27\n",
      "SD: 0.0858154296875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.16676766018575367\n",
      "loss: 0.13963560852742504\n",
      "loss: 0.13735700609571808\n",
      "loss: 0.1372022484368309\n",
      "loss: 0.13728645791346297\n",
      "loss: 0.13717686584207875\n",
      "loss: 0.13759270156731823\n",
      "loss: 0.13743102553544695\n",
      "loss: 0.13720113668608871\n",
      "loss: 0.13715256737031958\n",
      "loss: 0.13721857898053155\n",
      "loss: 0.13715538615929834\n",
      "loss: 0.13711913933885916\n",
      "loss: 0.13718290207376643\n",
      "loss: 0.13747134520295462\n",
      "loss: 0.13719157003105248\n",
      "loss: 0.13707136231136618\n",
      "loss: 0.13711828609053928\n",
      "loss: 0.13728033928966563\n",
      "QNN: 0.037841796875\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 28\n",
      "SD: 0.185302734375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.20858125178148507\n",
      "loss: 0.14949484925483728\n",
      "loss: 0.13078105656425493\n",
      "loss: 0.13003576387722973\n",
      "loss: 0.13016209013996005\n",
      "loss: 0.1301016333528953\n",
      "loss: 0.13000125469384433\n",
      "loss: 0.13015812091729864\n",
      "loss: 0.12991002517398753\n",
      "loss: 0.1299356641459113\n",
      "loss: 0.13020769578759053\n",
      "loss: 0.13049604695288974\n",
      "loss: 0.13044505841856832\n",
      "loss: 0.12998103929875843\n",
      "loss: 0.13102123907368654\n",
      "loss: 0.1299032742051318\n",
      "loss: 0.12998719551314872\n",
      "loss: 0.1300958387364892\n",
      "loss: 0.12996018521519787\n",
      "QNN: 0.047607421875\n",
      "----------------------------current SNR_dB: 5\n",
      "----------------------------current iter num: 29\n",
      "SD: 0.127685546875\n",
      "loss: 0.6931471805599462\n",
      "loss: 0.21017743698504715\n",
      "loss: 0.1795383851076305\n",
      "loss: 0.17668009906696872\n",
      "loss: 0.17641086553070173\n",
      "loss: 0.17643644698005304\n",
      "loss: 0.17690700207552323\n",
      "loss: 0.17649486299365605\n",
      "loss: 0.17638343510714216\n",
      "loss: 0.17640763601786727\n",
      "loss: 0.1763975217000781\n",
      "loss: 0.17636257113122797\n",
      "loss: 0.17627329845392722\n",
      "loss: 0.17625198800802197\n",
      "loss: 0.1762605779811544\n",
      "loss: 0.17642306401419947\n",
      "loss: 0.1764834511929323\n",
      "loss: 0.1766803336644002\n",
      "loss: 0.17631086953539574\n",
      "loss: 0.1762317818092181\n",
      "QNN: 0.061279296875\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 0\n",
      "SD: 0.013916015625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.18247716889646276\n",
      "loss: 0.15400618383134665\n",
      "loss: 0.1523293742271054\n",
      "loss: 0.15208053711750075\n",
      "loss: 0.15205116195075238\n",
      "loss: 0.15212528492733246\n",
      "loss: 0.15218057288561535\n",
      "loss: 0.15203105330901667\n",
      "loss: 0.15226917696478917\n",
      "loss: 0.15199881000723195\n",
      "loss: 0.15205678061887842\n",
      "loss: 0.1520707752306478\n",
      "loss: 0.1519694451440202\n",
      "loss: 0.15206492087160933\n",
      "loss: 0.1520801796683642\n",
      "loss: 0.1519987372639882\n",
      "loss: 0.15217305963772426\n",
      "loss: 0.15207735647681672\n",
      "loss: 0.15203235323969302\n",
      "QNN: 0.019775390625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 1\n",
      "SD: 0.1048583984375\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.1917534996830192\n",
      "loss: 0.1733419816657421\n",
      "loss: 0.17258068611757132\n",
      "loss: 0.17270031992466875\n",
      "loss: 0.17256286413831742\n",
      "loss: 0.1726228690447656\n",
      "loss: 0.17254337460504374\n",
      "loss: 0.1727014369401579\n",
      "loss: 0.17253450130789028\n",
      "loss: 0.17256828549015774\n",
      "loss: 0.1725912034758943\n",
      "loss: 0.17259858126181224\n",
      "loss: 0.17254791684714027\n",
      "loss: 0.1725945365428312\n",
      "loss: 0.17258121045912128\n",
      "loss: 0.17256957356101862\n",
      "loss: 0.17254997031291736\n",
      "loss: 0.1726281872463737\n",
      "loss: 0.17261634265210238\n",
      "QNN: 0.0216064453125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 2\n",
      "SD: 0.0291748046875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.22533407671707567\n",
      "loss: 0.22035124177253837\n",
      "loss: 0.22006357909238602\n",
      "loss: 0.22012512816977683\n",
      "loss: 0.22006560514845228\n",
      "loss: 0.22010907046893052\n",
      "loss: 0.2202786033517546\n",
      "loss: 0.22007216605292323\n",
      "loss: 0.22016644109411052\n",
      "loss: 0.2200387334274819\n",
      "loss: 0.22025598114145784\n",
      "loss: 0.22019250619797953\n",
      "loss: 0.2202043637101094\n",
      "loss: 0.2200653860527253\n",
      "loss: 0.22037590036234742\n",
      "loss: 0.22015131452970227\n",
      "loss: 0.22001244043854978\n",
      "loss: 0.22003839045682327\n",
      "loss: 0.22016980165215158\n",
      "QNN: 0.049560546875\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 3\n",
      "SD: 0.11865234375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.21636015370425238\n",
      "loss: 0.1660257493572635\n",
      "loss: 0.15537609899214092\n",
      "loss: 0.155234855064559\n",
      "loss: 0.1553746910721525\n",
      "loss: 0.15526440723505636\n",
      "loss: 0.1552140401291206\n",
      "loss: 0.15516264563913137\n",
      "loss: 0.15518913657491493\n",
      "loss: 0.15521412374076696\n",
      "loss: 0.15532716880612413\n",
      "loss: 0.1551252452211949\n",
      "loss: 0.15531788604257285\n",
      "loss: 0.15530305192939378\n",
      "loss: 0.15515992000370832\n",
      "loss: 0.15517837452811167\n",
      "loss: 0.15517271592358023\n",
      "loss: 0.15524405371654496\n",
      "loss: 0.15514575467284816\n",
      "QNN: 0.02001953125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 4\n",
      "SD: 0.21826171875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.14307664374374598\n",
      "loss: 0.128992784219579\n",
      "loss: 0.12885016635799662\n",
      "loss: 0.12890139221418842\n",
      "loss: 0.1288141215623137\n",
      "loss: 0.1287882102229849\n",
      "loss: 0.12874908350131722\n",
      "loss: 0.1287080878802126\n",
      "loss: 0.12870131679735006\n",
      "loss: 0.1287211739908793\n",
      "loss: 0.12886085038104272\n",
      "loss: 0.1288772114622744\n",
      "loss: 0.128965695174865\n",
      "loss: 0.12873258655149042\n",
      "loss: 0.12870429657099022\n",
      "loss: 0.12880464317592732\n",
      "loss: 0.12887661178510654\n",
      "loss: 0.12873039403243797\n",
      "loss: 0.12894183925118186\n",
      "QNN: 0.0093994140625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 5\n",
      "SD: 0.019287109375\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.16911020030346707\n",
      "loss: 0.15681465690264487\n",
      "loss: 0.15632711264529575\n",
      "loss: 0.15622586613861972\n",
      "loss: 0.15636182784787214\n",
      "loss: 0.1562865594233414\n",
      "loss: 0.1563348836869115\n",
      "loss: 0.15627671674927282\n",
      "loss: 0.1564256858948986\n",
      "loss: 0.15629547670465535\n",
      "loss: 0.1562048698801038\n",
      "loss: 0.15630731873249842\n",
      "loss: 0.15625161020010275\n",
      "loss: 0.15629257968051896\n",
      "loss: 0.1564236457448273\n",
      "loss: 0.15634507620125376\n",
      "loss: 0.15629826014277845\n",
      "loss: 0.15635549753936673\n",
      "loss: 0.15633405066709163\n",
      "QNN: 0.0118408203125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 6\n",
      "SD: 0.0496826171875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2017597028168152\n",
      "loss: 0.17768435630319693\n",
      "loss: 0.176469593149198\n",
      "loss: 0.176402738173714\n",
      "loss: 0.17629356862435733\n",
      "loss: 0.17631729174021235\n",
      "loss: 0.17654823979492343\n",
      "loss: 0.1765100801626801\n",
      "loss: 0.17634500323612048\n",
      "loss: 0.17620332568505817\n",
      "loss: 0.17619767338608278\n",
      "loss: 0.17627112496861672\n",
      "loss: 0.17628086343951588\n",
      "loss: 0.17620410694311617\n",
      "loss: 0.17622571973667805\n",
      "loss: 0.17623200287964677\n",
      "loss: 0.17627887826184443\n",
      "loss: 0.1762262964080908\n",
      "loss: 0.1764024889269026\n",
      "QNN: 0.0108642578125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 7\n",
      "SD: 0.1434326171875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2890517707698314\n",
      "loss: 0.26644148633420367\n",
      "loss: 0.25870579533117694\n",
      "loss: 0.25665575000388624\n",
      "loss: 0.2565173576275824\n",
      "loss: 0.2563517830906908\n",
      "loss: 0.25645258005767607\n",
      "loss: 0.25647290083523233\n",
      "loss: 0.2565138078570161\n",
      "loss: 0.25663084326652436\n",
      "loss: 0.2567123933939789\n",
      "loss: 0.2563817515790684\n",
      "loss: 0.2566762592016573\n",
      "loss: 0.2570149558374236\n",
      "loss: 0.25667410508710564\n",
      "loss: 0.2573180082707248\n",
      "loss: 0.2570115795501137\n",
      "loss: 0.25699352593638786\n",
      "loss: 0.25664605707471233\n",
      "QNN: 0.063720703125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 8\n",
      "SD: 0.10205078125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.26693291879162045\n",
      "loss: 0.25619191495921095\n",
      "loss: 0.2560906933824619\n",
      "loss: 0.2555420596932749\n",
      "loss: 0.2562414777095577\n",
      "loss: 0.2555464144004616\n",
      "loss: 0.2556153815944596\n",
      "loss: 0.25572243672769107\n",
      "loss: 0.2556235129867886\n",
      "loss: 0.25553375695924296\n",
      "loss: 0.25626614348197785\n",
      "loss: 0.2556303107076997\n",
      "loss: 0.25568405416446155\n",
      "loss: 0.25566122686929077\n",
      "loss: 0.2556385982233751\n",
      "loss: 0.255494121226465\n",
      "loss: 0.2554942079623918\n",
      "loss: 0.2554336450663104\n",
      "loss: 0.2554428625262358\n",
      "QNN: 0.0738525390625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 9\n",
      "SD: 0.0147705078125\n",
      "loss: 0.6931471805599465\n",
      "loss: 0.2730952291023312\n",
      "loss: 0.2573123032497714\n",
      "loss: 0.25607544489910267\n",
      "loss: 0.25569783717119304\n",
      "loss: 0.2559440619333423\n",
      "loss: 0.2558440252389936\n",
      "loss: 0.2557198863159772\n",
      "loss: 0.25568891226313084\n",
      "loss: 0.25605860288024684\n",
      "loss: 0.25594217269303776\n",
      "loss: 0.255898582243922\n",
      "loss: 0.2556998340063352\n",
      "loss: 0.2557028227709728\n",
      "loss: 0.2559719433399987\n",
      "loss: 0.2557129533869856\n",
      "loss: 0.2557279269635507\n",
      "loss: 0.25563252517749524\n",
      "loss: 0.25563593002467705\n",
      "loss: 0.25566654318776\n",
      "QNN: 0.0565185546875\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 10\n",
      "SD: 0.080810546875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.28156161648155986\n",
      "loss: 0.26313961400977787\n",
      "loss: 0.2623047987224411\n",
      "loss: 0.2622097929373642\n",
      "loss: 0.26230475205581627\n",
      "loss: 0.26225203552663073\n",
      "loss: 0.2622448078725988\n",
      "loss: 0.2622053666745177\n",
      "loss: 0.26225172265712143\n",
      "loss: 0.26217059479212235\n",
      "loss: 0.2622079706868656\n",
      "loss: 0.2623515369273503\n",
      "loss: 0.26235404729731704\n",
      "loss: 0.26216448564406464\n",
      "loss: 0.26219281222516694\n",
      "loss: 0.2623732146157384\n",
      "loss: 0.26223647571597836\n",
      "loss: 0.2624526505087518\n",
      "loss: 0.2622045579940272\n",
      "QNN: 0.0751953125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 11\n",
      "SD: 0.052001953125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1741604217427937\n",
      "loss: 0.16800780629826648\n",
      "loss: 0.1678144717165773\n",
      "loss: 0.16779150024463488\n",
      "loss: 0.16791238023185417\n",
      "loss: 0.16797432674487292\n",
      "loss: 0.16777337468031425\n",
      "loss: 0.16775324807266825\n",
      "loss: 0.16791012686645349\n",
      "loss: 0.16791255821911386\n",
      "loss: 0.167846354067217\n",
      "loss: 0.1679477033029853\n",
      "loss: 0.167995874599643\n",
      "loss: 0.16783700319947656\n",
      "loss: 0.16782731573740609\n",
      "loss: 0.16795546189901808\n",
      "loss: 0.16787100347761294\n",
      "loss: 0.16795374629468546\n",
      "loss: 0.16793038520883793\n",
      "QNN: 0.013916015625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 12\n",
      "SD: 0.138916015625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.09127226948214777\n",
      "loss: 0.05019773651628502\n",
      "loss: 0.04812030512109766\n",
      "loss: 0.047893423470291734\n",
      "loss: 0.04784874479629867\n",
      "loss: 0.04782328056016995\n",
      "loss: 0.047827395363401845\n",
      "loss: 0.047813777873273594\n",
      "loss: 0.04782622720861511\n",
      "loss: 0.04780928066676839\n",
      "loss: 0.047826213603592245\n",
      "loss: 0.04779497927221798\n",
      "loss: 0.04778510978387892\n",
      "loss: 0.04779700198535227\n",
      "loss: 0.047777595357061345\n",
      "loss: 0.04778516498349877\n",
      "loss: 0.04782411429114022\n",
      "loss: 0.047769991727268056\n",
      "loss: 0.04779822664066639\n",
      "QNN: 0.00048828125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 13\n",
      "SD: 0.004150390625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.16847739921652438\n",
      "loss: 0.16108256971865315\n",
      "loss: 0.16062344371184775\n",
      "loss: 0.160640923450311\n",
      "loss: 0.16063984481171475\n",
      "loss: 0.16057297440514656\n",
      "loss: 0.16059132510945578\n",
      "loss: 0.16066450048205688\n",
      "loss: 0.16068873635804312\n",
      "loss: 0.160696645797587\n",
      "loss: 0.16060580768410915\n",
      "loss: 0.16054902366165907\n",
      "loss: 0.16059351087480916\n",
      "loss: 0.1607149537501379\n",
      "loss: 0.1606613273342776\n",
      "loss: 0.16070655771842754\n",
      "loss: 0.16062898648923277\n",
      "loss: 0.16055960795220597\n",
      "loss: 0.16056985406150218\n",
      "QNN: 0.0108642578125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 14\n",
      "SD: 0.15576171875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.3892431812099046\n",
      "loss: 0.3689648520763263\n",
      "loss: 0.3650682957428436\n",
      "loss: 0.35804579531575126\n",
      "loss: 0.3519904315555823\n",
      "loss: 0.3517225803935196\n",
      "loss: 0.35124409094232323\n",
      "loss: 0.35131121078394706\n",
      "loss: 0.3524897350440443\n",
      "loss: 0.350806766294462\n",
      "loss: 0.35112717247788744\n",
      "loss: 0.3515192133804738\n",
      "loss: 0.3513900088994624\n",
      "loss: 0.3509041274677121\n",
      "loss: 0.35112831563526664\n",
      "loss: 0.3512686584568126\n",
      "loss: 0.35144158158488065\n",
      "loss: 0.35149353564278185\n",
      "loss: 0.35091330376479934\n",
      "loss: 0.35212962021855804\n",
      "loss: 0.35154321152574314\n",
      "loss: 0.35145868308043604\n",
      "loss: 0.3509040381610889\n",
      "loss: 0.35114096866089456\n",
      "loss: 0.3507119436841886\n",
      "loss: 0.3516211834626692\n",
      "loss: 0.35221775196037286\n",
      "loss: 0.3519836206802813\n",
      "loss: 0.3509000560215921\n",
      "QNN: 0.145751953125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 15\n",
      "SD: 0.0697021484375\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.18476065011156967\n",
      "loss: 0.17642149251129255\n",
      "loss: 0.17642800236555856\n",
      "loss: 0.17639064005746144\n",
      "loss: 0.17634078474470988\n",
      "loss: 0.17632917123131644\n",
      "loss: 0.17636229564695202\n",
      "loss: 0.17632329122094226\n",
      "loss: 0.17634223115105835\n",
      "loss: 0.17629706944484425\n",
      "loss: 0.17631449892321466\n",
      "loss: 0.17675227954578618\n",
      "loss: 0.1767392884356227\n",
      "loss: 0.17637156478520827\n",
      "loss: 0.1765437197316621\n",
      "loss: 0.176296101039769\n",
      "loss: 0.17633646880361065\n",
      "loss: 0.17633872368882025\n",
      "loss: 0.1763037085396629\n",
      "QNN: 0.018798828125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 16\n",
      "SD: 0.0067138671875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.18089815021445912\n",
      "loss: 0.17453594810479794\n",
      "loss: 0.17425622744555846\n",
      "loss: 0.17408247901659776\n",
      "loss: 0.17407946384468345\n",
      "loss: 0.17416382146974405\n",
      "loss: 0.17410929544581072\n",
      "loss: 0.17409555504416901\n",
      "loss: 0.17406880921893692\n",
      "loss: 0.17405764306487118\n",
      "loss: 0.17439340266325165\n",
      "loss: 0.17422905362323118\n",
      "loss: 0.17423458413921158\n",
      "loss: 0.174113118882102\n",
      "loss: 0.1740939023449986\n",
      "loss: 0.17407486545390086\n",
      "loss: 0.17415821691044067\n",
      "loss: 0.17412477781293864\n",
      "loss: 0.17431468843099396\n",
      "QNN: 0.01416015625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 17\n",
      "SD: 0.1258544921875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.29688240087126905\n",
      "loss: 0.27112769829420186\n",
      "loss: 0.26592153710184235\n",
      "loss: 0.26457263935514924\n",
      "loss: 0.263794981785732\n",
      "loss: 0.2639575681176593\n",
      "loss: 0.26421722339285403\n",
      "loss: 0.2662874987375742\n",
      "loss: 0.2643095769200266\n",
      "loss: 0.2639910969123658\n",
      "loss: 0.26387107973640855\n",
      "loss: 0.26399406412596976\n",
      "loss: 0.26401133936236404\n",
      "loss: 0.26462300237621733\n",
      "loss: 0.2646064424260736\n",
      "loss: 0.26381911359675575\n",
      "loss: 0.2639553949657058\n",
      "loss: 0.26412305992129814\n",
      "loss: 0.26418011808290437\n",
      "QNN: 0.1043701171875\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 18\n",
      "SD: 0.0457763671875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.18745794595500218\n",
      "loss: 0.17014977691500224\n",
      "loss: 0.16965122130411528\n",
      "loss: 0.16959131208064318\n",
      "loss: 0.1696205346413146\n",
      "loss: 0.16950069823814842\n",
      "loss: 0.16971350752541844\n",
      "loss: 0.169913673298625\n",
      "loss: 0.16958125566167323\n",
      "loss: 0.16950777986682816\n",
      "loss: 0.16955285575687673\n",
      "loss: 0.1695785983753811\n",
      "loss: 0.169520652956958\n",
      "loss: 0.1696250646827488\n",
      "loss: 0.16961381928039362\n",
      "loss: 0.16974886413233153\n",
      "loss: 0.1696599660585194\n",
      "loss: 0.16969218717356135\n",
      "loss: 0.16947901300374082\n",
      "QNN: 0.0225830078125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 19\n",
      "SD: 0.1585693359375\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.3445025242413533\n",
      "loss: 0.30505422391914183\n",
      "loss: 0.29653243436466414\n",
      "loss: 0.29352279825615185\n",
      "loss: 0.29277255232819754\n",
      "loss: 0.29270088236370007\n",
      "loss: 0.293124895720625\n",
      "loss: 0.29369041535602475\n",
      "loss: 0.29273583667405817\n",
      "loss: 0.2932012316146874\n",
      "loss: 0.2935624177980896\n",
      "loss: 0.29401235477149057\n",
      "loss: 0.29356067986146456\n",
      "loss: 0.29251098627848626\n",
      "loss: 0.2925874175977913\n",
      "loss: 0.29277113622747725\n",
      "loss: 0.29297137738654133\n",
      "loss: 0.29303414560955093\n",
      "loss: 0.2926088461570167\n",
      "QNN: 0.11572265625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 20\n",
      "SD: 0.0067138671875\n",
      "loss: 0.6931471805599465\n",
      "loss: 0.17755494114036446\n",
      "loss: 0.17382010500692655\n",
      "loss: 0.17358127699812703\n",
      "loss: 0.17355050097891173\n",
      "loss: 0.17353370047918504\n",
      "loss: 0.17355022202597783\n",
      "loss: 0.17362742703386644\n",
      "loss: 0.1734936465694422\n",
      "loss: 0.1735601311172274\n",
      "loss: 0.17356349845112023\n",
      "loss: 0.1734884007456286\n",
      "loss: 0.17360542095678752\n",
      "loss: 0.17361060706925424\n",
      "loss: 0.173528160649911\n",
      "loss: 0.17347699980776238\n",
      "loss: 0.1736210268284431\n",
      "loss: 0.17361268844311106\n",
      "loss: 0.17349491708567677\n",
      "loss: 0.1735613354298241\n",
      "QNN: 0.027587890625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 21\n",
      "SD: 0.086669921875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.1611961651018517\n",
      "loss: 0.14554237654159355\n",
      "loss: 0.14494234972686426\n",
      "loss: 0.14448664993515564\n",
      "loss: 0.14437370559656876\n",
      "loss: 0.14433228026224448\n",
      "loss: 0.14431531963424338\n",
      "loss: 0.14435707733181855\n",
      "loss: 0.1443923382358154\n",
      "loss: 0.1445053303785096\n",
      "loss: 0.14435283063050144\n",
      "loss: 0.1444226148743454\n",
      "loss: 0.14438057064473722\n",
      "loss: 0.144677643279926\n",
      "loss: 0.1443841204614557\n",
      "loss: 0.14441077931064591\n",
      "loss: 0.14431959307374334\n",
      "loss: 0.1445574108302536\n",
      "loss: 0.1443979831504313\n",
      "QNN: 0.0244140625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 22\n",
      "SD: 0.0426025390625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2532203225469748\n",
      "loss: 0.24282633379847277\n",
      "loss: 0.24152770254241177\n",
      "loss: 0.24109608480516603\n",
      "loss: 0.24157328589748792\n",
      "loss: 0.24072838247429132\n",
      "loss: 0.24052901605031568\n",
      "loss: 0.2409002980357399\n",
      "loss: 0.2405689660900036\n",
      "loss: 0.24063961927154545\n",
      "loss: 0.24082881541061538\n",
      "loss: 0.24061444585806227\n",
      "loss: 0.2407497573637891\n",
      "loss: 0.24057924640765357\n",
      "loss: 0.24092885272915396\n",
      "loss: 0.2405589032937561\n",
      "loss: 0.24074554974604245\n",
      "loss: 0.24092921289765873\n",
      "loss: 0.24076827500310038\n",
      "QNN: 0.068603515625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 23\n",
      "SD: 0.1351318359375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.25494428594252355\n",
      "loss: 0.24869672261603604\n",
      "loss: 0.2480619497539869\n",
      "loss: 0.2482324565851907\n",
      "loss: 0.24810808807994267\n",
      "loss: 0.24825017450803447\n",
      "loss: 0.2480297422801183\n",
      "loss: 0.24822388248180857\n",
      "loss: 0.24818051093327195\n",
      "loss: 0.24812571942759917\n",
      "loss: 0.24806005591559094\n",
      "loss: 0.24810196087009917\n",
      "loss: 0.24820808037830905\n",
      "loss: 0.24811012374067454\n",
      "loss: 0.24813003586433413\n",
      "loss: 0.2481048273896302\n",
      "loss: 0.2483544401633278\n",
      "loss: 0.24818720557850174\n",
      "loss: 0.24815653922950423\n",
      "QNN: 0.0499267578125\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 24\n",
      "SD: 0.0296630859375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.19917239678645965\n",
      "loss: 0.13423962520853344\n",
      "loss: 0.10866677188734943\n",
      "loss: 0.1075236329044511\n",
      "loss: 0.10749103456599003\n",
      "loss: 0.10740742250522761\n",
      "loss: 0.10747472335349648\n",
      "loss: 0.10740133540816284\n",
      "loss: 0.10753807994496979\n",
      "loss: 0.10769827089897487\n",
      "loss: 0.10757556733897386\n",
      "loss: 0.10760922207896984\n",
      "loss: 0.10745817100190141\n",
      "loss: 0.10749216662895532\n",
      "loss: 0.1074743250292291\n",
      "loss: 0.10742720026759685\n",
      "loss: 0.10749141155095038\n",
      "loss: 0.10742081720120326\n",
      "loss: 0.10744336405128516\n",
      "QNN: 0.0093994140625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 25\n",
      "SD: 0.0439453125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2084509469020261\n",
      "loss: 0.20316105634897816\n",
      "loss: 0.2026881093052814\n",
      "loss: 0.20258753678984298\n",
      "loss: 0.20266543412370586\n",
      "loss: 0.20255902658584612\n",
      "loss: 0.2027836740176023\n",
      "loss: 0.20291022586521484\n",
      "loss: 0.20273585191552465\n",
      "loss: 0.20253588073433315\n",
      "loss: 0.2026143202142176\n",
      "loss: 0.20259633541582459\n",
      "loss: 0.2025739944329475\n",
      "loss: 0.20257215328278647\n",
      "loss: 0.2026244420828077\n",
      "loss: 0.20258918337781892\n",
      "loss: 0.20254440119937012\n",
      "loss: 0.202689792557156\n",
      "loss: 0.20270612402265817\n",
      "QNN: 0.0457763671875\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 26\n",
      "SD: 0.0467529296875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.342083004980586\n",
      "loss: 0.3041293266040792\n",
      "loss: 0.2960231872703291\n",
      "loss: 0.29300999674964523\n",
      "loss: 0.2915838657825396\n",
      "loss: 0.2915623075185946\n",
      "loss: 0.2916186538220285\n",
      "loss: 0.2915233266796165\n",
      "loss: 0.29177433628014315\n",
      "loss: 0.2915964085459735\n",
      "loss: 0.2924903637400435\n",
      "loss: 0.29259718243971305\n",
      "loss: 0.2924026440907415\n",
      "loss: 0.2925739514892519\n",
      "loss: 0.29222440364153207\n",
      "loss: 0.2920702363530776\n",
      "loss: 0.29160731369600973\n",
      "loss: 0.29219342052409136\n",
      "loss: 0.29297174233444245\n",
      "loss: 0.2919286519226327\n",
      "loss: 0.2922927404536867\n",
      "loss: 0.29151314183788185\n",
      "loss: 0.29219376334955993\n",
      "loss: 0.2930078270187621\n",
      "loss: 0.2931103898916246\n",
      "loss: 0.29206394910527933\n",
      "loss: 0.29196200184088567\n",
      "loss: 0.29166225315171834\n",
      "loss: 0.2916138320954574\n",
      "loss: 0.29166103057090564\n",
      "loss: 0.29239035591046164\n",
      "loss: 0.2917886828487025\n",
      "loss: 0.29192432097524224\n",
      "loss: 0.2919533508104175\n",
      "loss: 0.29306743244857575\n",
      "loss: 0.29249699451708644\n",
      "loss: 0.2916194446394761\n",
      "loss: 0.292564102332314\n",
      "loss: 0.29149225411075613\n",
      "QNN: 0.119384765625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 27\n",
      "SD: 0.0228271484375\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.11581915210853772\n",
      "loss: 0.10696611446709615\n",
      "loss: 0.10647692442029859\n",
      "loss: 0.106457696083341\n",
      "loss: 0.10640025875043173\n",
      "loss: 0.1063832221889436\n",
      "loss: 0.10661393850141956\n",
      "loss: 0.10644679692480674\n",
      "loss: 0.10644246163695092\n",
      "loss: 0.10646341239311853\n",
      "loss: 0.10642642206455251\n",
      "loss: 0.10636741318489384\n",
      "loss: 0.10636084774278824\n",
      "loss: 0.10666803373965833\n",
      "loss: 0.10644918920484073\n",
      "loss: 0.10640083473197544\n",
      "loss: 0.10635519011341402\n",
      "loss: 0.10641884383895397\n",
      "loss: 0.10639244537279037\n",
      "QNN: 0.00341796875\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 28\n",
      "SD: 0.1976318359375\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.10977796650774875\n",
      "loss: 0.10268221376927449\n",
      "loss: 0.10246914464467587\n",
      "loss: 0.10248375545091529\n",
      "loss: 0.1024432748648192\n",
      "loss: 0.10242959855792545\n",
      "loss: 0.10256906373157179\n",
      "loss: 0.10240551320511748\n",
      "loss: 0.10244477097066809\n",
      "loss: 0.10239894218124676\n",
      "loss: 0.10240632583091598\n",
      "loss: 0.10244306860698744\n",
      "loss: 0.10240119858329426\n",
      "loss: 0.10243089431179302\n",
      "loss: 0.10251982196747805\n",
      "loss: 0.10247073918990432\n",
      "loss: 0.10246949042189586\n",
      "loss: 0.10242738341553524\n",
      "loss: 0.10237079990592217\n",
      "QNN: 0.0025634765625\n",
      "----------------------------current SNR_dB: 10\n",
      "----------------------------current iter num: 29\n",
      "SD: 0.0552978515625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.1481495370677214\n",
      "loss: 0.12978107140916093\n",
      "loss: 0.12845487706063655\n",
      "loss: 0.12841214675198018\n",
      "loss: 0.1282952906575293\n",
      "loss: 0.12830596614697104\n",
      "loss: 0.12852982626463103\n",
      "loss: 0.12837682003721787\n",
      "loss: 0.1283256367280636\n",
      "loss: 0.12834523894014815\n",
      "loss: 0.12863024556993038\n",
      "loss: 0.12829422182036085\n",
      "loss: 0.12840242293137388\n",
      "loss: 0.12843623663465728\n",
      "loss: 0.12835487094393838\n",
      "loss: 0.12830861621509654\n",
      "loss: 0.12829856472644466\n",
      "loss: 0.12839953498502818\n",
      "loss: 0.12840585844396835\n",
      "QNN: 0.009765625\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 0\n",
      "SD: 0.0008544921875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.14056377195559971\n",
      "loss: 0.12831512124083627\n",
      "loss: 0.12763231370467062\n",
      "loss: 0.12745597265608702\n",
      "loss: 0.127469828907594\n",
      "loss: 0.12739692709227368\n",
      "loss: 0.12732395190961923\n",
      "loss: 0.12741799768714138\n",
      "loss: 0.12734865528401143\n",
      "loss: 0.1273361014715313\n",
      "loss: 0.1273392754767726\n",
      "loss: 0.1273746998984234\n",
      "loss: 0.1273761148321079\n",
      "loss: 0.12737987320443245\n",
      "loss: 0.12735556565359626\n",
      "loss: 0.12750232036912457\n",
      "loss: 0.12752644526923979\n",
      "loss: 0.12735791088059273\n",
      "loss: 0.12745596049394833\n",
      "QNN: 0.0037841796875\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 1\n",
      "SD: 0.0487060546875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.17366842426498794\n",
      "loss: 0.1622828570511979\n",
      "loss: 0.16173019790016058\n",
      "loss: 0.16170278316636566\n",
      "loss: 0.16184425923140447\n",
      "loss: 0.1617605235794218\n",
      "loss: 0.1617685011139975\n",
      "loss: 0.16173994382901688\n",
      "loss: 0.16165558591525703\n",
      "loss: 0.1617854359778378\n",
      "loss: 0.16167530811361722\n",
      "loss: 0.16172541811148136\n",
      "loss: 0.16173270495728456\n",
      "loss: 0.16182349274914282\n",
      "loss: 0.16169917993367144\n",
      "loss: 0.16168618717307243\n",
      "loss: 0.1616950258856008\n",
      "loss: 0.1617131161193796\n",
      "loss: 0.1617760862827365\n",
      "QNN: 0.001220703125\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 2\n",
      "SD: 0.000732421875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.22247516552831176\n",
      "loss: 0.21069489168120886\n",
      "loss: 0.21041841765120936\n",
      "loss: 0.21034460686329992\n",
      "loss: 0.2103562907732354\n",
      "loss: 0.21036557822278137\n",
      "loss: 0.21032274615755775\n",
      "loss: 0.21032279040838286\n",
      "loss: 0.21040499498839638\n",
      "loss: 0.2103458137625654\n",
      "loss: 0.21034612956052512\n",
      "loss: 0.2104026949984702\n",
      "loss: 0.21056629883925435\n",
      "loss: 0.2103257249289665\n",
      "loss: 0.2103710770187536\n",
      "loss: 0.21033215322347484\n",
      "loss: 0.21037195562455244\n",
      "loss: 0.210302967028978\n",
      "loss: 0.21030176692596944\n",
      "QNN: 0.017333984375\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 3\n",
      "SD: 0.0230712890625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.17151446818038155\n",
      "loss: 0.14571749223336095\n",
      "loss: 0.14520340647780133\n",
      "loss: 0.1452136961356192\n",
      "loss: 0.14522941710913256\n",
      "loss: 0.145191181680461\n",
      "loss: 0.1453095566406234\n",
      "loss: 0.1452414054398404\n",
      "loss: 0.14522444688482733\n",
      "loss: 0.14525497300687257\n",
      "loss: 0.14522197285194247\n",
      "loss: 0.14520237009245407\n",
      "loss: 0.14528216386132475\n",
      "loss: 0.14523669508666473\n",
      "loss: 0.1452422049751855\n",
      "loss: 0.14528038732200954\n",
      "loss: 0.14528501173225908\n",
      "loss: 0.1453726876337672\n",
      "loss: 0.14529154260237698\n",
      "QNN: 0.002685546875\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 4\n",
      "SD: 0.0848388671875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.12709255974285413\n",
      "loss: 0.11853534172290735\n",
      "loss: 0.11835842379184996\n",
      "loss: 0.11842318669688501\n",
      "loss: 0.1184040471506709\n",
      "loss: 0.11830294589346789\n",
      "loss: 0.11827253503016236\n",
      "loss: 0.11829638948293439\n",
      "loss: 0.11825204914555427\n",
      "loss: 0.11826521317244862\n",
      "loss: 0.11829873817585392\n",
      "loss: 0.11844116245976526\n",
      "loss: 0.11834368254231308\n",
      "loss: 0.11844169909356853\n",
      "loss: 0.11826325850775339\n",
      "loss: 0.1183287246977779\n",
      "loss: 0.11841367845039026\n",
      "loss: 0.118261343316065\n",
      "loss: 0.11826754843168981\n",
      "QNN: 0.001220703125\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 5\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.1502868522387399\n",
      "loss: 0.13603411471228158\n",
      "loss: 0.13545147268516072\n",
      "loss: 0.13548796975039232\n",
      "loss: 0.1354628124758671\n",
      "loss: 0.13545607188980155\n",
      "loss: 0.13541294334842632\n",
      "loss: 0.13542261236784\n",
      "loss: 0.13556411950208458\n",
      "loss: 0.13545181419579375\n",
      "loss: 0.13543484035758524\n",
      "loss: 0.13544696567913006\n",
      "loss: 0.13577748338397413\n",
      "loss: 0.13545932259018595\n",
      "loss: 0.13548145771867248\n",
      "loss: 0.13544163680171611\n",
      "loss: 0.13544612547628773\n",
      "loss: 0.1354690062565757\n",
      "loss: 0.13546914104993582\n",
      "QNN: 0.003173828125\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 6\n",
      "SD: 0.0030517578125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.17417492286994302\n",
      "loss: 0.14681752819113075\n",
      "loss: 0.14539448349168752\n",
      "loss: 0.14526594019171032\n",
      "loss: 0.14524029214813208\n",
      "loss: 0.14543103836986523\n",
      "loss: 0.14532130172793042\n",
      "loss: 0.1457978852364684\n",
      "loss: 0.14560266315320727\n",
      "loss: 0.14538172430901986\n",
      "loss: 0.14538611737755813\n",
      "loss: 0.14533758735105937\n",
      "loss: 0.14536503738438333\n",
      "loss: 0.14554773480242103\n",
      "loss: 0.1452462075384899\n",
      "loss: 0.1454070728843118\n",
      "loss: 0.14539975099474367\n",
      "loss: 0.14530651268092276\n",
      "loss: 0.14526603776079966\n",
      "QNN: 0.003662109375\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 7\n",
      "SD: 0.0350341796875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2668930598838338\n",
      "loss: 0.24266161177813314\n",
      "loss: 0.2384189591817638\n",
      "loss: 0.23795227710426525\n",
      "loss: 0.2379244029836735\n",
      "loss: 0.23773415588580693\n",
      "loss: 0.2378140025275407\n",
      "loss: 0.23772733607718352\n",
      "loss: 0.23785692247696513\n",
      "loss: 0.23774111095246342\n",
      "loss: 0.237735795232914\n",
      "loss: 0.23784224337961465\n",
      "loss: 0.23790476491385973\n",
      "loss: 0.2379701654053505\n",
      "loss: 0.23821415765822515\n",
      "loss: 0.23803028609467872\n",
      "loss: 0.23767812633623198\n",
      "loss: 0.23778835131222575\n",
      "loss: 0.237782161194095\n",
      "QNN: 0.0552978515625\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 8\n",
      "SD: 0.02783203125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.25859184278747027\n",
      "loss: 0.24526407530808358\n",
      "loss: 0.24470699161606277\n",
      "loss: 0.24416809575410256\n",
      "loss: 0.24405399460422159\n",
      "loss: 0.24410369100615215\n",
      "loss: 0.24435840159183336\n",
      "loss: 0.24408765862551082\n",
      "loss: 0.24428116618275114\n",
      "loss: 0.24419013747278914\n",
      "loss: 0.24441662566515993\n",
      "loss: 0.24412996357666777\n",
      "loss: 0.2441152946720495\n",
      "loss: 0.24404793031589306\n",
      "loss: 0.24411623774621574\n",
      "loss: 0.2440295339628046\n",
      "loss: 0.24407082836125735\n",
      "loss: 0.24408957274942109\n",
      "loss: 0.24429352881513522\n",
      "QNN: 0.05908203125\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 9\n",
      "SD: 0.000244140625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.27311362033236375\n",
      "loss: 0.23729230517245314\n",
      "loss: 0.23264190833379056\n",
      "loss: 0.2319106434069477\n",
      "loss: 0.23175706676821684\n",
      "loss: 0.23172743945228289\n",
      "loss: 0.2317425944445298\n",
      "loss: 0.23166119637926127\n",
      "loss: 0.23164405648605152\n",
      "loss: 0.2320351967074183\n",
      "loss: 0.2319354738332534\n",
      "loss: 0.23167017255043706\n",
      "loss: 0.2317065868250196\n",
      "loss: 0.23176126923880574\n",
      "loss: 0.23161414437615568\n",
      "loss: 0.2316728982445083\n",
      "loss: 0.2316187124849744\n",
      "loss: 0.23165067510629972\n",
      "loss: 0.23169124300712818\n",
      "QNN: 0.046630859375\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 10\n",
      "SD: 0.0126953125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2721705599664544\n",
      "loss: 0.24821916012987644\n",
      "loss: 0.2468971654589206\n",
      "loss: 0.24673100014369015\n",
      "loss: 0.24671173112487232\n",
      "loss: 0.24669246649725848\n",
      "loss: 0.2466932304664666\n",
      "loss: 0.24673038625765897\n",
      "loss: 0.24671644541678947\n",
      "loss: 0.24675880780628492\n",
      "loss: 0.2469641377903365\n",
      "loss: 0.24675844800081942\n",
      "loss: 0.2468050249607894\n",
      "loss: 0.24679360226251557\n",
      "loss: 0.2467175634974256\n",
      "loss: 0.24673722297307601\n",
      "loss: 0.24697225172176918\n",
      "loss: 0.24685484863279727\n",
      "loss: 0.24679193766431157\n",
      "QNN: 0.060791015625\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 11\n",
      "SD: 0.002197265625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.15903044870769353\n",
      "loss: 0.14741043364067719\n",
      "loss: 0.14688454531200745\n",
      "loss: 0.1467599469618982\n",
      "loss: 0.14678756941855936\n",
      "loss: 0.14682317677820972\n",
      "loss: 0.14694050210892648\n",
      "loss: 0.1467768748326416\n",
      "loss: 0.14680506064262547\n",
      "loss: 0.14683966083524674\n",
      "loss: 0.14681259184034554\n",
      "loss: 0.14677558972964275\n",
      "loss: 0.1467329031987853\n",
      "loss: 0.14675772193005757\n",
      "loss: 0.14681257823482768\n",
      "loss: 0.14674906982336533\n",
      "loss: 0.14673575746441286\n",
      "loss: 0.14686897700011003\n",
      "loss: 0.1467369116086028\n",
      "QNN: 0.002197265625\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 12\n",
      "SD: 0.02392578125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.09007848702207998\n",
      "loss: 0.04109186995517834\n",
      "loss: 0.03803134171593952\n",
      "loss: 0.037781784353954385\n",
      "loss: 0.037721821664996595\n",
      "loss: 0.037702478130135386\n",
      "loss: 0.037694209253317464\n",
      "loss: 0.037702636489733946\n",
      "loss: 0.03769154331245782\n",
      "loss: 0.037722400676235605\n",
      "loss: 0.037695830889003704\n",
      "loss: 0.03769605510612773\n",
      "loss: 0.037696482796187473\n",
      "loss: 0.037703098382937415\n",
      "loss: 0.03769449619915765\n",
      "loss: 0.03769768590997994\n",
      "loss: 0.03769276519995708\n",
      "loss: 0.03769641952467062\n",
      "loss: 0.03770079637142009\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 13\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.17027111626523833\n",
      "loss: 0.14380871978862275\n",
      "loss: 0.1401045583656693\n",
      "loss: 0.14000002511228185\n",
      "loss: 0.1400213917149104\n",
      "loss: 0.14005687152572846\n",
      "loss: 0.14001531294339276\n",
      "loss: 0.13999936674404748\n",
      "loss: 0.13999881486019228\n",
      "loss: 0.14008550281345\n",
      "loss: 0.1400253775838427\n",
      "loss: 0.14001192179543057\n",
      "loss: 0.14001225846406673\n",
      "loss: 0.1400603269096588\n",
      "loss: 0.14008571899826341\n",
      "loss: 0.13996376299485408\n",
      "loss: 0.1400694575998187\n",
      "loss: 0.140075590359099\n",
      "loss: 0.14000496991610692\n",
      "QNN: 0.0010986328125\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 14\n",
      "SD: 0.0458984375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3812579920473254\n",
      "loss: 0.3622886186435881\n",
      "loss: 0.3522867951321843\n",
      "loss: 0.34211452835397466\n",
      "loss: 0.33314082893411084\n",
      "loss: 0.33218631138290805\n",
      "loss: 0.3284443067863935\n",
      "loss: 0.32688617986503143\n",
      "loss: 0.32707514909093216\n",
      "loss: 0.3262260161416134\n",
      "loss: 0.3262744641074519\n",
      "loss: 0.32625285396650755\n",
      "loss: 0.3262822721498511\n",
      "loss: 0.32642667882806137\n",
      "loss: 0.3262459445867904\n",
      "loss: 0.32646334609089506\n",
      "loss: 0.32701555608904986\n",
      "loss: 0.3271628992861898\n",
      "loss: 0.32789574908446145\n",
      "QNN: 0.1466064453125\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 15\n",
      "SD: 0.0069580078125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.1608162574546666\n",
      "loss: 0.1557568294012797\n",
      "loss: 0.15560017737489762\n",
      "loss: 0.15556792056280563\n",
      "loss: 0.15570728627716193\n",
      "loss: 0.1556483737792831\n",
      "loss: 0.155617361538552\n",
      "loss: 0.15564070574462194\n",
      "loss: 0.1556559165507382\n",
      "loss: 0.15563208716206314\n",
      "loss: 0.15556411409477264\n",
      "loss: 0.1555584831005903\n",
      "loss: 0.15571056122931098\n",
      "loss: 0.15560565982069033\n",
      "loss: 0.15555330505073742\n",
      "loss: 0.1556868779248983\n",
      "loss: 0.15560569578065617\n",
      "loss: 0.15553802169558734\n",
      "loss: 0.15559369375743093\n",
      "QNN: 0.00537109375\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 16\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1791940277409233\n",
      "loss: 0.15742652234105076\n",
      "loss: 0.15579559491776132\n",
      "loss: 0.15572135767421114\n",
      "loss: 0.15541796564057364\n",
      "loss: 0.1554166102993122\n",
      "loss: 0.15540627637792884\n",
      "loss: 0.15594617925482224\n",
      "loss: 0.1553813510738833\n",
      "loss: 0.15546750776992646\n",
      "loss: 0.1554914322763529\n",
      "loss: 0.15531708776716296\n",
      "loss: 0.15541420735929387\n",
      "loss: 0.15547838420288115\n",
      "loss: 0.15557417970588275\n",
      "loss: 0.1553117178670586\n",
      "loss: 0.1555650491350499\n",
      "loss: 0.1553898540789385\n",
      "loss: 0.15547168480081885\n",
      "QNN: 0.0023193359375\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 17\n",
      "SD: 0.0277099609375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.29844132514075944\n",
      "loss: 0.26008404692468007\n",
      "loss: 0.25279805252469\n",
      "loss: 0.25141138988587036\n",
      "loss: 0.25182828082227593\n",
      "loss: 0.251795780889588\n",
      "loss: 0.25157302024824135\n",
      "loss: 0.2518301219186153\n",
      "loss: 0.2517575861586274\n",
      "loss: 0.25136248531346844\n",
      "loss: 0.2517701524919435\n",
      "loss: 0.2516386198023566\n",
      "loss: 0.2514610807264859\n",
      "loss: 0.2513262341337045\n",
      "loss: 0.2515444415861779\n",
      "loss: 0.2517560386046465\n",
      "loss: 0.2514398602554843\n",
      "loss: 0.2514898630429876\n",
      "loss: 0.2517668985402401\n",
      "QNN: 0.1044921875\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 18\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.16752552112198818\n",
      "loss: 0.1460960620423354\n",
      "loss: 0.14546551638865846\n",
      "loss: 0.14535927288842362\n",
      "loss: 0.14530971048199082\n",
      "loss: 0.14532717642101026\n",
      "loss: 0.14532469019402403\n",
      "loss: 0.14536425609169046\n",
      "loss: 0.14532338486407778\n",
      "loss: 0.14532769292826184\n",
      "loss: 0.14555953934397706\n",
      "loss: 0.14538417449951113\n",
      "loss: 0.14534385709648304\n",
      "loss: 0.14549684171873548\n",
      "loss: 0.1453384816643849\n",
      "loss: 0.14549385765999312\n",
      "loss: 0.14538673732982987\n",
      "loss: 0.14552415140545708\n",
      "loss: 0.14534456683516328\n",
      "QNN: 0.0093994140625\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 19\n",
      "SD: 0.03955078125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3098946948424514\n",
      "loss: 0.29643409999300635\n",
      "loss: 0.29586263580416955\n",
      "loss: 0.2954370414258799\n",
      "loss: 0.2958344996703624\n",
      "loss: 0.294509826544981\n",
      "loss: 0.2944247030528002\n",
      "loss: 0.2942063749355144\n",
      "loss: 0.29434209262854344\n",
      "loss: 0.294090103415725\n",
      "loss: 0.2941291113225952\n",
      "loss: 0.29431777798955966\n",
      "loss: 0.294081987792945\n",
      "loss: 0.29442149230488107\n",
      "loss: 0.29426583476300056\n",
      "loss: 0.294056330334982\n",
      "loss: 0.29420647168694475\n",
      "loss: 0.29403144048867075\n",
      "loss: 0.29440217902804205\n",
      "QNN: 0.0936279296875\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 20\n",
      "SD: 0.0001220703125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.18238805130755478\n",
      "loss: 0.16538284984933024\n",
      "loss: 0.1643254315667\n",
      "loss: 0.16423313180704482\n",
      "loss: 0.16426913264642806\n",
      "loss: 0.16422872007148062\n",
      "loss: 0.16430344745380177\n",
      "loss: 0.16425836453547688\n",
      "loss: 0.16425300092727735\n",
      "loss: 0.16422099963906314\n",
      "loss: 0.16425430642168254\n",
      "loss: 0.16423671468983256\n",
      "loss: 0.1642373294082093\n",
      "loss: 0.1643651698990929\n",
      "loss: 0.16431725930991617\n",
      "loss: 0.16428986640272597\n",
      "loss: 0.1642366588020402\n",
      "loss: 0.16438846126536016\n",
      "loss: 0.16425035933603446\n",
      "QNN: 0.0052490234375\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 21\n",
      "SD: 0.0057373046875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1342508602707034\n",
      "loss: 0.12972251521536504\n",
      "loss: 0.129474558493673\n",
      "loss: 0.1293076978330954\n",
      "loss: 0.12932488397703337\n",
      "loss: 0.1292913336599697\n",
      "loss: 0.12928514284966003\n",
      "loss: 0.1293898554397871\n",
      "loss: 0.12931375964076414\n",
      "loss: 0.12938831779752355\n",
      "loss: 0.1292860439191247\n",
      "loss: 0.12928722467205278\n",
      "loss: 0.12928654259319455\n",
      "loss: 0.12936290525417596\n",
      "loss: 0.12930112943095615\n",
      "loss: 0.12927180770209154\n",
      "loss: 0.12930989952328592\n",
      "loss: 0.12929228819327057\n",
      "loss: 0.12928552803376508\n",
      "QNN: 0.00537109375\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 22\n",
      "SD: 0.0023193359375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2393015712597576\n",
      "loss: 0.21107719254062096\n",
      "loss: 0.20735348923222982\n",
      "loss: 0.20723600917318297\n",
      "loss: 0.20758617887303746\n",
      "loss: 0.2076027334587539\n",
      "loss: 0.20707532347830393\n",
      "loss: 0.2069884862062741\n",
      "loss: 0.20691181061213396\n",
      "loss: 0.2068731232312437\n",
      "loss: 0.20700996269936003\n",
      "loss: 0.2068822645204709\n",
      "loss: 0.20717259306138172\n",
      "loss: 0.20700849311447275\n",
      "loss: 0.20734671972544066\n",
      "loss: 0.2084799492113879\n",
      "loss: 0.20764660485639377\n",
      "loss: 0.20770885455084065\n",
      "loss: 0.20689129160956626\n",
      "QNN: 0.04296875\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 23\n",
      "SD: 0.0499267578125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.24173457816974395\n",
      "loss: 0.23236465896743994\n",
      "loss: 0.2318540891992146\n",
      "loss: 0.23199211161857128\n",
      "loss: 0.23198473121392843\n",
      "loss: 0.23187845188536232\n",
      "loss: 0.23186203860270904\n",
      "loss: 0.23192059438928658\n",
      "loss: 0.23182409402945803\n",
      "loss: 0.23183287931314162\n",
      "loss: 0.23188488041462446\n",
      "loss: 0.23189551684517776\n",
      "loss: 0.23188361561405096\n",
      "loss: 0.23197268089266335\n",
      "loss: 0.23196583991487607\n",
      "loss: 0.2318929933613156\n",
      "loss: 0.2318909848551816\n",
      "loss: 0.23252761446374234\n",
      "loss: 0.23198851149748648\n",
      "QNN: 0.0333251953125\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 24\n",
      "SD: 0.00146484375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1321182676988104\n",
      "loss: 0.09989487318449694\n",
      "loss: 0.09785103591957814\n",
      "loss: 0.09775071852874385\n",
      "loss: 0.09778051307304009\n",
      "loss: 0.0978138716578986\n",
      "loss: 0.09773304363945681\n",
      "loss: 0.09770824912647137\n",
      "loss: 0.09780906694272555\n",
      "loss: 0.0977226627468293\n",
      "loss: 0.09770061004899114\n",
      "loss: 0.09777036025341389\n",
      "loss: 0.09771144325922947\n",
      "loss: 0.09771699575876422\n",
      "loss: 0.09772244673254427\n",
      "loss: 0.09774356912029895\n",
      "loss: 0.09774962089733424\n",
      "loss: 0.097750765587443\n",
      "loss: 0.09770658582581\n",
      "QNN: 0.0003662109375\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 25\n",
      "SD: 0.0030517578125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.19843606502717062\n",
      "loss: 0.18801345120573573\n",
      "loss: 0.18780071037079996\n",
      "loss: 0.18778371761819246\n",
      "loss: 0.18790545808200404\n",
      "loss: 0.18773251403728142\n",
      "loss: 0.1878055217491714\n",
      "loss: 0.18782643433659835\n",
      "loss: 0.18782318997983452\n",
      "loss: 0.18781591066539083\n",
      "loss: 0.18782874595749605\n",
      "loss: 0.18773561517139895\n",
      "loss: 0.18773427140323815\n",
      "loss: 0.18776791841160678\n",
      "loss: 0.1878103464693829\n",
      "loss: 0.1878480048319297\n",
      "loss: 0.18787646173732517\n",
      "loss: 0.18777271846767513\n",
      "loss: 0.18777988062898535\n",
      "QNN: 0.0361328125\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 26\n",
      "SD: 0.00244140625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.33890235933780133\n",
      "loss: 0.3026174228579145\n",
      "loss: 0.2925730952945365\n",
      "loss: 0.2857506681009954\n",
      "loss: 0.28396243922650827\n",
      "loss: 0.28355689113935467\n",
      "loss: 0.2827662121546969\n",
      "loss: 0.2827070717717289\n",
      "loss: 0.28270865341712026\n",
      "loss: 0.28282046216601564\n",
      "loss: 0.2827483635676014\n",
      "loss: 0.28269643468946537\n",
      "loss: 0.28283277862782474\n",
      "loss: 0.28263619700609677\n",
      "loss: 0.2827615420688481\n",
      "loss: 0.2830372199103727\n",
      "loss: 0.28322198239655266\n",
      "loss: 0.2831141044152833\n",
      "loss: 0.2828705383215107\n",
      "QNN: 0.1151123046875\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 27\n",
      "SD: 0.000244140625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.10504270499668317\n",
      "loss: 0.08986211261946732\n",
      "loss: 0.08957225199325353\n",
      "loss: 0.08951451477207718\n",
      "loss: 0.08951186157107835\n",
      "loss: 0.08953846968672327\n",
      "loss: 0.08956757777105466\n",
      "loss: 0.08952404841703304\n",
      "loss: 0.08950427184789293\n",
      "loss: 0.0895115948001091\n",
      "loss: 0.08947697297067916\n",
      "loss: 0.08954383974140025\n",
      "loss: 0.08950990632884073\n",
      "loss: 0.08957105807299816\n",
      "loss: 0.08957190139504223\n",
      "loss: 0.08956034103848949\n",
      "loss: 0.08949571670198217\n",
      "loss: 0.08952363914175095\n",
      "loss: 0.0895079784128241\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 28\n",
      "SD: 0.0615234375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.09645684174521182\n",
      "loss: 0.09081958566863971\n",
      "loss: 0.09057991698231899\n",
      "loss: 0.09061723117659301\n",
      "loss: 0.09060121127630291\n",
      "loss: 0.09074434744258118\n",
      "loss: 0.09058079864855235\n",
      "loss: 0.09073249540133124\n",
      "loss: 0.09057100494146833\n",
      "loss: 0.0905879164211288\n",
      "loss: 0.09055794032267261\n",
      "loss: 0.09058414520285187\n",
      "loss: 0.09057266884419105\n",
      "loss: 0.0906983411166761\n",
      "loss: 0.09061347230669993\n",
      "loss: 0.09059757694285664\n",
      "loss: 0.0906296753344862\n",
      "loss: 0.09060294884990457\n",
      "loss: 0.09059738676744723\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 15\n",
      "----------------------------current iter num: 29\n",
      "SD: 0.002685546875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.13090457050988202\n",
      "loss: 0.1190231500324888\n",
      "loss: 0.1186073658203825\n",
      "loss: 0.11855251332946563\n",
      "loss: 0.11864270519102309\n",
      "loss: 0.11858759633467292\n",
      "loss: 0.11857469536387308\n",
      "loss: 0.11865709525658107\n",
      "loss: 0.11857698112959837\n",
      "loss: 0.11875834174588534\n",
      "loss: 0.11864823167729575\n",
      "loss: 0.1185559117525326\n",
      "loss: 0.1185898722659981\n",
      "loss: 0.11860632890871502\n",
      "loss: 0.11852957603387287\n",
      "loss: 0.11857150263558558\n",
      "loss: 0.11853693378686099\n",
      "loss: 0.11852084289552614\n",
      "loss: 0.11857504368909297\n",
      "QNN: 0.0006103515625\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 0\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1368624713317883\n",
      "loss: 0.12274689256245458\n",
      "loss: 0.12166333453398351\n",
      "loss: 0.12164532274511475\n",
      "loss: 0.12166947291373338\n",
      "loss: 0.12150362965850886\n",
      "loss: 0.12147592319729994\n",
      "loss: 0.12148909033972315\n",
      "loss: 0.1215009315844975\n",
      "loss: 0.12145123893040569\n",
      "loss: 0.12142257766565112\n",
      "loss: 0.12147564760899583\n",
      "loss: 0.12145904380569558\n",
      "loss: 0.12151325200727878\n",
      "loss: 0.12154644428682272\n",
      "loss: 0.12143709564623216\n",
      "loss: 0.12154708426883223\n",
      "loss: 0.12161804283508698\n",
      "loss: 0.12148131474028839\n",
      "QNN: 0.000244140625\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 1\n",
      "SD: 0.007568359375\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1652182675393844\n",
      "loss: 0.15972390593596475\n",
      "loss: 0.1597851023394266\n",
      "loss: 0.15971189412261486\n",
      "loss: 0.1596702306859654\n",
      "loss: 0.15965888823026314\n",
      "loss: 0.1596510535000344\n",
      "loss: 0.1596356166947753\n",
      "loss: 0.15967925506728115\n",
      "loss: 0.15963033168250715\n",
      "loss: 0.15963199247685667\n",
      "loss: 0.15960958110542425\n",
      "loss: 0.15961279675842777\n",
      "loss: 0.15964735645974282\n",
      "loss: 0.15964212405800632\n",
      "loss: 0.15964791943743747\n",
      "loss: 0.15963911820992532\n",
      "loss: 0.15966576496430923\n",
      "loss: 0.159615131333932\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 2\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.23707546325935466\n",
      "loss: 0.2021176949697178\n",
      "loss: 0.20001434998192483\n",
      "loss: 0.20005751316582346\n",
      "loss: 0.20002390815056484\n",
      "loss: 0.20002691321191526\n",
      "loss: 0.20003374449659567\n",
      "loss: 0.20003361182405519\n",
      "loss: 0.2000067259908919\n",
      "loss: 0.2001340937184736\n",
      "loss: 0.200031005172718\n",
      "loss: 0.19993724619953893\n",
      "loss: 0.19993258728833696\n",
      "loss: 0.19999214045305463\n",
      "loss: 0.20002261924748743\n",
      "loss: 0.2000310981218719\n",
      "loss: 0.20001195436693622\n",
      "loss: 0.19992035601103267\n",
      "loss: 0.19994660712562673\n",
      "QNN: 0.01416015625\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 3\n",
      "SD: 0.000732421875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.17240178785459032\n",
      "loss: 0.14230643513661664\n",
      "loss: 0.14148282791149128\n",
      "loss: 0.14145587686054378\n",
      "loss: 0.14152322706136808\n",
      "loss: 0.14145562677561313\n",
      "loss: 0.14144381125098027\n",
      "loss: 0.1414447821404468\n",
      "loss: 0.14147193249669784\n",
      "loss: 0.14144570091435937\n",
      "loss: 0.14144275042928728\n",
      "loss: 0.14145117581129252\n",
      "loss: 0.14144250444330053\n",
      "loss: 0.14155927185938547\n",
      "loss: 0.14150666420161986\n",
      "loss: 0.14146128744889647\n",
      "loss: 0.14147084604281265\n",
      "loss: 0.1416603664020028\n",
      "loss: 0.1414843238710434\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 4\n",
      "SD: 0.0067138671875\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.12192730532872864\n",
      "loss: 0.11232682468506425\n",
      "loss: 0.11197997271748107\n",
      "loss: 0.11192906799844278\n",
      "loss: 0.11193500441513492\n",
      "loss: 0.11194714618696844\n",
      "loss: 0.11196816448544405\n",
      "loss: 0.11194032792946423\n",
      "loss: 0.11207390051636522\n",
      "loss: 0.11194478303393318\n",
      "loss: 0.11194917659078252\n",
      "loss: 0.11195807276566379\n",
      "loss: 0.11192392262339262\n",
      "loss: 0.11192203420719266\n",
      "loss: 0.1119646498829822\n",
      "loss: 0.11195893037797369\n",
      "loss: 0.11194679143902277\n",
      "loss: 0.11194838092856288\n",
      "loss: 0.11194864758333069\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 5\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.15457441836727753\n",
      "loss: 0.13226677052844793\n",
      "loss: 0.13107690373216835\n",
      "loss: 0.1310817689368192\n",
      "loss: 0.13119001416256698\n",
      "loss: 0.13111779515787414\n",
      "loss: 0.13107109018162783\n",
      "loss: 0.13107794584540886\n",
      "loss: 0.13106801258814146\n",
      "loss: 0.1313363812971624\n",
      "loss: 0.131082359085328\n",
      "loss: 0.13109367517555956\n",
      "loss: 0.13113611060360278\n",
      "loss: 0.1310941748877513\n",
      "loss: 0.13111990034276366\n",
      "loss: 0.13109769652793832\n",
      "loss: 0.13110274016176723\n",
      "loss: 0.13112086146053897\n",
      "loss: 0.1311830930221185\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 6\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1595371981135522\n",
      "loss: 0.14019147203745522\n",
      "loss: 0.1396875998783521\n",
      "loss: 0.13982742238060125\n",
      "loss: 0.13965260122980191\n",
      "loss: 0.13962193366214523\n",
      "loss: 0.1396052906729858\n",
      "loss: 0.13979770443811798\n",
      "loss: 0.13970323132751875\n",
      "loss: 0.13980278168828986\n",
      "loss: 0.13963611613220725\n",
      "loss: 0.13960217389156104\n",
      "loss: 0.1396793040630841\n",
      "loss: 0.1396199899468592\n",
      "loss: 0.13962480733784222\n",
      "loss: 0.13963109514117972\n",
      "loss: 0.13983350673691738\n",
      "loss: 0.1396463710950221\n",
      "loss: 0.1396002210149705\n",
      "QNN: 0.0001220703125\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 7\n",
      "SD: 0.0009765625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.2649724357055853\n",
      "loss: 0.23699656891527066\n",
      "loss: 0.23444051203252853\n",
      "loss: 0.2334578668213686\n",
      "loss: 0.2330836754446968\n",
      "loss: 0.23322968307923045\n",
      "loss: 0.23301725267630485\n",
      "loss: 0.23309244479905503\n",
      "loss: 0.2332954998385772\n",
      "loss: 0.23300833897398865\n",
      "loss: 0.2330426542752654\n",
      "loss: 0.23309847392360677\n",
      "loss: 0.23310958515177468\n",
      "loss: 0.23311477415912374\n",
      "loss: 0.233112378677678\n",
      "loss: 0.23293449038736416\n",
      "loss: 0.23311725748809597\n",
      "loss: 0.2330974897160253\n",
      "loss: 0.23326493398178777\n",
      "QNN: 0.03955078125\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 8\n",
      "SD: 0.0029296875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.2867684168098199\n",
      "loss: 0.23864394602264222\n",
      "loss: 0.22959009434233005\n",
      "loss: 0.2292039933832497\n",
      "loss: 0.22973898964737977\n",
      "loss: 0.2293417240323046\n",
      "loss: 0.2292426704176008\n",
      "loss: 0.22915084094096894\n",
      "loss: 0.22974234190258397\n",
      "loss: 0.22955547489840547\n",
      "loss: 0.2291011874362874\n",
      "loss: 0.22907613282945907\n",
      "loss: 0.22964553342695201\n",
      "loss: 0.23018049358870166\n",
      "loss: 0.22911652424985185\n",
      "loss: 0.2291072264848296\n",
      "loss: 0.2292480734344687\n",
      "loss: 0.2292894903659516\n",
      "loss: 0.22912800388218282\n",
      "QNN: 0.070068359375\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 9\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.23798037097640196\n",
      "loss: 0.22849554077869258\n",
      "loss: 0.22789813131242448\n",
      "loss: 0.2273785709941886\n",
      "loss: 0.22735213052530967\n",
      "loss: 0.22750926938205657\n",
      "loss: 0.22735691331449223\n",
      "loss: 0.2273520346686583\n",
      "loss: 0.22741675474985265\n",
      "loss: 0.22731488429842342\n",
      "loss: 0.2276395341806212\n",
      "loss: 0.22732457470882128\n",
      "loss: 0.22733135216806907\n",
      "loss: 0.22732879677129725\n",
      "loss: 0.2273555188626323\n",
      "loss: 0.22741549121190752\n",
      "loss: 0.22769750735943514\n",
      "loss: 0.2273907636202155\n",
      "loss: 0.22731302364369596\n",
      "QNN: 0.0299072265625\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 10\n",
      "SD: 0.0001220703125\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.25641394047848\n",
      "loss: 0.2462882516678539\n",
      "loss: 0.24559312939172287\n",
      "loss: 0.24555280765956922\n",
      "loss: 0.24559537374930462\n",
      "loss: 0.24561585032217503\n",
      "loss: 0.24552950061217388\n",
      "loss: 0.24580344001616805\n",
      "loss: 0.24562460132579106\n",
      "loss: 0.24567462700589338\n",
      "loss: 0.24560464762752202\n",
      "loss: 0.2456749152552633\n",
      "loss: 0.24552841434067652\n",
      "loss: 0.24565771153007443\n",
      "loss: 0.24565251754497205\n",
      "loss: 0.24561973943614773\n",
      "loss: 0.24560958992082324\n",
      "loss: 0.2457447092380272\n",
      "loss: 0.24556810454903852\n",
      "QNN: 0.0531005859375\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 11\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.17043227035077607\n",
      "loss: 0.14332219574707072\n",
      "loss: 0.14172158724231193\n",
      "loss: 0.14164112907394025\n",
      "loss: 0.14168425799295933\n",
      "loss: 0.14171950304125933\n",
      "loss: 0.14166067424124273\n",
      "loss: 0.14173402118482442\n",
      "loss: 0.14162387945742697\n",
      "loss: 0.14170015852306003\n",
      "loss: 0.14165461511849647\n",
      "loss: 0.14162513800312146\n",
      "loss: 0.14170761785645383\n",
      "loss: 0.1416755332553913\n",
      "loss: 0.14166055147966583\n",
      "loss: 0.14171171024519844\n",
      "loss: 0.14167480402668406\n",
      "loss: 0.14166659345948018\n",
      "loss: 0.1416748689670028\n",
      "QNN: 0.0003662109375\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 12\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.04154409464815435\n",
      "loss: 0.036438578209750806\n",
      "loss: 0.03547519055614143\n",
      "loss: 0.035265673727830085\n",
      "loss: 0.03521173979681475\n",
      "loss: 0.03519738867728854\n",
      "loss: 0.035195537316334805\n",
      "loss: 0.035198040010289776\n",
      "loss: 0.035198735897474555\n",
      "loss: 0.03519761207036323\n",
      "loss: 0.03520001122250801\n",
      "loss: 0.03519223196542214\n",
      "loss: 0.03519076212597411\n",
      "loss: 0.035203128352819656\n",
      "loss: 0.03522523756378915\n",
      "loss: 0.03519125880482785\n",
      "loss: 0.03519409028921496\n",
      "loss: 0.035193704107474216\n",
      "loss: 0.03518954512455973\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 13\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1484158285216377\n",
      "loss: 0.14014082960867083\n",
      "loss: 0.13936392937389985\n",
      "loss: 0.13936328669582596\n",
      "loss: 0.13941154623669078\n",
      "loss: 0.13931131848522452\n",
      "loss: 0.1393285980999389\n",
      "loss: 0.13943267058182057\n",
      "loss: 0.1393156588927338\n",
      "loss: 0.13932959385614685\n",
      "loss: 0.1393706860834166\n",
      "loss: 0.13941816721151376\n",
      "loss: 0.13938203490061557\n",
      "loss: 0.1393180524576636\n",
      "loss: 0.1393295914737234\n",
      "loss: 0.13931180612562236\n",
      "loss: 0.13942052238782712\n",
      "loss: 0.13931350587554106\n",
      "loss: 0.13941247699941153\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 14\n",
      "SD: 0.0018310546875\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3793698461584908\n",
      "loss: 0.3565344636446352\n",
      "loss: 0.34447190789560456\n",
      "loss: 0.342661443227944\n",
      "loss: 0.3381052341153832\n",
      "loss: 0.33802915895951935\n",
      "loss: 0.33949262266097235\n",
      "loss: 0.33842770912402365\n",
      "loss: 0.3406827931448019\n",
      "loss: 0.34100515823431926\n",
      "loss: 0.3417792692531265\n",
      "loss: 0.3406608373600345\n",
      "loss: 0.3347641336599753\n",
      "loss: 0.33423025813656926\n",
      "loss: 0.33327921914672054\n",
      "loss: 0.33456283001456566\n",
      "loss: 0.3354903198470798\n",
      "loss: 0.3350820734277435\n",
      "loss: 0.33666937636395144\n",
      "loss: 0.3342971753196171\n",
      "loss: 0.33312225988323557\n",
      "loss: 0.3325186484095384\n",
      "loss: 0.33263876611444465\n",
      "loss: 0.3323250575252349\n",
      "loss: 0.3327628193618486\n",
      "loss: 0.33300530892227603\n",
      "loss: 0.3328023128236032\n",
      "loss: 0.3322916299267819\n",
      "loss: 0.33336297193811865\n",
      "loss: 0.33340176793886483\n",
      "loss: 0.3322529131693177\n",
      "loss: 0.3322565923359078\n",
      "loss: 0.3321663556797515\n",
      "loss: 0.33243849028488326\n",
      "loss: 0.3323855780744415\n",
      "loss: 0.33218366952871187\n",
      "loss: 0.33230281238684517\n",
      "loss: 0.3325186822444439\n",
      "loss: 0.3329937114331743\n",
      "QNN: 0.137451171875\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 15\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.16031249327451869\n",
      "loss: 0.1541842355010793\n",
      "loss: 0.15393898702543377\n",
      "loss: 0.15379750465135303\n",
      "loss: 0.15379288674591818\n",
      "loss: 0.15377301403696653\n",
      "loss: 0.15380446499823738\n",
      "loss: 0.15380119123392275\n",
      "loss: 0.1537964042171486\n",
      "loss: 0.15387448891594319\n",
      "loss: 0.15376596037954324\n",
      "loss: 0.1538062509341148\n",
      "loss: 0.15378487098611132\n",
      "loss: 0.1537869000907097\n",
      "loss: 0.153800311482319\n",
      "loss: 0.1537679637759943\n",
      "loss: 0.15379039065612546\n",
      "loss: 0.1537723786627045\n",
      "loss: 0.15387796359697406\n",
      "QNN: 0.000244140625\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 16\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599462\n",
      "loss: 0.16467238433618464\n",
      "loss: 0.15069624061773398\n",
      "loss: 0.1502541485127441\n",
      "loss: 0.15026840592034307\n",
      "loss: 0.15020328490212892\n",
      "loss: 0.15021261323527046\n",
      "loss: 0.15021269064284237\n",
      "loss: 0.15050332761127883\n",
      "loss: 0.1503620842927078\n",
      "loss: 0.15057957329793162\n",
      "loss: 0.15024414681284595\n",
      "loss: 0.15021671329526298\n",
      "loss: 0.15028987679427913\n",
      "loss: 0.15024168011740813\n",
      "loss: 0.15027249311530097\n",
      "loss: 0.15031756526176493\n",
      "loss: 0.1503691254263224\n",
      "loss: 0.15027685401778312\n",
      "loss: 0.15039515464711742\n",
      "QNN: 0.00048828125\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 17\n",
      "SD: 0.000244140625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.28903582275785167\n",
      "loss: 0.2657223606938952\n",
      "loss: 0.2582803607874785\n",
      "loss: 0.2569079636719031\n",
      "loss: 0.2563289735969454\n",
      "loss: 0.25545568598144597\n",
      "loss: 0.2553190074665124\n",
      "loss: 0.25425904819917994\n",
      "loss: 0.2543461502985349\n",
      "loss: 0.25495060907837463\n",
      "loss: 0.25436651518070497\n",
      "loss: 0.2542531938167573\n",
      "loss: 0.25423186231855915\n",
      "loss: 0.2542620669359087\n",
      "loss: 0.25420034297634736\n",
      "loss: 0.2551796501267349\n",
      "loss: 0.25488713966642285\n",
      "loss: 0.2549496083469797\n",
      "loss: 0.2550413735801411\n",
      "QNN: 0.0823974609375\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 18\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.16158170121178092\n",
      "loss: 0.14239411815492944\n",
      "loss: 0.14144593349161383\n",
      "loss: 0.14138579480110441\n",
      "loss: 0.14138656689533255\n",
      "loss: 0.14143627550874366\n",
      "loss: 0.14136161830339808\n",
      "loss: 0.14137645802056592\n",
      "loss: 0.1413766010015969\n",
      "loss: 0.1414748839406859\n",
      "loss: 0.14137883203690954\n",
      "loss: 0.141444657002997\n",
      "loss: 0.14143432932288338\n",
      "loss: 0.14151584620895544\n",
      "loss: 0.141588495025589\n",
      "loss: 0.14135772440271865\n",
      "loss: 0.14136353458087866\n",
      "loss: 0.14139427811739927\n",
      "loss: 0.14143766065916558\n",
      "QNN: 0.003173828125\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 19\n",
      "SD: 0.000244140625\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3085095754963622\n",
      "loss: 0.2908370095719346\n",
      "loss: 0.2838584912009718\n",
      "loss: 0.280917192498574\n",
      "loss: 0.2817926493347181\n",
      "loss: 0.28135002711254314\n",
      "loss: 0.2808804879364624\n",
      "loss: 0.27964008649715183\n",
      "loss: 0.2796014593791123\n",
      "loss: 0.27978928458840135\n",
      "loss: 0.28027731642656806\n",
      "loss: 0.2797877598574182\n",
      "loss: 0.2796821640167095\n",
      "loss: 0.2795358032707208\n",
      "loss: 0.279588837369196\n",
      "loss: 0.2798477691320806\n",
      "loss: 0.27993631019344994\n",
      "loss: 0.27980091818359437\n",
      "loss: 0.2796751896871676\n",
      "QNN: 0.0867919921875\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 20\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1713953547119367\n",
      "loss: 0.15354396091696074\n",
      "loss: 0.1521934034672716\n",
      "loss: 0.15222612485577336\n",
      "loss: 0.1522023885397417\n",
      "loss: 0.15218230306888267\n",
      "loss: 0.15219751780247132\n",
      "loss: 0.15220926586957695\n",
      "loss: 0.15220824756926524\n",
      "loss: 0.15220828794305927\n",
      "loss: 0.1521832234644852\n",
      "loss: 0.152238511988018\n",
      "loss: 0.15220042762143438\n",
      "loss: 0.15236582836068424\n",
      "loss: 0.15228374188158292\n",
      "loss: 0.15229785812549027\n",
      "loss: 0.15222687758569783\n",
      "loss: 0.15221892471208376\n",
      "loss: 0.1522166828316416\n",
      "QNN: 0.001220703125\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 21\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.13638378534873888\n",
      "loss: 0.12634167402662522\n",
      "loss: 0.1257584161688778\n",
      "loss: 0.12575858575359983\n",
      "loss: 0.12570658935285442\n",
      "loss: 0.12570148136512985\n",
      "loss: 0.12571836321316845\n",
      "loss: 0.1257813992850974\n",
      "loss: 0.12568616313052652\n",
      "loss: 0.1256681838444033\n",
      "loss: 0.1257949900653057\n",
      "loss: 0.12567256443571173\n",
      "loss: 0.1257030527105138\n",
      "loss: 0.12567403419624099\n",
      "loss: 0.12569519395947035\n",
      "loss: 0.12567760604126055\n",
      "loss: 0.12569210201997766\n",
      "loss: 0.12579427691450756\n",
      "loss: 0.12568291996313835\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 22\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.2523993370561009\n",
      "loss: 0.21377397692550099\n",
      "loss: 0.20977898113600488\n",
      "loss: 0.20857535618544557\n",
      "loss: 0.2083075170367569\n",
      "loss: 0.20853226895807056\n",
      "loss: 0.20836739780895416\n",
      "loss: 0.20839258831670515\n",
      "loss: 0.20827315807753716\n",
      "loss: 0.20825675167814958\n",
      "loss: 0.20855205209514593\n",
      "loss: 0.2087836056973979\n",
      "loss: 0.2086517441279471\n",
      "loss: 0.2087093228244441\n",
      "loss: 0.2085779969807714\n",
      "loss: 0.20864688744347257\n",
      "loss: 0.20862767842033297\n",
      "loss: 0.2090799537371907\n",
      "loss: 0.20904177979194244\n",
      "QNN: 0.040771484375\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 23\n",
      "SD: 0.00341796875\n",
      "loss: 0.6931471805599465\n",
      "loss: 0.2394601613409249\n",
      "loss: 0.22514935380713164\n",
      "loss: 0.22459937538465602\n",
      "loss: 0.22433755744891312\n",
      "loss: 0.22428015348763736\n",
      "loss: 0.22430595712347312\n",
      "loss: 0.22423474620474537\n",
      "loss: 0.2242555957921731\n",
      "loss: 0.22440007879716797\n",
      "loss: 0.2242765904634766\n",
      "loss: 0.22430561573038882\n",
      "loss: 0.22431089266833257\n",
      "loss: 0.22424150548509497\n",
      "loss: 0.22427115337820058\n",
      "loss: 0.22427939343522174\n",
      "loss: 0.2244350174936537\n",
      "loss: 0.22452738517950305\n",
      "loss: 0.22447513369994224\n",
      "loss: 0.22429506604220822\n",
      "QNN: 0.033203125\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 24\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.10110631727695422\n",
      "loss: 0.09811203777228425\n",
      "loss: 0.09801884748739217\n",
      "loss: 0.0979610116522635\n",
      "loss: 0.09794125586994369\n",
      "loss: 0.09791808164900465\n",
      "loss: 0.09800487952420918\n",
      "loss: 0.09797079359705717\n",
      "loss: 0.0979194707603704\n",
      "loss: 0.09791556287495629\n",
      "loss: 0.09795132529205221\n",
      "loss: 0.09798217718520662\n",
      "loss: 0.09794149758775005\n",
      "loss: 0.09797371697588857\n",
      "loss: 0.09792717436188064\n",
      "loss: 0.0979557631267694\n",
      "loss: 0.09793920743052181\n",
      "loss: 0.0979561967032331\n",
      "loss: 0.09810954586431031\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 25\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.21903500069368803\n",
      "loss: 0.17985888482238194\n",
      "loss: 0.17883233737754836\n",
      "loss: 0.17883826272558817\n",
      "loss: 0.17873429700665705\n",
      "loss: 0.17872618973379203\n",
      "loss: 0.1787070752560199\n",
      "loss: 0.17858476660873676\n",
      "loss: 0.17855763093164148\n",
      "loss: 0.17860238745318505\n",
      "loss: 0.17857705034424742\n",
      "loss: 0.1786421998922098\n",
      "loss: 0.1786134342070799\n",
      "loss: 0.17858434261003842\n",
      "loss: 0.17868697678023213\n",
      "loss: 0.17856221063987684\n",
      "loss: 0.1786166486289716\n",
      "loss: 0.17858847069843145\n",
      "loss: 0.1789784460586061\n",
      "QNN: 0.0311279296875\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 26\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599462\n",
      "loss: 0.3250948014544391\n",
      "loss: 0.2747317356895711\n",
      "loss: 0.26644192141621925\n",
      "loss: 0.2636935080078299\n",
      "loss: 0.26537248327227836\n",
      "loss: 0.2644764392916182\n",
      "loss: 0.26323873941907355\n",
      "loss: 0.26308658381118366\n",
      "loss: 0.2634646492880915\n",
      "loss: 0.2630657895412031\n",
      "loss: 0.2633025860460335\n",
      "loss: 0.2631887409978415\n",
      "loss: 0.2632488102110244\n",
      "loss: 0.2632126520895257\n",
      "loss: 0.2644875525656467\n",
      "loss: 0.26405263677204305\n",
      "loss: 0.26329728557541565\n",
      "loss: 0.26377843636515313\n",
      "loss: 0.263507413172411\n",
      "QNN: 0.103271484375\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 27\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.09856505877347199\n",
      "loss: 0.08796661257017252\n",
      "loss: 0.08770654822334738\n",
      "loss: 0.0876763482446338\n",
      "loss: 0.08768323524079825\n",
      "loss: 0.087635426142891\n",
      "loss: 0.08768877592796528\n",
      "loss: 0.08767075030651543\n",
      "loss: 0.08764950767024203\n",
      "loss: 0.08763540758455544\n",
      "loss: 0.08778672956126649\n",
      "loss: 0.08765624658572602\n",
      "loss: 0.08765175107141343\n",
      "loss: 0.08765878279165747\n",
      "loss: 0.08764967268725343\n",
      "loss: 0.08764629939842193\n",
      "loss: 0.0876638891760952\n",
      "loss: 0.08767334925762055\n",
      "loss: 0.0877138789561657\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 28\n",
      "SD: 0.0054931640625\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.10903858102548128\n",
      "loss: 0.08577267718079148\n",
      "loss: 0.08501747800495904\n",
      "loss: 0.08494284206388371\n",
      "loss: 0.08494509487113996\n",
      "loss: 0.0849243001972638\n",
      "loss: 0.08490799652440076\n",
      "loss: 0.08495382176458659\n",
      "loss: 0.08493398442211485\n",
      "loss: 0.08492580750231847\n",
      "loss: 0.0849447509002431\n",
      "loss: 0.08491143416484147\n",
      "loss: 0.08496103560067136\n",
      "loss: 0.08493538588902212\n",
      "loss: 0.08493015780187659\n",
      "loss: 0.08492127095445946\n",
      "loss: 0.08492545371770491\n",
      "loss: 0.08495481998462337\n",
      "loss: 0.084932028322762\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 20\n",
      "----------------------------current iter num: 29\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.12960844112736894\n",
      "loss: 0.11699847099334702\n",
      "loss: 0.11615283654645168\n",
      "loss: 0.11619519040253479\n",
      "loss: 0.11613865892637781\n",
      "loss: 0.11612127034273659\n",
      "loss: 0.1161368849909067\n",
      "loss: 0.11611009279296226\n",
      "loss: 0.11623384712388193\n",
      "loss: 0.11613386838942551\n",
      "loss: 0.11630369181543695\n",
      "loss: 0.11612144644266609\n",
      "loss: 0.11612891118432225\n",
      "loss: 0.1161986309154211\n",
      "loss: 0.11616060842284602\n",
      "loss: 0.11611175119985438\n",
      "loss: 0.11629435711311766\n",
      "loss: 0.11612237365015877\n",
      "loss: 0.11619247993322013\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 0\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.13150178896117173\n",
      "loss: 0.1236661775819758\n",
      "loss: 0.12290468959363478\n",
      "loss: 0.12277058081734236\n",
      "loss: 0.12275319306707753\n",
      "loss: 0.12275218741594157\n",
      "loss: 0.12287858288115314\n",
      "loss: 0.12285487983253641\n",
      "loss: 0.12277649176141657\n",
      "loss: 0.12278248608355712\n",
      "loss: 0.1227382193269031\n",
      "loss: 0.12281472546663218\n",
      "loss: 0.12274389207188628\n",
      "loss: 0.1227576203989142\n",
      "loss: 0.12275418294285848\n",
      "loss: 0.12277381398008792\n",
      "loss: 0.1228569963359294\n",
      "loss: 0.12273596966575726\n",
      "loss: 0.12273673779215874\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 1\n",
      "SD: 0.0001220703125\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.16187303732805575\n",
      "loss: 0.15757620369801967\n",
      "loss: 0.15756630697514742\n",
      "loss: 0.15763613871374682\n",
      "loss: 0.15765718208353405\n",
      "loss: 0.1577003968850916\n",
      "loss: 0.1575523790127923\n",
      "loss: 0.1576150992957684\n",
      "loss: 0.1575455257304073\n",
      "loss: 0.1575464568407242\n",
      "loss: 0.1575870150726912\n",
      "loss: 0.15758064008987224\n",
      "loss: 0.15762236595407902\n",
      "loss: 0.15758087905185314\n",
      "loss: 0.15756821482563402\n",
      "loss: 0.15756398351718143\n",
      "loss: 0.1575603758518385\n",
      "loss: 0.15761202307539193\n",
      "loss: 0.15756914454452012\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 2\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.21630249178171726\n",
      "loss: 0.20852876006087176\n",
      "loss: 0.20766510188626322\n",
      "loss: 0.20759435152829833\n",
      "loss: 0.20765646815720584\n",
      "loss: 0.20755728538069443\n",
      "loss: 0.20761306342488706\n",
      "loss: 0.20762889990883857\n",
      "loss: 0.20759742150199367\n",
      "loss: 0.2076461022908941\n",
      "loss: 0.2076209429858677\n",
      "loss: 0.2075990943982504\n",
      "loss: 0.20756106539306313\n",
      "loss: 0.2076237062469086\n",
      "loss: 0.2076162832729342\n",
      "loss: 0.20759174664072214\n",
      "loss: 0.20756712321063964\n",
      "loss: 0.20755668758288587\n",
      "loss: 0.20781475017921436\n",
      "QNN: 0.0020751953125\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 3\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.16850945917154003\n",
      "loss: 0.14134199779810813\n",
      "loss: 0.1397798782620255\n",
      "loss: 0.13958512989532645\n",
      "loss: 0.139592584414212\n",
      "loss: 0.13961075319101973\n",
      "loss: 0.13961140061916125\n",
      "loss: 0.139805936856785\n",
      "loss: 0.13965127948201916\n",
      "loss: 0.1397385236734907\n",
      "loss: 0.13960981060912586\n",
      "loss: 0.13963594403343033\n",
      "loss: 0.13963803589326515\n",
      "loss: 0.13962959060209656\n",
      "loss: 0.13960927324433742\n",
      "loss: 0.13960671839946412\n",
      "loss: 0.13961717140966115\n",
      "loss: 0.13963914518452641\n",
      "loss: 0.1396318118234285\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 4\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.13713308911144353\n",
      "loss: 0.11212394068468089\n",
      "loss: 0.11135391919003566\n",
      "loss: 0.11138522589834318\n",
      "loss: 0.11130258677096044\n",
      "loss: 0.11129433520501258\n",
      "loss: 0.1113481149365981\n",
      "loss: 0.1113417415764332\n",
      "loss: 0.11129686679083728\n",
      "loss: 0.11130359644468873\n",
      "loss: 0.11129734356275774\n",
      "loss: 0.11134197446528799\n",
      "loss: 0.111419723667578\n",
      "loss: 0.1113019163199702\n",
      "loss: 0.11131609236214036\n",
      "loss: 0.11133450157103897\n",
      "loss: 0.11135510174378264\n",
      "loss: 0.11129300183626156\n",
      "loss: 0.11138737309452353\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 5\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.13686176360328337\n",
      "loss: 0.12991518366229382\n",
      "loss: 0.12972767903588261\n",
      "loss: 0.12972804944243463\n",
      "loss: 0.12986339700417887\n",
      "loss: 0.12974676673456773\n",
      "loss: 0.12974446525322939\n",
      "loss: 0.13007383914956971\n",
      "loss: 0.129954596487434\n",
      "loss: 0.12973840374185733\n",
      "loss: 0.12979846767941702\n",
      "loss: 0.12972896337424245\n",
      "loss: 0.1298293571983654\n",
      "loss: 0.1298210156829221\n",
      "loss: 0.12975355796132318\n",
      "loss: 0.12976443774535243\n",
      "loss: 0.12978157132598692\n",
      "loss: 0.12989968486510203\n",
      "loss: 0.1300346060683083\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 6\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.17110137934732597\n",
      "loss: 0.13722438529599185\n",
      "loss: 0.13575808821263244\n",
      "loss: 0.13569977314994203\n",
      "loss: 0.13574568947617344\n",
      "loss: 0.1356987509645609\n",
      "loss: 0.135721768627316\n",
      "loss: 0.1356943743192324\n",
      "loss: 0.13580548912539062\n",
      "loss: 0.13571887827884174\n",
      "loss: 0.135806337917959\n",
      "loss: 0.13592132833525372\n",
      "loss: 0.135716015821408\n",
      "loss: 0.13573407869756873\n",
      "loss: 0.1357306577463052\n",
      "loss: 0.13570943731722968\n",
      "loss: 0.13576387830321313\n",
      "loss: 0.13576010777441866\n",
      "loss: 0.1356892867626023\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 7\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.25144723897803795\n",
      "loss: 0.23957439148878965\n",
      "loss: 0.23699371822937576\n",
      "loss: 0.23630209229449772\n",
      "loss: 0.2363808350787277\n",
      "loss: 0.23629753719764382\n",
      "loss: 0.23628832706636155\n",
      "loss: 0.23588806611792473\n",
      "loss: 0.23626415566346462\n",
      "loss: 0.236103076796493\n",
      "loss: 0.23621249917126177\n",
      "loss: 0.2361370123411185\n",
      "loss: 0.23592798188617953\n",
      "loss: 0.2362295709710003\n",
      "loss: 0.23598019785634503\n",
      "loss: 0.23587997815781184\n",
      "loss: 0.2359685723560396\n",
      "loss: 0.23588975000928633\n",
      "loss: 0.2359170066033644\n",
      "QNN: 0.03515625\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 8\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.24037502487835072\n",
      "loss: 0.23191924854960597\n",
      "loss: 0.2305016298058444\n",
      "loss: 0.23045860651324612\n",
      "loss: 0.2305728358660799\n",
      "loss: 0.23065495757970939\n",
      "loss: 0.23079473320399124\n",
      "loss: 0.2308054859072786\n",
      "loss: 0.2305510510385673\n",
      "loss: 0.23045367794572022\n",
      "loss: 0.2304939977702727\n",
      "loss: 0.23056701811957941\n",
      "loss: 0.23052152855283056\n",
      "loss: 0.23067483535162928\n",
      "loss: 0.23053967413236526\n",
      "loss: 0.2306439954867652\n",
      "loss: 0.23058922945877422\n",
      "loss: 0.2305882083765663\n",
      "loss: 0.23062826680569992\n",
      "QNN: 0.064453125\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 9\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.25074859263735616\n",
      "loss: 0.2197616186841233\n",
      "loss: 0.21819382400186738\n",
      "loss: 0.21815256862611004\n",
      "loss: 0.21819028911602803\n",
      "loss: 0.21820664304639642\n",
      "loss: 0.21827824708416863\n",
      "loss: 0.21816807357377832\n",
      "loss: 0.21813651197584413\n",
      "loss: 0.21829146932294616\n",
      "loss: 0.21814468390194786\n",
      "loss: 0.21818359626917405\n",
      "loss: 0.21834819013027335\n",
      "loss: 0.21809346719732517\n",
      "loss: 0.2183870023083141\n",
      "loss: 0.21815377748758155\n",
      "loss: 0.2181390542454021\n",
      "loss: 0.21828303076692018\n",
      "loss: 0.2180716808754839\n",
      "QNN: 0.03955078125\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 10\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.27446004422261056\n",
      "loss: 0.24782321220213552\n",
      "loss: 0.24448452428147802\n",
      "loss: 0.24446754527264788\n",
      "loss: 0.24462926597811052\n",
      "loss: 0.2445620687574401\n",
      "loss: 0.24442493953070957\n",
      "loss: 0.24447040927793073\n",
      "loss: 0.2444515974287052\n",
      "loss: 0.2445766967173936\n",
      "loss: 0.24455217749563662\n",
      "loss: 0.2445472402765287\n",
      "loss: 0.24454218084519397\n",
      "loss: 0.2446858061951328\n",
      "loss: 0.24445619797485105\n",
      "loss: 0.24455772774141707\n",
      "loss: 0.24447953599047176\n",
      "loss: 0.24448531126734835\n",
      "loss: 0.24447601780186623\n",
      "QNN: 0.033935546875\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 11\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.16874722692952146\n",
      "loss: 0.14127857049360462\n",
      "loss: 0.14076831308752843\n",
      "loss: 0.14091465756222327\n",
      "loss: 0.14077338960239566\n",
      "loss: 0.1407177446904678\n",
      "loss: 0.14080338009287208\n",
      "loss: 0.1409240342379705\n",
      "loss: 0.14074271357916493\n",
      "loss: 0.14084335018673225\n",
      "loss: 0.14086745036010898\n",
      "loss: 0.14087633738120586\n",
      "loss: 0.14072093446191306\n",
      "loss: 0.14073397963589682\n",
      "loss: 0.14071854392346675\n",
      "loss: 0.14088207998916485\n",
      "loss: 0.14098093209204693\n",
      "loss: 0.14076048924766577\n",
      "loss: 0.14078570374074292\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 12\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.052471010750685436\n",
      "loss: 0.035474972875907305\n",
      "loss: 0.03489786706878685\n",
      "loss: 0.034738932101970564\n",
      "loss: 0.0347049196235341\n",
      "loss: 0.03467668485204256\n",
      "loss: 0.03468197239367184\n",
      "loss: 0.03469482871033478\n",
      "loss: 0.0346724913681645\n",
      "loss: 0.03467345101335391\n",
      "loss: 0.03466687224819856\n",
      "loss: 0.03467389943853563\n",
      "loss: 0.03467804599119925\n",
      "loss: 0.034668114080493924\n",
      "loss: 0.03467852362789117\n",
      "loss: 0.034666394322609574\n",
      "loss: 0.03466736248252814\n",
      "loss: 0.034661773900111874\n",
      "loss: 0.03467091463281267\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 13\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599462\n",
      "loss: 0.15755898318173941\n",
      "loss: 0.13938281713645434\n",
      "loss: 0.13832976866890614\n",
      "loss: 0.13827471103573682\n",
      "loss: 0.1382946902910699\n",
      "loss: 0.1382702992509297\n",
      "loss: 0.13831277380823925\n",
      "loss: 0.13841706840594106\n",
      "loss: 0.13841035807637656\n",
      "loss: 0.1383128450564752\n",
      "loss: 0.13829985591807184\n",
      "loss: 0.13828930327065894\n",
      "loss: 0.13833867615582415\n",
      "loss: 0.13835035282104471\n",
      "loss: 0.1382669616571248\n",
      "loss: 0.13831662847480336\n",
      "loss: 0.13827296566138522\n",
      "loss: 0.13827349858541507\n",
      "loss: 0.13825859540611143\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 14\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.37037279954669444\n",
      "loss: 0.36813985263207216\n",
      "loss: 0.3534629730237946\n",
      "loss: 0.3536638876520583\n",
      "loss: 0.3491011175467439\n",
      "loss: 0.3480092640589667\n",
      "loss: 0.3470160823947531\n",
      "loss: 0.3452196297697475\n",
      "loss: 0.34497142487196364\n",
      "loss: 0.3409339805103979\n",
      "loss: 0.34191420004895273\n",
      "loss: 0.3413036472255676\n",
      "loss: 0.3397240077017413\n",
      "loss: 0.3393398374875027\n",
      "loss: 0.3412078524692373\n",
      "loss: 0.3397760721178671\n",
      "loss: 0.34005973881852314\n",
      "loss: 0.3407075690543854\n",
      "loss: 0.34073596597672967\n",
      "loss: 0.3388346711090338\n",
      "loss: 0.3383972667781104\n",
      "loss: 0.3389858642956452\n",
      "loss: 0.33930026910322386\n",
      "loss: 0.33897607850530587\n",
      "loss: 0.3355424864342082\n",
      "loss: 0.3360183267630229\n",
      "loss: 0.33581636277467203\n",
      "loss: 0.3352209264604107\n",
      "loss: 0.3350568873677597\n",
      "loss: 0.3350133147026188\n",
      "loss: 0.3351209670824194\n",
      "loss: 0.3350693533420395\n",
      "loss: 0.3352115225623413\n",
      "loss: 0.33513429100754943\n",
      "loss: 0.3351226793921878\n",
      "loss: 0.3352795853996944\n",
      "loss: 0.3354325127779049\n",
      "loss: 0.33517347110533796\n",
      "loss: 0.33507513236446723\n",
      "QNN: 0.138916015625\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 15\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.1584707519276646\n",
      "loss: 0.1515812561315661\n",
      "loss: 0.15136973877957044\n",
      "loss: 0.15124322500889006\n",
      "loss: 0.1512346876258639\n",
      "loss: 0.15123588348722994\n",
      "loss: 0.151264390798991\n",
      "loss: 0.15126272118306244\n",
      "loss: 0.15124436239710884\n",
      "loss: 0.15123720266622317\n",
      "loss: 0.1512313143791523\n",
      "loss: 0.15126400426504757\n",
      "loss: 0.15127506489877274\n",
      "loss: 0.15122565498017332\n",
      "loss: 0.1512325372382428\n",
      "loss: 0.15127264649005912\n",
      "loss: 0.15125164872517138\n",
      "loss: 0.1513439456537103\n",
      "loss: 0.15132124239843286\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 16\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.15538039360313027\n",
      "loss: 0.14891947011118598\n",
      "loss: 0.14864225836077016\n",
      "loss: 0.148543192487949\n",
      "loss: 0.14869770382058942\n",
      "loss: 0.14854364598680556\n",
      "loss: 0.1485303994513876\n",
      "loss: 0.14863093301751668\n",
      "loss: 0.14858775182952264\n",
      "loss: 0.14857356890430207\n",
      "loss: 0.1485343196371833\n",
      "loss: 0.1485594024549096\n",
      "loss: 0.14861993240708796\n",
      "loss: 0.14879095788601027\n",
      "loss: 0.1485477170033747\n",
      "loss: 0.148596007925376\n",
      "loss: 0.14851799114489495\n",
      "loss: 0.14853266553957437\n",
      "loss: 0.14856759921096285\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 17\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.28301211362884604\n",
      "loss: 0.26412131272767675\n",
      "loss: 0.2566663905111996\n",
      "loss: 0.2536580949362206\n",
      "loss: 0.2526726377376969\n",
      "loss: 0.25346588930660063\n",
      "loss: 0.2511477461242802\n",
      "loss: 0.2508937352628052\n",
      "loss: 0.2506285374722632\n",
      "loss: 0.2505779825504802\n",
      "loss: 0.25062803206485057\n",
      "loss: 0.2512756530078513\n",
      "loss: 0.25091026482260115\n",
      "loss: 0.250734425351527\n",
      "loss: 0.25051533008807103\n",
      "loss: 0.2507470043294596\n",
      "loss: 0.25077561134210147\n",
      "loss: 0.2506908484453012\n",
      "loss: 0.2508715800495645\n",
      "QNN: 0.0806884765625\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 18\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.14686732334834007\n",
      "loss: 0.14107740811856062\n",
      "loss: 0.14099592566169256\n",
      "loss: 0.14106383639142617\n",
      "loss: 0.140970778776559\n",
      "loss: 0.14099463222573008\n",
      "loss: 0.14107222098661773\n",
      "loss: 0.14114618560368408\n",
      "loss: 0.1413304741199746\n",
      "loss: 0.1409956575043891\n",
      "loss: 0.1409811975277606\n",
      "loss: 0.14102817554827704\n",
      "loss: 0.14106691714526468\n",
      "loss: 0.14097308733933978\n",
      "loss: 0.14097910224062832\n",
      "loss: 0.14095282231124887\n",
      "loss: 0.14104476903527113\n",
      "loss: 0.14106806873917427\n",
      "loss: 0.1410126217800991\n",
      "QNN: 0.00048828125\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 19\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3022701827061227\n",
      "loss: 0.2880528889184113\n",
      "loss: 0.28253606247458335\n",
      "loss: 0.28096728387758996\n",
      "loss: 0.2807241483541269\n",
      "loss: 0.2806195122909979\n",
      "loss: 0.2804762582128071\n",
      "loss: 0.28039160741891067\n",
      "loss: 0.28056748170090745\n",
      "loss: 0.2805525177765782\n",
      "loss: 0.2804647807826405\n",
      "loss: 0.2803855163574788\n",
      "loss: 0.28047080583725825\n",
      "loss: 0.28066405525944466\n",
      "loss: 0.28072334298392226\n",
      "loss: 0.2807380246673408\n",
      "loss: 0.28126980432704995\n",
      "loss: 0.28064236926238134\n",
      "loss: 0.2804207927597825\n",
      "QNN: 0.08642578125\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 20\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.18953238287639823\n",
      "loss: 0.15545751726096452\n",
      "loss: 0.15408017516821787\n",
      "loss: 0.1540289389206749\n",
      "loss: 0.15402512117419923\n",
      "loss: 0.1541131637016469\n",
      "loss: 0.15424894075038506\n",
      "loss: 0.15408958298669265\n",
      "loss: 0.1540791461019394\n",
      "loss: 0.1540419900260485\n",
      "loss: 0.1540978733997329\n",
      "loss: 0.15418966346135443\n",
      "loss: 0.15415390445673527\n",
      "loss: 0.1541630631859179\n",
      "loss: 0.15412422915543542\n",
      "loss: 0.15421492890680863\n",
      "loss: 0.15446626491104523\n",
      "loss: 0.15405965610735467\n",
      "loss: 0.1540785723822641\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 21\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.13172983768803512\n",
      "loss: 0.12463754729930183\n",
      "loss: 0.12405416082489237\n",
      "loss: 0.1239652306804268\n",
      "loss: 0.1240241889840408\n",
      "loss: 0.12396751134313505\n",
      "loss: 0.12395006587813896\n",
      "loss: 0.12397407743562729\n",
      "loss: 0.12398825414324915\n",
      "loss: 0.12396483853384759\n",
      "loss: 0.12396302986470842\n",
      "loss: 0.1239897211769017\n",
      "loss: 0.12399158787501469\n",
      "loss: 0.12402558829976487\n",
      "loss: 0.12395789311595101\n",
      "loss: 0.12404091934108447\n",
      "loss: 0.12398948869343707\n",
      "loss: 0.12396650815964223\n",
      "loss: 0.12399330003507894\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 22\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.22709260681404067\n",
      "loss: 0.21076403482934708\n",
      "loss: 0.20830860247144556\n",
      "loss: 0.20805867382856538\n",
      "loss: 0.20792664356128265\n",
      "loss: 0.2080666749069298\n",
      "loss: 0.20811055669075795\n",
      "loss: 0.20807482006327802\n",
      "loss: 0.20880968079831125\n",
      "loss: 0.20796399359095732\n",
      "loss: 0.2078706480428047\n",
      "loss: 0.20795239734310889\n",
      "loss: 0.20791928997520073\n",
      "loss: 0.20790067446052787\n",
      "loss: 0.20798132090917865\n",
      "loss: 0.2078985202557669\n",
      "loss: 0.2078642980391132\n",
      "loss: 0.2080142903032685\n",
      "loss: 0.20803288171733084\n",
      "QNN: 0.02880859375\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 23\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.23091338399441647\n",
      "loss: 0.2233987625295953\n",
      "loss: 0.2227986504098904\n",
      "loss: 0.22279724207585205\n",
      "loss: 0.22296663317408327\n",
      "loss: 0.22277361743217405\n",
      "loss: 0.22284947206470312\n",
      "loss: 0.22274314979914445\n",
      "loss: 0.22279184381228218\n",
      "loss: 0.22273833036053575\n",
      "loss: 0.22292034459977345\n",
      "loss: 0.22275770491610755\n",
      "loss: 0.2228252186769973\n",
      "loss: 0.2231406778838423\n",
      "loss: 0.2231472534948308\n",
      "loss: 0.22299374518130957\n",
      "loss: 0.2227640122825993\n",
      "loss: 0.22276340538011244\n",
      "loss: 0.2228592087690181\n",
      "QNN: 0.033447265625\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 24\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.16697317930857875\n",
      "loss: 0.10882052325915316\n",
      "loss: 0.09296508134460009\n",
      "loss: 0.09239875472924466\n",
      "loss: 0.09234082803609979\n",
      "loss: 0.0923197376288905\n",
      "loss: 0.09231988138412348\n",
      "loss: 0.09237458116292574\n",
      "loss: 0.09230767513914018\n",
      "loss: 0.09235829340779622\n",
      "loss: 0.09235582052924635\n",
      "loss: 0.09232922715258063\n",
      "loss: 0.09236910614256041\n",
      "loss: 0.09240599398243636\n",
      "loss: 0.09233144625248745\n",
      "loss: 0.09244301272756261\n",
      "loss: 0.09236709689348704\n",
      "loss: 0.09235098828937795\n",
      "loss: 0.09237433659040536\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 25\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599464\n",
      "loss: 0.1915113226446347\n",
      "loss: 0.1792685573764805\n",
      "loss: 0.17888059049381522\n",
      "loss: 0.1788472022480508\n",
      "loss: 0.17882768774962055\n",
      "loss: 0.17888309340288203\n",
      "loss: 0.1789642072499843\n",
      "loss: 0.17882460677272427\n",
      "loss: 0.17882536618949738\n",
      "loss: 0.17890233350622234\n",
      "loss: 0.17891454882466676\n",
      "loss: 0.1789711458260694\n",
      "loss: 0.17889772983341165\n",
      "loss: 0.17882264827982994\n",
      "loss: 0.1788773490478327\n",
      "loss: 0.17881793359591022\n",
      "loss: 0.17884465238957842\n",
      "loss: 0.17889089357907212\n",
      "loss: 0.17912298546677516\n",
      "QNN: 0.0145263671875\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 26\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.3186030552158255\n",
      "loss: 0.2911664234246484\n",
      "loss: 0.28558601739291956\n",
      "loss: 0.28355107641931027\n",
      "loss: 0.2819068161409278\n",
      "loss: 0.28184565602648154\n",
      "loss: 0.2819080091686154\n",
      "loss: 0.2824276095969655\n",
      "loss: 0.28233947987628266\n",
      "loss: 0.2820321654024107\n",
      "loss: 0.28393917187328094\n",
      "loss: 0.2851343140449113\n",
      "loss: 0.28611617446979815\n",
      "loss: 0.28693090650417\n",
      "loss: 0.28653695146297686\n",
      "loss: 0.28839569152921\n",
      "loss: 0.284640326820944\n",
      "loss: 0.28345750502891986\n",
      "loss: 0.28275411800231454\n",
      "QNN: 0.1082763671875\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 27\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.09307196510952266\n",
      "loss: 0.0854998831226821\n",
      "loss: 0.08534760419806008\n",
      "loss: 0.08532100245126509\n",
      "loss: 0.08536013681513839\n",
      "loss: 0.08536344665486577\n",
      "loss: 0.08535245242081779\n",
      "loss: 0.08535667697637488\n",
      "loss: 0.08533324138320368\n",
      "loss: 0.08533432457675034\n",
      "loss: 0.08535249291756397\n",
      "loss: 0.08535522045748135\n",
      "loss: 0.08533266837702765\n",
      "loss: 0.08533180959265602\n",
      "loss: 0.08535986307190725\n",
      "loss: 0.0853302718866011\n",
      "loss: 0.08533413538771785\n",
      "loss: 0.08533750938779024\n",
      "loss: 0.08534132521695184\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 28\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.09056983706786145\n",
      "loss: 0.08533833616853219\n",
      "loss: 0.08500931221061996\n",
      "loss: 0.0849763921651133\n",
      "loss: 0.08505930026205212\n",
      "loss: 0.08499067775928809\n",
      "loss: 0.08501118775798175\n",
      "loss: 0.08497771868822905\n",
      "loss: 0.08506144766187444\n",
      "loss: 0.08499617315780171\n",
      "loss: 0.08500998504768043\n",
      "loss: 0.08497279530182301\n",
      "loss: 0.08499001598008517\n",
      "loss: 0.08500123372830012\n",
      "loss: 0.085012060826057\n",
      "loss: 0.08499979199879767\n",
      "loss: 0.08505280164615793\n",
      "loss: 0.08500595311482939\n",
      "loss: 0.08502419152672062\n",
      "QNN: 0.0\n",
      "----------------------------current SNR_dB: 25\n",
      "----------------------------current iter num: 29\n",
      "SD: 0.0\n",
      "loss: 0.6931471805599463\n",
      "loss: 0.17790581839586977\n",
      "loss: 0.12789119184993722\n",
      "loss: 0.11096036190104124\n",
      "loss: 0.11060941826285545\n",
      "loss: 0.11063404639198963\n",
      "loss: 0.11061553852674148\n",
      "loss: 0.11064063729570482\n",
      "loss: 0.11069516734888316\n",
      "loss: 0.11061187646703848\n",
      "loss: 0.11062969376791451\n",
      "loss: 0.11061125130374506\n",
      "loss: 0.11062434110448545\n",
      "loss: 0.11062546620824153\n",
      "loss: 0.11065006197985287\n",
      "loss: 0.11062774271119424\n",
      "loss: 0.11061881653838683\n",
      "loss: 0.11070574893050622\n",
      "loss: 0.11066108299288459\n",
      "loss: 0.11063575752333145\n",
      "QNN: 0.0\n"
     ]
    }
   ],
   "source": [
    "for ii in range(len(SNR_list)):\n",
    "    SNR_dB = SNR_list[ii]\n",
    "    \n",
    "    SD_performance = np.zeros(iter_num)\n",
    "    QNN_performance_128 = np.zeros(iter_num)\n",
    "\n",
    "    for jj in range(iter_num):\n",
    "        print(\"----------------------------current SNR_dB: \" +str(SNR_dB))\n",
    "        print(\"----------------------------current iter num: \" +str(jj))\n",
    "\n",
    "        H = H_list[jj]\n",
    "\n",
    "        bits_sequence_testing, x_sequence_testing, y_sequence_testing = generate_data(Nr,Nt,SNR_dB,1024,H)\n",
    "        SD_performance[jj] = sphere_decoding_BER(H, y_sequence_testing, bits_sequence_testing, 1)\n",
    "        print(\"SD: \"+str(SD_performance[jj]))\n",
    "\n",
    "        bits_sequence, x_sequence, y_sequence = generate_data(Nr,Nt,SNR_dB,pilot_length,H)\n",
    "        H_trained, loss = training(max_iter)\n",
    "\n",
    "        save_channel[ii][jj] = H_trained\n",
    "        save_loss[ii][jj] = loss\n",
    "        \n",
    "        BER = calculate_BER(H_trained, bits_sequence_testing, y_sequence_testing)\n",
    "\n",
    "        save_BER[ii][jj] = BER\n",
    "\n",
    "        QNN_performance_128[jj] = BER\n",
    "        print(\"QNN: \"+str(BER))\n",
    "\n",
    "    SD_mean_performance[ii] = np.mean(SD_performance)\n",
    "    QNN_mean_performance_128[ii] = np.mean(QNN_performance_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "lns1 = ax1.plot(SNR_list, SD_mean_performance, '-ro', linewidth=2.0, label=\"Max Log\")\n",
    "lns2 = ax1.plot(SNR_list, QNN_mean_performance_128, '-bo', linewidth=2.0, label=\"QNN Decoding (128 pilot)\")\n",
    "\n",
    "\n",
    "\n",
    "lns = lns1+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, loc=\"lower left\")\n",
    "\n",
    "ax1.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs='auto'))\n",
    "ax1.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "ax1.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
    "\n",
    "ax1.set_xticks(SNR_list)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_adjustable(\"datalim\")\n",
    "ax1.set_xlim(-0.5,25.5)\n",
    "ax1.set_ylim(1e-5, 0.5)\n",
    "ax1.set_ylabel(\"BER\")\n",
    "ax1.set_xlabel(\"SNR(dB)\")\n",
    "plt.title(\"4*2 MIMO, cross entropy loss, gradient descent, 128 pilots\")\n",
    "\n",
    "plt.savefig('BER.png',dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42285545+0.62606458j, -0.84648585-1.90772263j],\n",
       "       [-0.87646608+0.83763628j, -1.37942579+0.91253003j],\n",
       "       [ 0.57674952+0.97768131j,  0.50516082-0.45890055j],\n",
       "       [-0.27671069+0.05670283j,  0.13824529+1.48844958j]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_channel[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.37533806+0.49157468j, -0.79734719-1.74176951j],\n",
       "       [-0.71785279+0.70506569j, -1.2926474 +0.82855668j],\n",
       "       [ 0.46385573+0.77768565j,  0.44475096-0.39933949j],\n",
       "       [-0.19958736+0.06235297j,  0.12763225+1.35868458j]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
